{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영상입력 수치 예측 모델 레시피\n",
    "영상을 입력해서 수치를 예측하는 모델들에 대하여 알아보겠다.<br>\n",
    "수치 예측을 위한 영상 데이터셋을 생성해보고, 다층퍼셉트론 및 컨볼루션 신경망 모델을 구성 및 학습시켜보겠다.<br>\n",
    "이 모델은 고정된 지역에서 촬영된 영상으로부터 복잡도, 밀도 등을 수치화하는 문제를 풀 수 있다.<br>\n",
    "- CCTV 등 촬영 영상으로부터 미세먼지 지수 예측\n",
    "- 위성영상으로부터 녹조, 적조 등의 지수 예측\n",
    "- 태양광 패널의 먼지가 쌓여있는 정도 예측\n",
    "<br>\n",
    "\n",
    "### 1. 데이터셋 준비\n",
    "너비가 16, 높이가 16이고, 픽셀값으로 0과 1을 가지는 영상을 만들어보겠다.<br>\n",
    "임의의 값이 주어지면, 그 값만큼 반복하여 영상 내에 픽셀값이 1인 픽셀을 찍었다.<br>\n",
    "여기서 임의의 값을 라벨값으로 지정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "width = 16\n",
    "height =16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "    \n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "        \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples,1)\n",
    "\n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "        \n",
    "    return img.reshape(width,height,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋 생성( 훈련셋 : 1500개, 검증셋 : 300개, 시험셋 : 100개)\n",
    "\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#데이터셋 일부 가시화\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_train[i].reshape(width,height))\n",
    "    sub_plt.set_title('R ' + str(y_train[i][0]))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R(Real)은 픽셀값이 1인 픽셀 수를 의미한다. 한 번 표시한 픽셀에 다시 표시가 될 수 있기 때문에 실제 픽셀 수와 조금 차이가 있을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 레이어 준비\n",
    "- 2D Input data\n",
    "\n",
    "2차원의 입력 데이터이다.<br>\n",
    "주로 영상 데이터를 의미하며 너비 높이 채널 수로 구성되어있다.<br>\n",
    "\n",
    "- Conv2D\n",
    "\n",
    "필터를 이용하여 영상 특징을 추출하는 컨볼루션 레이어이다.<br>\n",
    "\n",
    "- MaxPooling2D\n",
    "\n",
    "영상에서 사소한 변화가 특징 추출에 크게 영향을 미치지 않도록 해주는 맥스풀링 레이어이다.<br>\n",
    "\n",
    "- Flatten\n",
    "\n",
    "2차원의 특징 맵을 전결합층으로 전달하기 위해 1차원 형식으로 바꿔준다.<br>\n",
    "\n",
    "- relu\n",
    "\n",
    "활성화 함수로 주로 Conv2D 은닉층에 사용된다.<br>\n",
    "\n",
    "### 3. 모델 준비\n",
    "영상입력 수치 예측을 하기 위해 다층퍼셉트론 신경망 모델, 컨볼루션 신경망 모델을 준비하였다.\n",
    "<br>\n",
    "- 다층퍼셉트론 신경망 모델\n",
    "\n",
    "      model = Sequential()\n",
    "      model.add(Dense(256, input_dim = width * height, activation = 'relu'))\n",
    "      model.add(Dense(256, activation = 'relu'))\n",
    "      model.add(Dense(256))\n",
    "      model.add(Dense(1))\n",
    "<br>\n",
    "\n",
    "- 컨볼루션 신경망 모델\n",
    "\n",
    "      model = Sequential()\n",
    "      model.add(Conv2D(32, (3,3),input_dim = (width, height, 1), activation = 'relu'))\n",
    "      model.add(MaxPooling2D(pool_size(2,2)))\n",
    "      model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "      model.add(MaxPooling2D(pool_size(2,2)))\n",
    "      model.add(Flatten())\n",
    "      model.add(Dense(256), activation = 'relu'))\n",
    "      model.add(Dense(1))    \n",
    "    \n",
    "### 4. 전체 소스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 4531.4984 - val_loss: 502.6979\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 0s 67us/step - loss: 301.5262 - val_loss: 245.2407\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 208.6551 - val_loss: 190.3442\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 150.2709 - val_loss: 158.5467\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 101.3946 - val_loss: 133.8490\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 72.9046 - val_loss: 149.1762\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 0s 66us/step - loss: 56.4535 - val_loss: 118.9446\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 0s 67us/step - loss: 41.1626 - val_loss: 118.0269\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 43.1212 - val_loss: 126.9391\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 26.4327 - val_loss: 115.9829\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 19.3374 - val_loss: 111.6813\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 17.4631 - val_loss: 112.0572\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 12.2372 - val_loss: 109.7101\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 7.9206 - val_loss: 108.9737\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 6.6459 - val_loss: 107.8906\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 4.7479 - val_loss: 112.3543\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.7841 - val_loss: 108.2227\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.7277 - val_loss: 107.1198\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 1.9619 - val_loss: 109.1087\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 0s 67us/step - loss: 1.6051 - val_loss: 106.6026\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.3137 - val_loss: 107.3934\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.3666 - val_loss: 110.4204\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.8368 - val_loss: 110.3231\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.6027 - val_loss: 108.5532\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4649 - val_loss: 108.5192\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.3996 - val_loss: 108.4438\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2515 - val_loss: 108.7372\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1685 - val_loss: 108.0199\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2289 - val_loss: 108.9150\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2446 - val_loss: 109.2962\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.1547 - val_loss: 109.5453\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 0s 67us/step - loss: 0.1566 - val_loss: 108.9453\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1461 - val_loss: 108.1594\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1250 - val_loss: 109.1298\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.1537 - val_loss: 107.8772\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 0s 67us/step - loss: 0.1920 - val_loss: 109.8837\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.5611 - val_loss: 110.4038\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 0.9717 - val_loss: 108.3983\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 1.4221 - val_loss: 111.5858\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 3.1397 - val_loss: 110.1263\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.3643 - val_loss: 112.1654\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 6.7844 - val_loss: 107.4906\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 0s 69us/step - loss: 5.9017 - val_loss: 111.8375\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 0s 69us/step - loss: 12.3758 - val_loss: 123.3974\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 17.2261 - val_loss: 115.3446\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 9.0656 - val_loss: 106.9219\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 3.5201 - val_loss: 119.6392\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 2.8697 - val_loss: 109.5694\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 4.5929 - val_loss: 108.8702\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 3.7967 - val_loss: 111.7220\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.5075 - val_loss: 109.0797\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.5230 - val_loss: 108.1780\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 3.7792 - val_loss: 112.7824\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 2.9467 - val_loss: 109.8645\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.2878 - val_loss: 105.6517\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 1.6693 - val_loss: 104.9812\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.2877 - val_loss: 107.3922\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.8079 - val_loss: 104.2653\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.7694 - val_loss: 105.8663\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5026 - val_loss: 104.9129\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.5483 - val_loss: 108.9723\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.2026 - val_loss: 104.5173\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 2.3231 - val_loss: 107.7557\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.2238 - val_loss: 106.6630\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.8606 - val_loss: 107.7541\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 3.9367 - val_loss: 120.4350\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 6.9652 - val_loss: 106.6175\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 4.9153 - val_loss: 105.0285\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 9.7290 - val_loss: 110.7910\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 24.4921 - val_loss: 118.7375\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 49.7722 - val_loss: 133.0728\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 26.6677 - val_loss: 108.8451\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 6.5602 - val_loss: 109.6564\n",
      "Epoch 74/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 3.3546 - val_loss: 105.8755\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 2.2045 - val_loss: 104.6588\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 2.1737 - val_loss: 101.7104\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.2641 - val_loss: 107.7161\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.6211 - val_loss: 104.9963\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.7470 - val_loss: 102.8214\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.5651 - val_loss: 103.1711\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.7122 - val_loss: 102.7800\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.6542 - val_loss: 102.5197\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3141 - val_loss: 102.0699\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3837 - val_loss: 101.6039\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.2317 - val_loss: 101.7394\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2978 - val_loss: 101.5316\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4463 - val_loss: 103.0293\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.3372 - val_loss: 101.6892\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1848 - val_loss: 102.9287\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.1214 - val_loss: 101.5925\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1350 - val_loss: 102.0098\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1953 - val_loss: 102.6253\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1398 - val_loss: 101.9413\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1118 - val_loss: 102.5193\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2776 - val_loss: 101.1921\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3065 - val_loss: 102.8258\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.8311 - val_loss: 102.7941\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.9261 - val_loss: 103.7849\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.1980 - val_loss: 104.1348\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 4.4276 - val_loss: 106.3394\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 17.9649 - val_loss: 105.5555\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 13.0971 - val_loss: 104.8056\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 15.4007 - val_loss: 132.9812\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 60.6035 - val_loss: 131.8950\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 48.2404 - val_loss: 105.9579\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 13.6141 - val_loss: 112.6182\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 3.8038 - val_loss: 108.8201\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.0473 - val_loss: 98.3194\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.4492 - val_loss: 100.7282\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.9286 - val_loss: 104.0669\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.7482 - val_loss: 101.7282\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.4543 - val_loss: 102.8352\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3429 - val_loss: 102.1779\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3433 - val_loss: 101.7671\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3038 - val_loss: 99.8818\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3514 - val_loss: 100.2544\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1702 - val_loss: 101.0634\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.0873 - val_loss: 100.6214\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.0573 - val_loss: 101.4606\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0339 - val_loss: 100.8488\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0882 - val_loss: 100.3924\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.0912 - val_loss: 101.7923\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.1257 - val_loss: 101.1309\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4006 - val_loss: 100.3814\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.2595 - val_loss: 101.4506\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5290 - val_loss: 101.8779\n",
      "Epoch 127/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2638 - val_loss: 101.7600\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2871 - val_loss: 100.9388\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.1309 - val_loss: 100.0497\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1367 - val_loss: 100.3058\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.0887 - val_loss: 100.7167\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1164 - val_loss: 100.3490\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.2226 - val_loss: 99.0192\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.7485 - val_loss: 106.3578\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 5.7015 - val_loss: 110.8631\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 7.4519 - val_loss: 112.2802\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 6.6698 - val_loss: 102.0259\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.8340 - val_loss: 100.3803\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 14.4871 - val_loss: 117.7097\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 6.6228 - val_loss: 104.1264\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.8678 - val_loss: 103.3577\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 4.3518 - val_loss: 99.9773\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 4.0060 - val_loss: 100.2339\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.9672 - val_loss: 99.0920\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.0247 - val_loss: 102.7425\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.5540 - val_loss: 99.6965\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.9272 - val_loss: 107.1956\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.2197 - val_loss: 99.2301\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.0533 - val_loss: 102.6850\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.9572 - val_loss: 99.1614\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.0855 - val_loss: 99.3468\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.9266 - val_loss: 99.7208\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8099 - val_loss: 101.6838\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.4444 - val_loss: 100.1913\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.0910 - val_loss: 100.7675\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.2634 - val_loss: 103.2548\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.7851 - val_loss: 101.7819\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.9146 - val_loss: 97.8670\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.8109 - val_loss: 107.4112\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 2.6782 - val_loss: 102.1361\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 5.3679 - val_loss: 102.1053\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 3.4864 - val_loss: 98.2906\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.8776 - val_loss: 102.0035\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 2.9192 - val_loss: 113.3909\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 4.0224 - val_loss: 100.8775\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 2.3509 - val_loss: 112.6593\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 3.7464 - val_loss: 102.8076\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 4.5717 - val_loss: 100.5437\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 6.1853 - val_loss: 104.2142\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.3506 - val_loss: 100.8948\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 4.0453 - val_loss: 102.4297\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 6.9844 - val_loss: 104.2204\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 10.2619 - val_loss: 103.7063\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 13.0666 - val_loss: 106.1690\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 5.3123 - val_loss: 103.2574\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.5631 - val_loss: 101.7552\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.6630 - val_loss: 100.0418\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.0376 - val_loss: 100.4378\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.8591 - val_loss: 106.2256\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.9224 - val_loss: 102.7717\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6170 - val_loss: 99.6897\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.9395 - val_loss: 99.0935\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.3656 - val_loss: 100.4311\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3333 - val_loss: 100.1646\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4261 - val_loss: 101.5151\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.3328 - val_loss: 99.9298\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1584 - val_loss: 100.6475\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1051 - val_loss: 99.9743\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1019 - val_loss: 100.9131\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1243 - val_loss: 100.3840\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1364 - val_loss: 101.7704\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3232 - val_loss: 100.6766\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.4409 - val_loss: 99.3839\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.6761 - val_loss: 103.2317\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.5793 - val_loss: 100.4932\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3676 - val_loss: 100.9563\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4721 - val_loss: 100.2392\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.8789 - val_loss: 101.8443\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5506 - val_loss: 105.0191\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.6378 - val_loss: 99.5441\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.6795 - val_loss: 103.2861\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 11.9261 - val_loss: 104.2489\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 20.5755 - val_loss: 133.8909\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 7.9379 - val_loss: 103.9484\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 3.8177 - val_loss: 106.0917\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 1.7889 - val_loss: 101.9046\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.5738 - val_loss: 103.7474\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.0800 - val_loss: 100.2062\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.6206 - val_loss: 102.0759\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.7052 - val_loss: 100.9065\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.7123 - val_loss: 100.5720\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7054 - val_loss: 99.8414\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4307 - val_loss: 102.6726\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2546 - val_loss: 100.6275\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.4824 - val_loss: 99.6035\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5084 - val_loss: 105.3587\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 1.3031 - val_loss: 101.4733\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.0868 - val_loss: 100.2617\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.1018 - val_loss: 101.9078\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.1199 - val_loss: 101.5087\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.7571 - val_loss: 100.4823\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 3.6588 - val_loss: 105.3452\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 3.6862 - val_loss: 99.2091\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.3452 - val_loss: 99.2953\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 5.6691 - val_loss: 105.1305\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 7.3851 - val_loss: 98.4251\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 5.5554 - val_loss: 99.5701\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.7196 - val_loss: 101.7478\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.5723 - val_loss: 101.3366\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.7125 - val_loss: 102.9813\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7347 - val_loss: 101.3356\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.0267 - val_loss: 101.6596\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.8661 - val_loss: 101.4533\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.5242 - val_loss: 103.9445\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.7080 - val_loss: 101.7919\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.9277 - val_loss: 101.1218\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.5284 - val_loss: 100.9485\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.3780 - val_loss: 101.0257\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2249 - val_loss: 100.8231\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4023 - val_loss: 101.7163\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.9831 - val_loss: 102.9854\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.6282 - val_loss: 100.9929\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 3.0360 - val_loss: 100.9325\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.7136 - val_loss: 102.6539\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.0508 - val_loss: 105.6242\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.2867 - val_loss: 102.0913\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 4.1903 - val_loss: 103.7963\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 7.2574 - val_loss: 118.3260\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 23.3116 - val_loss: 137.4746\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 11.6942 - val_loss: 105.8515\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 5.5255 - val_loss: 101.4327\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.9227 - val_loss: 101.6333\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.7054 - val_loss: 99.8846\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.7257 - val_loss: 102.0667\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.8057 - val_loss: 100.8161\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.3780 - val_loss: 103.4242\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.5130 - val_loss: 100.9342\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.8978 - val_loss: 103.6304\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.8578 - val_loss: 101.1429\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.0334 - val_loss: 102.7683\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4482 - val_loss: 103.2108\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.2358 - val_loss: 101.9836\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1337 - val_loss: 101.8143\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.1128 - val_loss: 101.3530\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1395 - val_loss: 103.7358\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.1436 - val_loss: 101.1315\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0884 - val_loss: 102.9633\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.0695 - val_loss: 101.2238\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1474 - val_loss: 102.0286\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0715 - val_loss: 101.1141\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0719 - val_loss: 102.5294\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1258 - val_loss: 101.7466\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0760 - val_loss: 102.1036\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0589 - val_loss: 101.9007\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1032 - val_loss: 100.6034\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.3473 - val_loss: 104.5498\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6845 - val_loss: 101.2171\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.6384 - val_loss: 115.3764\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 8.8377 - val_loss: 100.9573\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 9.3085 - val_loss: 107.6798\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 7.9658 - val_loss: 100.6279\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.9825 - val_loss: 101.5484\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.6153 - val_loss: 98.6031\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.7857 - val_loss: 98.9509\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.7446 - val_loss: 100.4783\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.6759 - val_loss: 102.2579\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.5321 - val_loss: 100.3736\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.0339 - val_loss: 100.3494\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.9808 - val_loss: 101.1253\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.4943 - val_loss: 102.8917\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 2.5784 - val_loss: 103.0870\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.1742 - val_loss: 99.6411\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.9589 - val_loss: 100.1362\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.8259 - val_loss: 101.1599\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.0899 - val_loss: 101.2122\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.0887 - val_loss: 101.4096\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.0581 - val_loss: 105.1156\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.4208 - val_loss: 98.6637\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.2571 - val_loss: 100.2933\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.3604 - val_loss: 98.7251\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 1.9381 - val_loss: 106.1790\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 3.0586 - val_loss: 100.5417\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 2.5432 - val_loss: 98.3968\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 2.9613 - val_loss: 112.7562\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 3.1616 - val_loss: 97.4599\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.7890 - val_loss: 100.6945\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 3.6274 - val_loss: 100.0633\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.3021 - val_loss: 103.0317\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 11.9072 - val_loss: 103.1687\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 3.6976 - val_loss: 99.4575\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.8586 - val_loss: 103.7208\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.0509 - val_loss: 101.1568\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.8803 - val_loss: 101.1052\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.6123 - val_loss: 101.6453\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.2927 - val_loss: 101.0596\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.2041 - val_loss: 100.8757\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1551 - val_loss: 99.8845\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.2990 - val_loss: 99.3250\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1788 - val_loss: 100.0687\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1441 - val_loss: 100.5216\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1653 - val_loss: 100.2351\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3132 - val_loss: 103.2804\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.1798 - val_loss: 97.7651\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.7843 - val_loss: 103.0040\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.8428 - val_loss: 100.5906\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 7.5778 - val_loss: 102.1406\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 3.8667 - val_loss: 101.7141\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 3.2177 - val_loss: 101.7619\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.9755 - val_loss: 101.7266\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.9519 - val_loss: 98.4244\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.8551 - val_loss: 99.8817\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.7329 - val_loss: 106.4493\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.5331 - val_loss: 100.0653\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.3208 - val_loss: 100.1272\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.8416 - val_loss: 101.0197\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.0112 - val_loss: 101.1882\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.8812 - val_loss: 101.6801\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.7260 - val_loss: 99.1596\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.4763 - val_loss: 101.0223\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.2565 - val_loss: 102.1823\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2436 - val_loss: 100.2782\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.1253 - val_loss: 100.1037\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1278 - val_loss: 101.2991\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1651 - val_loss: 101.9510\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.2443 - val_loss: 102.6991\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1929 - val_loss: 101.3565\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.1705 - val_loss: 101.1787\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.0903 - val_loss: 100.2306\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3637 - val_loss: 99.7304\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.6712 - val_loss: 99.6154\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 4.5853 - val_loss: 103.5511\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 12.0659 - val_loss: 96.3310\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 6.3591 - val_loss: 101.7923\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.7787 - val_loss: 99.5573\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 3.5729 - val_loss: 100.6906\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 3.5238 - val_loss: 107.1532\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.9643 - val_loss: 104.6122\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.5210 - val_loss: 101.0434\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.3880 - val_loss: 98.7957\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.0834 - val_loss: 100.1284\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.3494 - val_loss: 99.5690\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.4178 - val_loss: 99.7305\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2124 - val_loss: 101.8982\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.5043 - val_loss: 99.2682\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4510 - val_loss: 99.9468\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.2037 - val_loss: 99.9987\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1672 - val_loss: 99.9866\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.0679 - val_loss: 100.5635\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.1555 - val_loss: 99.4618\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.1926 - val_loss: 100.4730\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2024 - val_loss: 101.7598\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3567 - val_loss: 103.5632\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.6253 - val_loss: 99.5315\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.5619 - val_loss: 97.6177\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 1.0986 - val_loss: 99.0075\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.9763 - val_loss: 98.7441\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 3.3297 - val_loss: 114.7577\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 6.0406 - val_loss: 102.5043\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 4.8781 - val_loss: 118.4403\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 6.3357 - val_loss: 100.3228\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 4.3785 - val_loss: 104.1043\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.6724 - val_loss: 96.6328\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.2297 - val_loss: 98.0422\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.2576 - val_loss: 99.3398\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0868 - val_loss: 100.3905\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.8754 - val_loss: 104.2581\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.5552 - val_loss: 100.0064\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.6416 - val_loss: 98.9210\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.4725 - val_loss: 106.0047\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 1.0987 - val_loss: 104.4891\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.8436 - val_loss: 101.7371\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.3961 - val_loss: 99.3037\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2622 - val_loss: 100.9288\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1268 - val_loss: 99.0290\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.2764 - val_loss: 100.7487\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2541 - val_loss: 98.7595\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1953 - val_loss: 98.7129\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2105 - val_loss: 100.3591\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.3767 - val_loss: 101.5236\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.5798 - val_loss: 101.0117\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.5315 - val_loss: 99.5881\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 1.1251 - val_loss: 99.0721\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 1.0232 - val_loss: 99.3559\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 2.4633 - val_loss: 101.7186\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 3.9594 - val_loss: 98.4034\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 6.6806 - val_loss: 104.2682\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 11.9793 - val_loss: 99.7609\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 5.0450 - val_loss: 97.3864\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.0446 - val_loss: 100.8780\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.9976 - val_loss: 100.0193\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6518 - val_loss: 99.1669\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3000 - val_loss: 99.8361\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3127 - val_loss: 103.7363\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3697 - val_loss: 100.3110\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.5186 - val_loss: 98.4461\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.9315 - val_loss: 99.0702\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2644 - val_loss: 99.4165\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1862 - val_loss: 99.4976\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3913 - val_loss: 99.9035\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.7762 - val_loss: 98.7197\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4885 - val_loss: 99.1167\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6434 - val_loss: 100.2639\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.4769 - val_loss: 102.4514\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.7872 - val_loss: 97.6441\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 3.1942 - val_loss: 106.9823\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.2234 - val_loss: 100.1059\n",
      "Epoch 427/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.9871 - val_loss: 103.2631\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4647 - val_loss: 100.0171\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.0699 - val_loss: 101.9253\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 11.0275 - val_loss: 107.2971\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 6.4902 - val_loss: 101.3774\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 2.7471 - val_loss: 98.9821\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.0373 - val_loss: 99.5419\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.2767 - val_loss: 100.1921\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.9121 - val_loss: 100.7959\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.5028 - val_loss: 100.8164\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.2925 - val_loss: 100.1928\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.2669 - val_loss: 99.7516\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1449 - val_loss: 100.9869\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0788 - val_loss: 99.5534\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.0639 - val_loss: 99.6073\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0471 - val_loss: 99.9630\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.0323 - val_loss: 99.8294\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 0s 69us/step - loss: 0.0345 - val_loss: 100.7137\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0252 - val_loss: 100.2429\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0301 - val_loss: 100.2402\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0473 - val_loss: 98.7016\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1038 - val_loss: 99.6596\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1457 - val_loss: 99.5722\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1886 - val_loss: 99.5859\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1641 - val_loss: 99.9694\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.5910 - val_loss: 101.2944\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.8175 - val_loss: 100.1430\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 4.3634 - val_loss: 106.2938\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 5.2991 - val_loss: 107.4821\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.0309 - val_loss: 108.6595\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.0250 - val_loss: 101.9688\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.1816 - val_loss: 99.9427\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.5698 - val_loss: 99.6618\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.8151 - val_loss: 98.3975\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5979 - val_loss: 98.6007\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3361 - val_loss: 102.1446\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3820 - val_loss: 99.1774\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4309 - val_loss: 99.5366\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.4115 - val_loss: 99.9477\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.4036 - val_loss: 98.4508\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.7193 - val_loss: 97.3314\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.9571 - val_loss: 99.4756\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 3.1867 - val_loss: 101.2626\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 7.1190 - val_loss: 101.3796\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 3.3825 - val_loss: 99.8231\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 3.3852 - val_loss: 102.3417\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.6947 - val_loss: 99.1375\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.8645 - val_loss: 103.7570\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0901 - val_loss: 103.4377\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.4827 - val_loss: 101.4391\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.6764 - val_loss: 98.7019\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.4923 - val_loss: 99.8684\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.8103 - val_loss: 103.3932\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.4499 - val_loss: 99.7303\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.2102 - val_loss: 100.1118\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1511 - val_loss: 100.3922\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1591 - val_loss: 100.5188\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0830 - val_loss: 99.6961\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.0951 - val_loss: 100.5147\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.2226 - val_loss: 101.6154\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1935 - val_loss: 100.7951\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.4421 - val_loss: 97.3862\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.6375 - val_loss: 98.6054\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.1848 - val_loss: 103.1236\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 3.9012 - val_loss: 103.8091\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 4.5884 - val_loss: 99.2087\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 1.4187 - val_loss: 98.5212\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 1.4603 - val_loss: 103.9060\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.8682 - val_loss: 101.4496\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.6625 - val_loss: 98.4137\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.8414 - val_loss: 98.5578\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.5923 - val_loss: 98.1812\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4131 - val_loss: 99.3760\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.4835 - val_loss: 98.1375\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.4950 - val_loss: 100.4137\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.3589 - val_loss: 99.8280\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2977 - val_loss: 98.6397\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.4954 - val_loss: 101.0178\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.3538 - val_loss: 99.0098\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 1.2491 - val_loss: 102.6413\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.8368 - val_loss: 100.2452\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.7289 - val_loss: 99.3139\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.7666 - val_loss: 102.6757\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.7039 - val_loss: 102.1363\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.9072 - val_loss: 99.1860\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4115 - val_loss: 104.0140\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.6565 - val_loss: 98.8657\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.6854 - val_loss: 104.6287\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 3.1926 - val_loss: 102.4717\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 2.9272 - val_loss: 118.9883\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 6.5055 - val_loss: 102.1212\n",
      "Epoch 518/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 3.4636 - val_loss: 100.1225\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 2.3374 - val_loss: 100.2993\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.1194 - val_loss: 101.7273\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.4688 - val_loss: 100.1792\n",
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.4684 - val_loss: 98.2153\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 1.2989 - val_loss: 101.7913\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.1808 - val_loss: 105.8259\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.7049 - val_loss: 101.0294\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.3588 - val_loss: 100.9649\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.1769 - val_loss: 100.4602\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.1874 - val_loss: 99.3287\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.1597 - val_loss: 100.3292\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.0861 - val_loss: 99.9711\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.0479 - val_loss: 100.9270\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.1985 - val_loss: 102.2338\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.4428 - val_loss: 105.1405\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.7153 - val_loss: 102.9374\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 3.1164 - val_loss: 126.8798\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 4.7091 - val_loss: 100.5528\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 2.8290 - val_loss: 96.8165\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 2.4936 - val_loss: 99.4516\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 1.2235 - val_loss: 98.1558\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.0473 - val_loss: 102.9384\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 1.3290 - val_loss: 99.8786\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.4694 - val_loss: 100.4355\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.4456 - val_loss: 102.7133\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.7354 - val_loss: 104.6542\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.3851 - val_loss: 100.1289\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.2002 - val_loss: 101.2856\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1104 - val_loss: 101.7894\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.1221 - val_loss: 100.8510\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1517 - val_loss: 100.3298\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 1.0603 - val_loss: 97.9682\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 2.8605 - val_loss: 103.3792\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.2647 - val_loss: 97.6617\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 1.3155 - val_loss: 98.2829\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.0132 - val_loss: 99.2229\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.9511 - val_loss: 99.9500\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 1.0170 - val_loss: 99.0527\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.7532 - val_loss: 101.5018\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 1.3616 - val_loss: 101.5002\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.8920 - val_loss: 105.1424\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.5054 - val_loss: 100.0469\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.4496 - val_loss: 98.2441\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.4944 - val_loss: 99.5090\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.4968 - val_loss: 100.4431\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.3188 - val_loss: 99.0573\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.5778 - val_loss: 101.9768\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.4013 - val_loss: 102.7901\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.6775 - val_loss: 102.2470\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.7774 - val_loss: 99.7321\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 2.1844 - val_loss: 103.7094\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.2807 - val_loss: 102.0199\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.7540 - val_loss: 100.4195\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.8431 - val_loss: 99.3748\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 1.0470 - val_loss: 100.1012\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.7029 - val_loss: 100.1119\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 2.1125 - val_loss: 104.8663\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 5.1204 - val_loss: 98.6408\n",
      "Epoch 577/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 91us/step - loss: 5.7027 - val_loss: 121.2083\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 4.6930 - val_loss: 103.9313\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 1.8946 - val_loss: 109.2161\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 1.4299 - val_loss: 99.1113\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 1.8147 - val_loss: 98.5960\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.3696 - val_loss: 103.0613\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.7857 - val_loss: 99.6340\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.9756 - val_loss: 103.1294\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.4876 - val_loss: 100.4689\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.2428 - val_loss: 102.0354\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.2483 - val_loss: 101.5222\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.1495 - val_loss: 100.8467\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1161 - val_loss: 101.6428\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.2092 - val_loss: 100.6996\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1640 - val_loss: 102.3319\n",
      "Epoch 592/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.1588 - val_loss: 99.8025\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0873 - val_loss: 101.0290\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0690 - val_loss: 100.4439\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.0539 - val_loss: 101.0889\n",
      "Epoch 596/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1070 - val_loss: 100.3224\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0836 - val_loss: 100.5063\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1295 - val_loss: 100.1801\n",
      "Epoch 599/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1541 - val_loss: 100.9034\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.1733 - val_loss: 100.4439\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.4258 - val_loss: 104.5669\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.5464 - val_loss: 99.8903\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.0415 - val_loss: 100.3703\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.5322 - val_loss: 99.6836\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 2.0183 - val_loss: 98.2682\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 4.3565 - val_loss: 105.7741\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 3.0362 - val_loss: 112.7417\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 3.4688 - val_loss: 101.8175\n",
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.2906 - val_loss: 100.2054\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.8489 - val_loss: 101.5323\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.6786 - val_loss: 100.7567\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.9873 - val_loss: 98.4735\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.0624 - val_loss: 101.5807\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.4784 - val_loss: 102.6307\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.0086 - val_loss: 109.6332\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 1.6982 - val_loss: 99.9177\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.8829 - val_loss: 102.8927\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 1.0077 - val_loss: 99.5263\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.4133 - val_loss: 100.3163\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.2770 - val_loss: 99.1113\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.3794 - val_loss: 100.8487\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.2911 - val_loss: 98.9798\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.2630 - val_loss: 101.6679\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.1901 - val_loss: 99.5550\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0918 - val_loss: 99.8246\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.0806 - val_loss: 99.7753\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0507 - val_loss: 99.7476\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0657 - val_loss: 99.5136\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0476 - val_loss: 101.1473\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.0738 - val_loss: 99.5043\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.1423 - val_loss: 100.2353\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1284 - val_loss: 99.8416\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.3665 - val_loss: 99.5807\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.9271 - val_loss: 101.9374\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.8645 - val_loss: 98.7045\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.8752 - val_loss: 97.8617\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.0207 - val_loss: 101.5894\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.9082 - val_loss: 98.7199\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 3.4484 - val_loss: 96.8958\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 9.2025 - val_loss: 97.7910\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 2.4293 - val_loss: 101.6953\n",
      "Epoch 642/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 1.0649 - val_loss: 100.6028\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.6192 - val_loss: 101.0629\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.5520 - val_loss: 103.3925\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.5529 - val_loss: 101.9451\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.2587 - val_loss: 102.1187\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.2677 - val_loss: 100.2259\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.4229 - val_loss: 101.0538\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.3886 - val_loss: 99.8918\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.3426 - val_loss: 99.1457\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.8238 - val_loss: 100.4035\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.1981 - val_loss: 99.4146\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.8848 - val_loss: 99.2083\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.9350 - val_loss: 99.4140\n",
      "Epoch 655/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.4221 - val_loss: 99.8242\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.5516 - val_loss: 97.6187\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.5986 - val_loss: 101.1969\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 1.2473 - val_loss: 96.0016\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.9021 - val_loss: 101.3329\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.5029 - val_loss: 100.5348\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.3957 - val_loss: 100.1357\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.2428 - val_loss: 99.7462\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2078 - val_loss: 100.2069\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.1307 - val_loss: 100.4209\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.3377 - val_loss: 99.6473\n",
      "Epoch 666/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.6130 - val_loss: 107.2957\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.8887 - val_loss: 102.5157\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 1.2153 - val_loss: 99.8238\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 3.8639 - val_loss: 100.5657\n",
      "Epoch 670/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 9.4292 - val_loss: 105.3722\n",
      "Epoch 671/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 3.1998 - val_loss: 101.6452\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 2.4170 - val_loss: 100.5935\n",
      "Epoch 673/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.9827 - val_loss: 101.0245\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.6031 - val_loss: 104.6057\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.3915 - val_loss: 101.6927\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2230 - val_loss: 101.1623\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1275 - val_loss: 101.4925\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1201 - val_loss: 99.7590\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1103 - val_loss: 101.5660\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0472 - val_loss: 100.7651\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0413 - val_loss: 100.9796\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0266 - val_loss: 100.2795\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0265 - val_loss: 101.1543\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0221 - val_loss: 100.8036\n",
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.0182 - val_loss: 101.2300\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.0168 - val_loss: 101.0041\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0144 - val_loss: 101.1429\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0401 - val_loss: 101.5190\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.0674 - val_loss: 101.0549\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.0615 - val_loss: 101.2907\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0640 - val_loss: 101.5594\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.0975 - val_loss: 101.5549\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2457 - val_loss: 99.3648\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.3039 - val_loss: 100.2875\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.5237 - val_loss: 102.1908\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.0190 - val_loss: 105.1286\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.9951 - val_loss: 100.9322\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.9023 - val_loss: 101.2143\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 2.6022 - val_loss: 105.3315\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 3.2083 - val_loss: 102.9630\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 2.5590 - val_loss: 99.2151\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 1.2023 - val_loss: 104.9998\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.7555 - val_loss: 102.2635\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.4830 - val_loss: 100.9167\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 0s 66us/step - loss: 0.6555 - val_loss: 103.3313\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 1.0729 - val_loss: 102.1959\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.9864 - val_loss: 104.9592\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.9628 - val_loss: 102.9805\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.8801 - val_loss: 98.0971\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6219 - val_loss: 101.1599\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.2731 - val_loss: 101.4617\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3101 - val_loss: 101.7032\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5461 - val_loss: 98.6677\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4163 - val_loss: 100.7670\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3778 - val_loss: 99.2044\n",
      "Epoch 716/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.3250 - val_loss: 99.4423\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2660 - val_loss: 100.7556\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2310 - val_loss: 101.5534\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.4187 - val_loss: 101.6065\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.8409 - val_loss: 98.3045\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.7285 - val_loss: 101.6630\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.7897 - val_loss: 101.6819\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.5433 - val_loss: 99.7637\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3618 - val_loss: 101.2667\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2167 - val_loss: 100.9405\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3466 - val_loss: 102.3662\n",
      "Epoch 727/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2953 - val_loss: 100.0013\n",
      "Epoch 728/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4656 - val_loss: 101.8264\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.4046 - val_loss: 99.5940\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.9816 - val_loss: 100.2123\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.8022 - val_loss: 98.5173\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.6486 - val_loss: 99.3709\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.3209 - val_loss: 108.4650\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 6.9638 - val_loss: 104.4423\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 3.2237 - val_loss: 100.8282\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.0345 - val_loss: 106.6416\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.2959 - val_loss: 104.8082\n",
      "Epoch 738/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.7247 - val_loss: 102.6787\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4226 - val_loss: 103.3418\n",
      "Epoch 740/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2854 - val_loss: 101.5093\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4394 - val_loss: 101.8138\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2824 - val_loss: 101.2508\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1860 - val_loss: 100.9843\n",
      "Epoch 744/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0851 - val_loss: 100.9783\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0528 - val_loss: 101.4708\n",
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0414 - val_loss: 100.7363\n",
      "Epoch 747/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0299 - val_loss: 101.4654\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0173 - val_loss: 101.7073\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0180 - val_loss: 100.8634\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0111 - val_loss: 100.9718\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0240 - val_loss: 101.3515\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.1083 - val_loss: 102.1150\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1046 - val_loss: 101.9476\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1224 - val_loss: 99.8077\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3323 - val_loss: 103.2154\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2505 - val_loss: 101.5530\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2545 - val_loss: 100.1974\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0356 - val_loss: 104.7962\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.1906 - val_loss: 101.6665\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.9483 - val_loss: 104.6146\n",
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.1825 - val_loss: 103.0280\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.8107 - val_loss: 105.7229\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.8244 - val_loss: 103.0910\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.4902 - val_loss: 102.1836\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5784 - val_loss: 100.2095\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.7557 - val_loss: 99.7066\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.6022 - val_loss: 101.3807\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.0559 - val_loss: 106.6350\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0662 - val_loss: 100.1449\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.1777 - val_loss: 113.2496\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.0671 - val_loss: 101.0325\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.8749 - val_loss: 101.2732\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.7565 - val_loss: 98.5755\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0484 - val_loss: 99.8425\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.8446 - val_loss: 101.2558\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.7050 - val_loss: 103.7878\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0250 - val_loss: 99.0412\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.1026 - val_loss: 100.2332\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.5554 - val_loss: 100.8318\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4217 - val_loss: 101.7509\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3159 - val_loss: 100.0537\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3218 - val_loss: 101.7416\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1833 - val_loss: 99.7430\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1507 - val_loss: 102.9361\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.9073 - val_loss: 97.5569\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.8739 - val_loss: 98.4527\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.3001 - val_loss: 102.6252\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.7040 - val_loss: 100.9913\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.5050 - val_loss: 99.7396\n",
      "Epoch 790/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4486 - val_loss: 101.6709\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3355 - val_loss: 100.3066\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3461 - val_loss: 102.8818\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.7196 - val_loss: 100.2913\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.4972 - val_loss: 101.1244\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.5131 - val_loss: 99.4297\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.8022 - val_loss: 101.3005\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 4.1753 - val_loss: 102.6485\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.5273 - val_loss: 99.3040\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.2561 - val_loss: 100.6316\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.0076 - val_loss: 98.9836\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4924 - val_loss: 101.5874\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4940 - val_loss: 101.2800\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2768 - val_loss: 100.5196\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4564 - val_loss: 103.8965\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2597 - val_loss: 100.5391\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2516 - val_loss: 102.6229\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1997 - val_loss: 100.5589\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0949 - val_loss: 101.4437\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0592 - val_loss: 101.5642\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1584 - val_loss: 100.7321\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1449 - val_loss: 101.3004\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0756 - val_loss: 100.6670\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1167 - val_loss: 101.3331\n",
      "Epoch 814/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3049 - val_loss: 100.8842\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2600 - val_loss: 103.5973\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2894 - val_loss: 100.1489\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.2207 - val_loss: 102.6310\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3134 - val_loss: 101.1103\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.6063 - val_loss: 104.3243\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4443 - val_loss: 100.4169\n",
      "Epoch 821/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.4756 - val_loss: 100.3140\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.9760 - val_loss: 104.9380\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.9929 - val_loss: 97.0776\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.1543 - val_loss: 101.1288\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.9034 - val_loss: 103.9669\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.5945 - val_loss: 100.6737\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.9205 - val_loss: 100.8514\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.3381 - val_loss: 101.5512\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.9293 - val_loss: 109.0095\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 4.9833 - val_loss: 110.6864\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 3.4666 - val_loss: 102.0927\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.6376 - val_loss: 105.6002\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.8326 - val_loss: 102.6092\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.3986 - val_loss: 103.8258\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 0.6355 - val_loss: 100.0352\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.4091 - val_loss: 100.8412\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3312 - val_loss: 101.7490\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.2282 - val_loss: 103.0748\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1584 - val_loss: 101.8284\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0562 - val_loss: 102.2884\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0552 - val_loss: 102.4355\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0511 - val_loss: 101.9584\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0534 - val_loss: 102.1670\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0308 - val_loss: 102.1754\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0879 - val_loss: 101.6667\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0667 - val_loss: 102.7033\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1148 - val_loss: 102.4900\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0528 - val_loss: 101.6110\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0586 - val_loss: 101.4984\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.0575 - val_loss: 101.8787\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.0475 - val_loss: 102.6797\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0550 - val_loss: 102.2854\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0633 - val_loss: 101.4273\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0388 - val_loss: 103.5015\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0730 - val_loss: 102.7485\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0852 - val_loss: 100.5758\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2992 - val_loss: 102.3386\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.6954 - val_loss: 98.9198\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.8012 - val_loss: 100.9093\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.5105 - val_loss: 102.4356\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.2703 - val_loss: 100.8388\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.8816 - val_loss: 105.3672\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 7.9475 - val_loss: 106.7434\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.9023 - val_loss: 100.8363\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.6934 - val_loss: 104.4112\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8750 - val_loss: 104.4241\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4071 - val_loss: 103.0321\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3338 - val_loss: 100.9905\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1777 - val_loss: 100.7503\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1479 - val_loss: 100.3090\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.1171 - val_loss: 102.9417\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0814 - val_loss: 101.1183\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0538 - val_loss: 101.2094\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0542 - val_loss: 102.3798\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0374 - val_loss: 102.3656\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0431 - val_loss: 101.7215\n",
      "Epoch 877/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0326 - val_loss: 102.2792\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0333 - val_loss: 100.6219\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.0513 - val_loss: 102.0211\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0253 - val_loss: 101.8886\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0133 - val_loss: 101.7873\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0156 - val_loss: 101.8185\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0176 - val_loss: 101.8146\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0173 - val_loss: 101.9152\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0282 - val_loss: 101.0126\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0537 - val_loss: 102.0993\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0750 - val_loss: 101.4841\n",
      "Epoch 888/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2550 - val_loss: 102.2847\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4836 - val_loss: 100.0828\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.0767 - val_loss: 112.2167\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 6.6398 - val_loss: 110.1734\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 2.1752 - val_loss: 97.2579\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.8841 - val_loss: 103.2156\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6372 - val_loss: 102.0469\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4644 - val_loss: 101.3388\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2871 - val_loss: 103.4024\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.2006 - val_loss: 100.8715\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1529 - val_loss: 102.8781\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1029 - val_loss: 103.0913\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2516 - val_loss: 104.4271\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2841 - val_loss: 100.1010\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2045 - val_loss: 103.5218\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1715 - val_loss: 102.2111\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3189 - val_loss: 103.8045\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.2169 - val_loss: 105.3029\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2698 - val_loss: 102.3540\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3197 - val_loss: 101.3490\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3975 - val_loss: 107.8677\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5711 - val_loss: 102.4667\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.1942 - val_loss: 97.3232\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.8960 - val_loss: 100.9515\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.6152 - val_loss: 105.6594\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.6401 - val_loss: 104.1214\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.6339 - val_loss: 105.9429\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5845 - val_loss: 102.1223\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.3622 - val_loss: 101.2927\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3350 - val_loss: 103.6759\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3714 - val_loss: 106.6580\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.1558 - val_loss: 100.5563\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 4.7264 - val_loss: 99.6196\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.8895 - val_loss: 107.8652\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.5866 - val_loss: 99.0388\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.1296 - val_loss: 103.0413\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.5713 - val_loss: 101.8507\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3866 - val_loss: 103.9272\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1715 - val_loss: 101.8216\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1772 - val_loss: 101.4284\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2479 - val_loss: 103.0784\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1157 - val_loss: 103.0982\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0927 - val_loss: 101.6464\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1905 - val_loss: 101.6476\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1734 - val_loss: 103.5792\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2709 - val_loss: 105.6504\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3530 - val_loss: 103.3155\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2304 - val_loss: 101.2747\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2936 - val_loss: 101.6916\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.5599 - val_loss: 103.2734\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.6309 - val_loss: 101.0444\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5212 - val_loss: 100.4232\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.4179 - val_loss: 101.7993\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.8727 - val_loss: 99.6709\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.7217 - val_loss: 104.2263\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.3204 - val_loss: 101.3820\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.0384 - val_loss: 100.9415\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.6355 - val_loss: 99.9387\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.8620 - val_loss: 99.8543\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.8147 - val_loss: 104.6317\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4978 - val_loss: 104.1106\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3961 - val_loss: 102.5444\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2519 - val_loss: 102.1304\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3091 - val_loss: 103.3718\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2985 - val_loss: 102.7022\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1691 - val_loss: 101.3636\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1433 - val_loss: 103.3026\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1370 - val_loss: 101.9499\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1802 - val_loss: 101.5098\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1754 - val_loss: 102.4281\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1271 - val_loss: 103.0590\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1709 - val_loss: 100.9363\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1900 - val_loss: 100.5801\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2807 - val_loss: 100.4223\n",
      "Epoch 962/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4443 - val_loss: 100.9904\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.6607 - val_loss: 105.1696\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.7956 - val_loss: 103.9370\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.2319 - val_loss: 101.7589\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.2695 - val_loss: 100.7323\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.8906 - val_loss: 106.5263\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.8567 - val_loss: 101.0240\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.2468 - val_loss: 106.4377\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.5526 - val_loss: 102.3687\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.8166 - val_loss: 103.4976\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.5960 - val_loss: 103.3325\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.3828 - val_loss: 99.3674\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.7042 - val_loss: 106.7188\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.5895 - val_loss: 102.5513\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.2192 - val_loss: 102.1207\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1333 - val_loss: 100.8670\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1245 - val_loss: 101.4367\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0631 - val_loss: 101.2432\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0359 - val_loss: 101.5189\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0277 - val_loss: 101.0820\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0233 - val_loss: 101.0318\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0383 - val_loss: 101.5859\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0821 - val_loss: 103.1853\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.2403 - val_loss: 101.1984\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2042 - val_loss: 100.7634\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.2741 - val_loss: 102.6982\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2065 - val_loss: 101.1055\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1725 - val_loss: 100.0152\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.3296 - val_loss: 100.2060\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 2.7654 - val_loss: 103.0380\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.4797 - val_loss: 101.2763\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.8129 - val_loss: 103.1613\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.5635 - val_loss: 100.8306\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3562 - val_loss: 105.1963\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.4871 - val_loss: 101.4138\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2657 - val_loss: 100.5675\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2091 - val_loss: 102.8198\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3637 - val_loss: 106.3643\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.3860 - val_loss: 101.7741\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 53us/step\n",
      "120.52575592041016\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAJPCAYAAABcoIE1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi41LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvSM8oowAAIABJREFUeJzs3Xm8JFV58PHfM6zKsIsioCCIIhhBY3ALiAoqSTQaxRiNgAZN4mtiYmLiEgVcI6Ix7vGNOqgoStzNi4jLKOCGu6IsETGyDCr7DKDinPePc642TVd3V92q7uqZ3/fzuZ+5t6v61Kl66lSfPlXPnEgpIUmSpHpWzLsCkiRJi8hOlCRJUgN2oiRJkhqwEyVJktSAnShJkqQG7ERJkiQ1YCdKkiSpgd53oiLi4oi4MSLWRsSaiFgVESvHrL9DRLw/Iq6MiJ9HxMkRsU1FeWsj4lNjyloVEb8s610VEWdExD4V624REW+NiCvKuh+PiF0Hlr8nIi6PiOsi4oKIOGbCfv992d/rIuIdEbHF+CO1GBrE89yBWK2NiJsj4uMDyx8aEd8ox+miiHjGmLKOi4hflXKuiYgvRsQDKtaNiHhZRFwaEddGxOqI2G9onUPLttdFxCUR8YQx235SRPy4rPuRiNhh/JHqhwbxOjEiLoyI6yPivIg4cmh5KsdgKZ7/ObBsMD5LP3tWbOeQiFhf1rk+Is6PiKdWrHv/0navioifRcSpEXHHgeV/X86d6yLisoj4t4jYdEQ5Dy71f9mY/d+itNfryvF6TtW6szbjWD4kIj5X2s7FE+q1RylrqZyLI+J5FeveLSI+WuJ4VUScHhF3r1j3M6XcTQdeOyAiziz1uiQiXjSmXkdFxNdLLC+JiBNGnRfz0iCeTyjXvBsiYvWY9Y4sx+2YgdemaiNl3anjWdZ/W2m/6yPi6KFlR0fEr4euCYcMbetzZZ/Oi4hDl7v/taWUev0DXAwcWn7fGfg28PIx678Z+BSwDbAt8GngtaPKm2Lbq4CXld9vC5wMfLli3X8qdbsDsCXwLuBDA8v3A7Yov+8DrAF+t6KsRwBXlPdsD6wG/nXesZhHPIfeG8CPgCPL35sB1wJ/WZb9HrAW2L/i/ccB7xl47wnA5UCMWPcJwGXAnsAmwCuBbwws3xf4KXA4sCmwI7BXxXb3A64HDgZWAu8FTpl3LLqIF3B8Ob9XAPcDrgYeOLA8AXedFJ8p6nUIcMnAefEY4GZg3xHrHg4cUa4JtwXeAXxyYPlewHbl9x2AzwLPGSpjM+BbwJeXrgkV9XolcGZpt/co7fyR847jHGJ5IPAU4BnAxRPqtUcpa9Py9wOAG0Ydt1LuX5Q4bQa8FDhvxHpPBr4wWG55/fvAy0ub3ovc/h9dUa+/Bg4CNgd2Bb4OPG/ecVxGPA8lX9deDKyuWGd74Dzge8AxddpIk3iW5f8HeBjwNeDooWVHA2eN2acvAa8FbgM8DrgG2Knp/jf56f1I1KCU0hrgdOCAMavdBfhISum6lNK1wIfJH2LL3fYN5A+/e47Z7ukppStSSjcB7x/cbkrp3JTSL5b+LD97VZR1FPD28p6ryReKo5e7D30zZTwHHQzcDvhg+XsH8gfju1N2DvADcgdn0rZ/BZxEvvjsOGKVu5Ab70UppV8D7xkq91+A/0gpnZZSujmldGVK6YcVm3sy8PGU0hdSSmuBFwF/EhFbT6pnn0wTr5TSsSml81JK61NKXyF3KEaO9rVYr5RS+gj5Q/5WsS8xOrVcE24A3gg8aGD5D1NK15Q/A1gP3HWomH8gfzk7b0J1jgJemlK6OqX0A+D/0sO223UsU0pfTSm9G7ioQd2+BJzLiGttKfftKaWrShv+N+DuEfGbNhwR2wLHkr/YDtsDODml9OvSXs+i4vMhpfSWlNKZKaVfppQuJX+JftCodedtynh+OqX0AfKXwyqvBF4P/HzovdO0kartVsazLH9TSukzwE3TlLckIu4G3Ac4NqV0Y0rpg8B3yZ2pUduZZv9rW6hOVETsRv5W+T9jVnsT8EcRsX1EbE8+oKcNrXNyGQ7+VETsP+W2V5I/DL9ZscrbgQdFxC4Rcduy7i22GxFvjogbyBfiy4H/V1HWfuRvFUu+Ddxh8EKxIZgynoOOAj6YUloHkFK6Angf8NSI2CTyrbndyRfGSdvegvzh9pOU0s9HrHIKsFe5fbBZ2fYnB5bfv5Tz3ci3ad8T1bfobhHPcvH+JXC3SfXsk7rxiojbkEcHzx1a9IVy++FDEbHH0LJHlds050bEX0+5nRUR8VhgO/JFdJKDh+sU+XbrdeQPj/2B/xhYtjvwNOAlE+qxPXBHbt12l/0lrm0zimWTekVEPIh8zKqutYMOBtaklK4ceO0VwFvIo4DDXgccGRGblduADyDfrZjGrc6bvmhwLR1VxoHAfYG3ViyvbCNjyqwbz1HuHfnRnAsi4kUDtxH3Ay5KKV0/sO7s21tbQ1pd/ZCHLNeSb4ck4DOUYcWK9XchN4r15ecMYPOB5Q8iD/3dFng+uaGNLI98O+8m8hDhGuBjVN+y2Zb8wZvItxW+CewwYr1NgN8nj2RsVlHWDxkY+iQPWydgj3nHY9bxHHjfbYHrgEOGXn8U+dbnzeXn6WPKOI7cebmGfCvus1TfUt0c+PeBeP4IuMvA8l+Wfbkb+RbdB8nfcEeV9Rngr4Zeu3R4X/r40zRe5b0nkTueMfDaweXYbkceEfoevx3237e0302AB5K/aPxZRdmHlPZ9DXAV+VbbE6eo073K+gdVLN+bPPK788BrHwX+tPy+iorbecCdyjHacuC1w5hwO2tDjOXAOodO2n9+e/vnGvJo4g+Av52iTruVdvRnA6/dt5wLmzJ0W6ksfyC5o3FzWXb8lPv/NOAS4HbzjuNy4wkcw9DtrNLmvgbcv/y9moHbeUPr3qqNtBTPs7j17bw9yXcFVgC/Q74d+/yy7CkMPV5DvlW7qu7+L+dnUUaiHpNS2pp84dyHfEunygeAC4Ctybd6fki+FQNASunslIf+bkgpvZIc6IPGlHdiSmm7lNLOKaVHp+pbNm8CtiDfGtoK+BC3HgEj5WHks8gXgKpv2mtL3Zcs/X79iHUXUZ14LvkT8off55deiPyQ/ynAkeSL+X7AP0XEH44p5wMlnrdPKT00pfT1ivVeTP7mfSfyM27HA58to4wANwLvTCldkPItulcAf1BR1nA8KX8vSjxrxysiXk0evn9CKlcugJRvaf4y5VsDzyZfIO9Rln0/pXRZaSNfJHdiHz9mM5eVWO6QUjogpXTKhDrdldwmn51SOnPUOimlC8mjDW8u73kUsHVK6f2T9pkcZ7h12+1TnGcSy4Zul1LaPqV0j5TS6yfUaSfy7dU3p5TeV15bQY7bs1NKN494zw7kjuBLyG36TsAjIuKZE7b1GPJtrsPT6FHreWpyLR3lmcB3UkpfnrTicBsZY+p4jtnWRSmlH6V8S/m75NgtXRN6cV1dlE4UACmlz5O/CZ44ZrUDyM+qrCsfbm+l+sMNco85WqjeAeQe8FUpP/v0BuDAiKg6qTel+pmoc8nDpUv2B65ItxyyXnhTxnPJUcC7Bi/i5Av7BSml00sjOx/4b/Kw9nIdALw/pXRJys88rSI/dLn0zM13yOfOkkS1W8QzcsbZFuTO/sKYNl4RcTw5Bg9PKV03qViq219bbXPpltynyc8rvXvC6oNt82HAfcstqzXAnwJ/FxEfvVVl8/OLl3Prttu7W0BziGVrym3TTwEfSym9fGDRNuSRqPeXWJ1TXr8kIg4ij2r8OqX0rtKmLyF/Cav8fIiIR5Kfa3tU+RDvpZrX0lEeBjx24Dx/IPCaiHhjxfrjPr+6NHiOnQvsOfRs6ezbW1tDWl39MJRNB+wErKM6A+tz5A7MbcrPm4EvlmV3Jt/O25z8TeS5wM+AHSvKWsWYTJyhdd9JvqWzLfn22wuAS8uy2wNPJN/22YScfbeO6qyQR5JvH+5LHir/LBtgdt408Szr7EYeft9r6PW9yN9GHkpuWHuRh+qfUVHOcUyf/XUseXj5DuQvG08p9VzKUHka+RbfnuRbjR8gP+A+qqz9yLciDyKPUr6HBczOmyZe5FvkFzJiqL8chwNKG1hJfj7lfMptbeCPyR3VIGdhXQocVbGdQyjZeVPsw67kEel/rFh+DHD78vu+5Ivwa8vfW5OTD5Z+3k9+mPlWt+rL+v9KHi3dnjwycDk9zM6bQSxXkK+xhwM/Lr9vXrGdPRi67TZmH7YBvgq8ccSyGIrV75VydyVf87ch33l4UqnfzuTsrldUbOuhwJXAwfOOXUvx3KTE4a/ImYtbDsRru6Fj90XgOcC2k9rIcuJZ1l/6PD4beHr5fUVZdjhwh/L7PuRbxscOvPfL5I7jlsBjGZ+dV7n/y4rDvE+EuidKee0t5AeMR61/F+Dj5eS/ijx8u3dZth95BGFdWf4Z4L5jtr2K6TtRO5KzN35aAnkWcODAyf358vp15Idfnz7w3juTOwN3HnjtOeRnfa4jd9C2mHcs5hHPsvz5wJkVy55QGtb15GcWXrXUAEesexzTd6K2JN+ivbzE4BsMfRiSb/H9rPy8G9h+YNlaBp67IV+4/7ecex+l4kO4bz8N2l8CflH2f+nnBWXZQ8kftOtKO/nIUtssy99X2uVacvJF5XMU1OtEHVvqNVintQPL31na2rqyv69m4LmmobJucU0gJ5CcO/D3FuT/QuG6UubINPCNIJaH8Nss5KWf1RXb2YPpO1FHlXXXDdXrztOUW+p9Dvm/RllDHmW6bVl2i+sw+Qv5zUPbOW3ecVxGPI8eEZNVFeuu5pb/xUGdNjJ1PAe2NVyvQ8qyEwe2exH5dt5mQ9taTX684nxu2akcbptT73+dnyiFS5IkqYaFeiZKkiSpL+xESZIkNWAnSpIkqQE7UZIkSQ3YiZIkSWpg08mrtOewFUfUSgU8/bJvLXubj9hl2rlt29tm3e3W3WZV2VXlrNj5wtb/A7y6sVwEVcev7jnURtmzjCXA+jV714pnnXrX3ce22mzd7dbRVtmzbJttXds02qzbZpfXpSptnfdt1L1KW9eVM9afOlU8HYmSJElqwE6UJElSA3aiJEmSGrATJUmS1ICdKEmSpAZmmp23CLrMGoBuM2Sq6n7G+va31WVWR9cxqDKP7dbNJOkilk10eR73KdOnbtldZgR2pY06L+J+N9WXttlGO5lXJuw8Mu+rLLcujkRJkiQ1YCdKkiSpATtRkiRJDdiJkiRJasBOlCRJUgMzzc6r+2R/lxldbWUZtJW904Y+ZMIsQoZbl3O29el86FIb9Z5Xds2GnknW5fyf8zpG84hZX86Trq9jbdRlkS0329KRKEmSpAbsREmSJDVgJ0qSJKkBO1GSJEkN2ImSJElqYKbZeV1n0HVZl0XISujLnE6jzCOrp+tt1jkn2jr3Z60vGUrjtDVvV50Y9Wn/p7UIGW59Ot/6HuNFyISu0kbd55WVPcyRKEmSpAbsREmSJDVgJ0qSJKkBO1GSJEkNzPTB8rrmMUVK1w/rtTFViKZjLKfXpwd6+2Rj2P8uH/Ktu815lNP3c38eD/7XVbeObTwU3pe4ORIlSZLUgJ0oSZKkBuxESZIkNWAnSpIkqQE7UZIkSQ30OjuvyiJkRXU5tUQf9nXW/7V+k7rUVbfuo15vK7to1lP4tJXRsshTUfQlG2u5usxaamt6jw3lWM/CvDLo6ug6zvPI1J+WI1GSJEkN2ImSJElqwE6UJElSA3aiJEmSGrATJUmS1EAvsvPayIpqq+y29CGDrktdZkT1Kduurg0t7nWzbjakOcvGaSs7tatsyzp16PJ4tzFHWlsWtW12eQzbukZuiHGetm06EiVJktSAnShJkqQG7ERJkiQ1YCdKkiSpATtRkiRJDfQiO6/LjK55zfHWRvl9ziZpq26LMKdelXnMRdaVLuM5r2y7eWy3zxmHizx3WpU2MtHqmnWm5Tw+w7qO2zzmwutqm45ESZIkNWAnSpIkqQE7UZIkSQ3YiZIkSWrATpQkSVIDvcjOa8M85knT8nU5d16dbY6zMZ9D85hXrco8jncbcwRCP+bO61Ld49HWXGt11u9z5mSb6hyrRdn3NubkbKPsURyJkiRJasBOlCRJUgN2oiRJkhqwEyVJktSAnShJkqQGep2d18YcOPOaI28eZW8M2WKjeJz6reusqLbivyiZSpMscntoK2tvueuO22bftVHvtjLc2vr87XMsHImSJElqwE6UJElSA3aiJEmSGrATJUmS1ICdKEmSpAYipTSzjR224oiRG+tT1kSX2SFV2sqEqJ6f69SoXakJ1q/Ze2Qs+5xFsUiqYrxi5wtbjyVUx7PKPDJku26bbcwtVrcuXcSz7nW2jVjW1afYt1WXWbfNtuYZbKOMea1fp4y6pv3cdCRKkiSpATtRkiRJDdiJkiRJasBOlCRJUgN2oiRJkhroRXZel7qeO68NXdexi+y8LmPZt5j1qT5dxBLqx7PLeebaypZqQ9cxnmXbnEe2Yl3zyIJuKwOzq7bZVib0qP3sOkuyrXLm0cbNzpMkSeqQnShJkqQG7ERJkiQ1YCdKkiSpgU3nXQGYz39Tvwj69PDdtDbEONTRpymM6mgrbn16GLlKnfp0Pe1Ln9V5EHlRz/tFMI9Ei7599rRxvnRVR0eiJEmSGrATJUmS1ICdKEmSpAbsREmSJDVgJ0qSJKmBXmTnLfJ/X1+3/DrbbG86glrFdKLO8d4QpyLYWLKRuswMmoe6se9D3busQ1tl9+E4LdmQMiphPteato5hl9fUro6LI1GSJEkN2ImSJElqwE6UJElSA3aiJEmSGrATJUmS1MBMs/PmMR/PvOZya6P8Pmd0LcIceV3P59Xlvm4MmUFdz0vXxnVlEefOm0cdFmFOvUWM5TjzqEdb2+z7sa3DkShJkqQG7ERJkiQ1YCdKkiSpATtRkiRJDdiJkiRJaiBSSjPb2GErjpjdxiboOsugjq4z3c5Yf2q0UtCA9Wv2HhnLRTgefdtuHV3EEqrjOQ9dZ3rViXPX14ku4ln3OjuPjKi2Mi2rtDG/al19aZttZMi2Ne9olS7Ln/XnpiNRkiRJDdiJkiRJasBOlCRJUgN2oiRJkhqwEyVJktTATLPzJEmSNhSOREmSJDVgJ0qSJKkBO1GSJEkN9KITFREXR8SNEbE2ItZExKqIWDlm/SdExBcj4oaIWD1mvSMjIkXEMQOvPSQiPhcR10bExRPqtUd5/9ryc3FEPG/M+m+LiPMjYn1EHD1i+Z4R8YmIuD4ifh4RJwws2yEiPhwR6yLixxHxpDHbOS4ifjVQr7URsee4fZmVNmMZEQcN7ePaEo/HleVbRMS/RcRlEXF1RLw5IjYbs61Uju/aiLg0Il4bEZuMWO/2EfG+Uu61EXF2RNxvaJ0nlTiti4iPRMQOA8tWR8RNA3U+f4rjtnlE/CAiLpm07iy13TYj4qER8Y2IuC4iLoqIZwwse0hEfDciromIK0t72HXKul1RVbdynry9xOv6iPhWRBw+tM7DIuK8Uu/PRcTuA8tOjIgLy3vPi4gjx9QpIuKFEfG/ZR9PiYhtqtbvk7qxLu85tMRzXURcEhFPGFg29no4VM6qiPhl2fZVEXFGROwzZv37RMQXBmL/7IFln4uIn5Xj/+2I+OMJ264sq88atM3K8zgi7hYRHy3H7aqIOD0i7j6w/IklltdGxE8j4qRx53W0dK2NiDtGxMfK8hQRewy9/4SI+EmJ9Y8j4gUTjtlOEfHesq2rI+LkcetPJaU09x/gYuDQ8vvOwLeBl49Z/1DgCcCLgdUV62wPnAd8Dzhm4PUDgacAzwAunlCvPYAEbFr+fgBwA/DIivX/D/Aw4GvA0UPLNgd+CDwH2ArYErjXwPL3Ae8HVgK/D1wL7FexneOA98w7brOK5cC6hwDXA1uVv48FzgR2AHYCvgwcP+b9Cbhr+X0fYA3wVyPW27PE6Y7AJuVc+Tmwsizfr9Tj4BKv9wKnDLx/9eA5N+VxeyHwBeCSecewq3gCm5Xz+i+BAH4PWAvsX5bfAdil/L4FcALwsSnrtmtp6/86Yr2tSpvZg/zF8Y9K/PYoy29X6nVEaZevBr488P7jy/myArgfcDXwwIo6HUW+7typnBsfBU6adxw7ivW+wE+Bw4FNgR2BvQaWV14PR5S1CnhZ+f22wMmDMRha93Zlu08u58nWwD0Glt+L316z71difccmZfX5p0G8Ks9j8ufiX5CvpZsBLwXOG3jvnYDbld9Xlvi8fsy22rrW3gF4JvmzNy212YH3353ffh7sCpwL/MmYep0JvBbYtuznvZcdh3mfCMMnQ/n7BOC/p3jfMVR3ot5aDv5qRnygkS/2F08ofw8GOlHltXOAf5zwvrOGLxrl5DizYv2tgF8Cdxt47d2M+EAoy45jATpRbcVyYJ13Au8c+PtrwBEDfz8J+MmY9/+mYZe/TwXeOOV+XQf8bvn9FcB7B5btVeK3dfl75Dk3puy7AD8gfxj1thO13HiWC2ICbjvw2jnAn414/xbAK4Hv16jbq4FPTLlf3wEeV35/BvDFgWVbATcC+1S892PAP1Qs+y/guQN/PxC4aXCf+/pTN9bkLw8vnaLcW10PR6yzitKJKn//IbC2Yt1XAO+ecp8OLMf/wOWW1befpm1zYP1x5/EOpa3uOGLZSuBdwP8bU3Yr19qB1zZlRCdqaJ1dge8C/1Sx/OHlmG3SZhx6cTtvUETsRv4w+Z9llHEgcF9yR6qtekVEPIg8CvHNBkXcH7g4Ik6LfCtvdUT8Tll2N+DmlNIFA+t/u2yryqPKsOu5EfHXDerTuTZiOVDWVsDjgZOGFw39vltEbDtFefsCBzFFLCPiAPJI4tJ+7EeODwAppR9SOsEDb3tlifPZEXHIhE28AXgB+YO7t5Ybz5TSFeQR16dGxCYR8QBgd/KH7NI27hwR15CPxT+SPximqdudgD9gunjegRyrc8tLw/FcRx41vlX7i4jbkEfQzh1eNrja0O9bAHtPqlefTBnr+5d1vxsRl0fEe2LgtvYytr2SPDJUFcv7A1dFvm3804j4eETceaiMT0TETcBXyF9qvta0rEVQt21OcR4fDKxJKV058J7fj4hrySN7jwNeN+W2lnOtnab850XEWuAS8heg91asen/gfOCkyI8LnBMRD552O5Xm3Zse6FGvJQcnAZ8BtpvifaO+7W5CbjD3L3+vZvkjUdeQhz5/APztFPUaNRL1KeBX5BN9c+C5wEXl94PIJ+zg+k8f3reBZfsCu5R9fSBwOSO+zS96LIeWPwX4EeX/NiuvvQw4m3wrb2fyBTNRPXSfyN9yriZ/SL4MWDGhXtuQv908f+C1zzA0NA1cChxSfr8f+bbAFuTbO9czcJtj6H2PBU4rvx9CP0eiWosn8CjgCuDm8vP0ivfvAPzzUjueULdrgB8DbwZuM6FemwGfBv5j4LW3MzTqW86ro0e8/yTgk4Pn4Yj9voB87diW/G0/AQ+YdyzbjjX5i8PF5A7pSuCDwMkj1pt2JOqmEss15bhVtZkLynq/R779+nrg7IpYHw48Z8x2pyqrjz9N2+ak8xjYrVzPRn6mkEd8jmPgzsmIdVq51g4sGzsSRf6ycm/yLcutK9Z5WynjL8q58cQS+9stJw59Gol6TEppa/IHyT7ke9VNPBP4Tkrpy21VjHyQt08p3SOl9PqGZdwInJVSOi2l9EvgRPIzBPcgN4Thh/S2ITeOW0kpfT+ldFlK6dcppS8C/04epemLtmI56CjgXam0huLl5G833wK+CHyE3FG9Ykw59ymx3Cul9C8ppfVVK5Zvax8nP5vxyoFFY+OVUvpKSun6lNIvUkonkT+Q/2BE+VuRR1r+dkx9+6CVeEZ+UPgU4Ejyl4f9gH+KiD8cXjeldBX5Qv/RiNh0Qt22SyntnlJ6ZkqpcjQvIlaQb5P/EnjWwKKp2l9EvBq4J/CEofNw0DvIo22ryd/yP1de71XCwBh1Yn0j+fb6BSmlteRbY7c6z2s4scRy55TSo1Me4a3a7odTSueklG4if3A+cHgEOqX0q5TSacDDI+LRyymrx2q3zXHncUTsRP7C/+aU0vtGvT+ldCm5A3bKhE21ca2dSsq+SY7n8RWr3UgeOHl7OTdOAX4CPKju9gb1qRMFQErp8+RvJSc2LOJhwGNLtsIa8kjNayLijS1VsanvkHvBo1wAbBoRg0P++zP+lsGgxC1vIfRCC7EEfnOr5hDyffjB8m9MKT0rpbRrSmlP4Erg6+Maa41tbkHulF1CfhB60Lnk+Cytuyd51OkCRquKz97kEYszy7n6IeCO5dzdYxnV70QL8bwncEFK6fSU0vqU0vnAf5NHC0bZFLg9t+7g1BYRQR5xugP5WahfDSwejudW5Ofczh147fhSz4enlK6r2k7Zr2NTSnuklHYrZVxafhbGlLEevqZVXd/aVne7m5Lj2UZZvTRt2xx3HkfE9uQO1MdSSi+fsMlxx7SWCdfauurEmhF/17ecYay2frj1A3I7AesoWTsj1t+EPPT6V+SMpi2Bzcqy7ci3dpZ+vkh++n/bsnxFWf9w8i2ALYHNK7azB0MPlk/Yj81LeWeTb8dtSRnCJGcR3EC+jbgJ8PfkYc7Ny/JTyN9gtyL3jMdl5/0xOfswyA9OXgocNe84th3LgXVeAHxhxHt3Jd/WDPL97p+QLw5VdbvFw45j1tuM/K3oI6NiTx5BuY58G3Yr4D2U7Lxy/j2i7Mem5Gc71jFi6LssHzxX/wS4rPze6sOPfYgn+eK2Fnhoidle5GcfnlGW/0lpJyvKdj4AfGPauk3Yj7eSszdXjli2U2lvjyv1fRW3zM57PnAhsPMU29mh7FeQb7t/b2n/+v7TINZPI99i35OcUfcBBh7SZsz1cERZqxh4sHxCPR9Kvk10QGmr/0ZJ2iGPxhwO3KYs+3PyyON96pbV958G8ao8j8lfVL5KxcPf5OvYncvvuwOfBz40pm6tXGvLOluSr7OpXB+2LK+vIHe6Bj8LL6fikZvSNq8m39XYhHz35iqWeTtv7ifCqJOhvPYW4IMV6x9dDujgz6qKdVdzy//i4JAR711d8d49qNeJWj2i7EPcuX1oAAAgAElEQVQGlv8J+UPjurLufgPLdign0jrgf4EnDSw7iIFMFXJn60ryB9J5VSfNhhLLso9/MeK9B5ft3UB+YPDJE+o2bcN+cFn3hnKMl34OGljnSSVO68hp7DuU13ciZ5xdT77f/mXgsKpYDm33EPr5TFRr8ST/9wffK8fnEnKHZemLxt+QP5TXkZ+LOQXYvU7dKtbbvdTjpqF4PnlgnUPLeXZjaZt7DJ03vxh67wsGlv/m3CA/H3R+OXd+zJjncfr2UzfWZfnxwM/Kz7uB7QeWrR5xLhxSUc4qpuxElfX/mvzl8Wryh/Cdyuv3ID8budT+zgEeO/C+W7W/qrL6/tOgbVaex+SORSptb3D5Usfp5aW9riv/vo0RmXtD22rrWjt8DqXy+grybcWrynsuIH/hHnxudrisg8jPXa0lPzt90KQ6TvpxAmJJkqQGevdMlCRJ0iKwEyVJktSAnShJkqQG7ERJkiQ1YCdKkiSpgXH/E3Dr1q/Ze2Qq4CN2OWDk+qdf9q2Rr1etX0dV2XUtQt1X7Hxh6/8R52ErjqiV1tnG8W7j2EH9uvTpfOsillDdNqvUPe/nYR51rLvNPrfNOud9l9e7rm1obbNP6sa/znlU95zr6nPTkShJkqQG7ERJkiQ1YCdKkiSpATtRkiRJDcz0wfK62niwsWttPNxW9+G7uuufsb7W6lNp60HSLmNcVfYiPOxYtX4XsRynjXh23Ta7fIC8y3MF+t022yi764d/+/Twe1/aZpfXqypV5XRdfpfbnDaejkRJkiQ1YCdKkiSpATtRkiRJDdiJkiRJasBOlCRJUgOR0uz+R/mq6Qi6zHDreoqPLqdMqNLnqSW6zsapU3aVrqf8acMsYwn1pwqp0qcpVeqW00bZdfVh2pc2LMJ1tuuyz1h/aq+nfZnHed9lm+06889pXyRJkjpkJ0qSJKkBO1GSJEkN2ImSJElqwE6UJElSA72eO28ecwDV1Ub2QVt17MN8a/PIwuvbvImLqOs50eqU0bU26t63c7Gvur62dVn2vD5Tpt3ePDKh6+rLMYTu9t+RKEmSpAbsREmSJDVgJ0qSJKkBO1GSJEkNzPTB8kV4yKzrByFHbbfraV+60Nbxm0fs52FeU9P0QdfTM9TVxgPkdddfxLY567LHlV9lHvvUl7bZxr53vY9dPhTf9WfNtAlZjkRJkiQ1YCdKkiSpATtRkiRJDdiJkiRJasBOlCRJUgMzzc7rMhun6/+6fx7ZaG1lqnQx7cs8piKYVyZfGzHrcyzHba/u+m1k9XSdrdrldaUPFjnjtcssv0WdXqtP59oitoclXWWWOhIlSZLUgJ0oSZKkBuxESZIkNWAnSpIkqQE7UZIkSQ1ESmlmGztsxREjN9bGU/Pzmuuny21WqVuXFTtfGLXeMIX1a/YeGcsus/C6ztpqIw5dZy12EUuobpuLbB5zyNXVRTznEcu2zu8uMwu73uYZ60/tpG12ea2tMo/s6yb16XKb07ZNR6IkSZIasBMlSZLUgJ0oSZKkBuxESZIkNWAnSpIkqYGZzp1XV51MgHnN6dNGFkNbWWdV+jx3Xp0y5qVOfeaRddSGLs/BrjO35pUxtGj61Da7bg9dZs7OWpfnfdfHZB5zIXad7T7MkShJkqQG7ERJkiQ1YCdKkiSpATtRkiRJDdiJkiRJaqDX2XlV2nhSv+qJ/K6zErrMDNpQso7aOnbziOWiZoTNOqOlrTKalN+nOcdmqcu5IevqOiOuL5l1bejyPO5bZmIbda+ral+nzWp3JEqSJKkBO1GSJEkN2ImSJElqwE6UJElSA3aiJEmSGuhFdl6X88/1aa6ftrZZd1+7mDuvT5lPdXU9V2GdMvqQtdWmLttmW+Yxh1wf2uY8zCv2fZ5rra55zPnXdeZbl8fQufMkSZIWgJ0oSZKkBuxESZIkNWAnSpIkqQE7UZIkSQ30IjuvDYsyp1MdfarLtHWYRxZenzIz69al7ja7yOaC9rJlFmFOvXlkW86yzfYpm2te16p5ZHBvDG2z68y3ecxT6tx5kiRJc2AnSpIkqQE7UZIkSQ3YiZIkSWrATpQkSVIDM83O6zJzaZHn+unTXFfTamvuvDpZNHV1Xc6GlNXUZUZXVRldnkNNtlun7LbWn6U2Mqv6vH8bqnlkK7fVZvs+L2EbHImSJElqwE6UJElSA3aiJEmSGrATJUmS1ECvp32p8xDbvB5g2xgenGtDG/+df11dP7Q9j7rP2jymSGmrLm1st+uH3/ugjTrPa//mcbz70jYX2TyOYVdJY45ESZIkNWAnSpIkqQE7UZIkSQ3YiZIkSWrATpQkSVIDkVKa2cbWr9m71sbmkWExjyyTrjMFz1h/arSygQFdxrKtjKi6upzGpa1tdhFLgMNWHDEynl1OIdH19C5daisrd8XOF7Yez6pYqltdtc2qa22fptiqq8us9rY+w6eNpyNRkiRJDdiJkiRJasBOlCRJUgN2oiRJkhqwEyVJktTATOfO61PmW9d1WeT5qKbRp1hW6dO8hn2O5bwschZe3bpXZ842q5c2HvO4dsxrvst5ZOE5d54kSdIc2ImSJElqwE6UJElSA3aiJEmSGrATJUmS1MBMs/Pq6jLDrW9ZexurUcejrcyQtjKo6pa/iNpqD3Xi2VZdupw7set5/zQ7G1psFiG7tctj3v2cs9O935EoSZKkBuxESZIkNWAnSpIkqQE7UZIkSQ3YiZIkSWogUkrzroMkSdLCcSRKkiSpATtRkiRJDdiJkiRJaqD3naiIuDgiboyItRGxJiJWRcTKMeufGBEXRsT1EXFeRBw5sOx2EXF2RFwZEddExJci4kFjyloVEb8s274qIs6IiH0q1n1uRHyvbPdHEfHcoeWfi4ifRcR1EfHtiPjjMdt9SFn/2oi4eOwB6rkG8ds1Ij5ajvclEfFXQ8vfFhHnR8T6iDh6wrbrxG/sMY+IPcryG8p5dejAsqMi4usltpdExAkRMXI2gIi4W9m/n5U6nR4Rdx+3H/PUZvsry1NErCvlrY2I/xxYNvV5X+KRBsq5OCKeV7Hu2GM+KX4RsToibhrY1vlj6hUR8apyjbmy/B7j9qUvGsT6CRHxxdImVo9Y/qhyTVxb1tt3TFltttUDIuLMsvySiHjRmO0eHRG/Hojt2og4pGr9RVE3lgPv26G0k7MGXts3Ir4WEVeXn09PiOVge/l5RHwoIu7YYLtPHorLDaXN/+6Ycp4YET8o15gfRsRBk/Z5uXrfiSoelVJaCRwA3Bt4/ph11wGPArYFjgL+PSIeWJatBZ4G7ARsD7wK+HhUfOAVJ5Rt7wb8FFhVsV4AR5ZyHwk8KyKeOLD82cAdU0rbAM8A3jPmxFoHvAN4bsXyRVMnfu8BfgTcAfhD4BUR8ZCB5d8Gngl8Y8ptTxu/Scf8fcA3gR2BFwL/FRE7lWW3Bf4OuB1wP+BhwD9WlLMd8DHg7uR9/Crw0Sn3ZV7aan9L9k8prSw/xwy9t+55v12p258BL46IR45ah/HHfJr4PWugzuM6vc8AHgPsD9yLfCz+ssb+zFudWF8FvA741+EFEbE3cDLwV+Tj/3HgYy1dayedJ+8FvgDsADwYeGZEPHrMdr80ENuVKaXVY9ZdJHViueRVwA+GXrsMeDz5eN6O3JZOmVDOs8q270aO/7/V3W5K6eTBuJCv+xdRce2PiMNKOU8FtgYOLut3alE6UQCklNYAp5NPiqp1jk0pnZdSWp9S+gpwJvCAsuymlNL5KaX15E7Pr8mdnh2m2PYN5MZ5z4rlJ6SUvpFSujmldD75Iv2ggeXfSSndvPQnsBlwp4qyvppSejczOAFmaVL8yjelQ4CXp5R+lVL6NvBf5I7vUhlvSil9Brip5rYnxa/ymEfE3YD7AMemlG5MKX0Q+C7wuPLet6SUzkwp/TKldCn5w2PkCGfZzttTSlellH5FvrjcPSJ2rLM/87Dc9jdF+Y3P+5TSl4BzGRHfSce8TvymcBTwmpTSJaWs1wBHNyxrbqaM9adTSh8gf8gOewRwZkrprHLdexWwK7lTM2nbjdtqsQdwckrp1ymlHwJnAftN2u6GappYApQvO/cE3jn0/mtSShennMq/9Ll51ym3fRXwQSpiOW67IxwFvCtV/5cCxwMvSSl9uVx/Li1tsFML1YmKiN2Aw4H/mXL92wC/R764Dr7+HfKH8MeA/0wp/XSKslYCTyaPRkxaN4CDRmz3ExFxE/AVYDXwtWn2Y0MxRfxi6N+l3ysbYI1tTx2/EfYDLkopXT/w2repvjAfzFDsxzgYWJNSurJBvWaqrfYHfKHcYvhQROzRQr0i8m35/ZguvpOO+aj4vbLcmjh7wu2e/cjnxpJx50lv1Y11VTFDv0/VlpfZViGPjh0ZEZtFvm37AODTY9a/d4ntBRHxogmjZQtnmlhGxCbAG4Fnkb/kj1rnGvLn5huAV0y57duRv2yOjOU02y3r7U5ul+8aU859gZ0i4n/Kbdw3lmtQpxalE/WRiLge+Al5mPfYKd/3VvJF7PTBF1NK9wK2AZ5E/pYyzj+Wk+d/gJVM963yOPKxHe7R/xF5mPEPgE+VEbGNwVTxK52Us4EXRcSWEXEfcgO87TK23SR+w1YC1w69di05lrcQEU8jN+YTJxVaLm5vAp7ToE6z1Gb7ezB5pGAf8gjGJ5b5ofVz8m2l/wSeV0YpK0065hXx+2dgT/JIytvIjwDsVbGJ4XPlWmBl+WK1CJrGetingQdHxCERsTnwAmBzxrflNtoqwCfIt59uBM4D3p5SOqdi3S+QO3a3J19r/owN5zGKOrH8W+ArKaWvV62QUtqOfJv+WUzu4L6+xPLbwOVUX+Mmbrc4kjyy+aOK5Xcg3915PHkAY+kW5r9MKHf5Ukq9/gEuBg4tvz8YuBS46xTvezXwdWCbCev9gPyMxqhlq4CX1azvs8jP9Ow2Yb1PAo+esM6hwMXzjsEs4wfsTr4I/ow8Yvd64DMj1jsLOHrCtpvE71bHHHgs8P2h194AvGHotccAVwC/M8V2dgK+D7xw3jFqM34D75vY/oBNyM+3/M7Q6xPPe3JHLAGb1tiXscd82viVtvs3FcuuBQ4c+Pt3gevnHceOY30MsHrE648HvgdcCfx7+f0pFWW01VZ3AK4jf+huSn6+6svAM6cs84nA1+cdi1nGEtiF/Jm1Q/n7aOCsMWWvKDG9fcXy1cAxU9Rx6u0CFwJPHVPW9uV6cNTAa48Dvtn1sV6UkSgAUkqfJze2sd/yI+J48vDlw1NK100odjPyt8xlK99inwc8LKV0yYTVNwWqvs1ukKaJX0rpxymlP0op7ZRSuh/5QcavzqiKVc4F9oyIwZGn/Rm45VMeaP6/5Ic5vzuusIjYHvgU8LGU0ss7qG8nOmp/S89ZdGrSMa8TP8bX+VzyubHkFufJopg21hPK+K+U0j1TSjuSR0H2AKpGhNqyJ/DrlNK7Un4+9RLyQ9B/MOX7Z3I+ztIUsTwQuCPw/YhYQ+7wHlhuuW8yYv0V5BHFXZdZtam2W27V70J+PnaklNLVwCXc8pbgTKZjWahOVPE64LCI2H/Uwoh4Pvk23aFp6JmHiLh/RPx+RGweEbeJiH8mDwN+ZbmViognk+8TH5ZSumho2T4RcXjZ5mYR8efk+7ufryhrRURsSe7gRbm1tfly69gTk+J3j4jYusToz4GHA68dWL55OTYBbFaOzbLP43HHPKV0AfAt4Njy+mPJmVcfLO99KPlh5MellMZ2+CJiG/LtrbNTSiNT8ntuOe1vv8jp55uU515eQ/6G/IOyvJPzftIxHxe/iNguIh5R6rJpaecHk0ejRnkX8JzI/1XHLsA/UJ1l1neTYr1JidemwIpyjDYbWP67ZZ2dyLdBP5ZSOm+5lZpwnlxQXntSWW9n4E+B71SUdXhE3KH8vg/wIvqfLdvEuFieRu7gHlB+Xky+XXdASunXEXFYRNy7xHIb8vX4am6dxVfX2O0OrHcU8MF0y2dSR3kn8DcRcfvypenvyXc1ujXrYca6PwwMSw689hbyQR21fgJ+Qf7vDJZ+XpB+O6z5beB68nMUnwcOHrPtVUw5xEwelvzV0HbfWpbdg9xRux64hvxt7LED7z0IWDvw9yFlPwZ/Vs87FjOK39+Rb+WtI9+yu+/Q8tUjjs0hLcRv7DEnN/bV5Ocszh/cJ+BzwM1DsT9tYPlpA+fgUaXsdUPr33nesWopfuPa30PLsVtHfkbjI8DeTc57atzOm3TMx8WPfAvwnIG2+2XyF6WqthvACeTry1Xl95h3HDuK9dEj4rVqYPlZ/PZa+x/AVmO23WZbfWiJ2bXAGvII423LsjsPxf5E8i3cdeRsv5cAm807FrOO5Yi4njXw9xHkZ8vWkq/N/w3ca8z7VzPF7bxJ2y2vbVna3cNGrP8Cbnmd3Qx4c1l/DflRkC27PtZOQCxJktTAIt7OkyRJmjs7UZIkSQ3YiZIkSWrATpQkSVIDdqIkSZIamOkcQYetOGKjTwU8/bJv3eq1R+wydl7IZTtj/amt/+dxVbEctX/jdL3vbajapzp1b6MM6CaW0F7brHN+1z0mXZ9bG3rb3JhsKLGE+bTNNspus/x5mDaejkRJkiQ1YCdKkiSpATtRkiRJDdiJkiRJasBOlCRJUgMznTtvEbJGFiHLoG4dFy0DqG4WVtf6FPtZZwB1GYu2svAW2YqdL1yotlnXIlxP29JV21y/Zu+R8dwQj2GVLrN+q5idJ0mS1CE7UZIkSQ3YiZIkSWrATpQkSVIDdqIkSZIamOncefNQ90n9Rch46EMdu5z3rA/711Rbx6Uvx6CNelTtY1tZePPI8jOzcDp9OY/H6XoOx+VahGNYZR7Xw1kfL0eiJEmSGrATJUmS1ICdKEmSpAbsREmSJDVgJ0qSJKmBXmTndZmhtMiZDX1W97jWWb9u9kvduszjfFvUrK15ZC513Wb7dC6esb7W6nPX92zSJtq6ls06lm3Eout4tnVs68ydN2uOREmSJDVgJ0qSJKkBO1GSJEkN2ImSJElqoBcPlvflAbG+2ZAe4qyzL316sLiuth7EnvWD6F1Oz9D11A9tHas2Hl5d1ASCaS3itWdD1Ub7mVc8N6Tp2ByJkiRJasBOlCRJUgN2oiRJkhqwEyVJktSAnShJkqQGepGdNw9tZb45Zc38tZURNY9MrL5ME9JlptwiZOG1sa4WU9+zoLvMZOv7vi8CR6IkSZIasBMlSZLUgJ0oSZKkBuxESZIkNWAnSpIkqYGNNjuvreyDNsrZkDIk5rEvbZXdZSbWhhRjaGfuvHlpI/uv6wzCWery3FyE876t7NGudJkx3nU2etdZ8G2UvVyOREmSJDVgJ0qSJKkBO1GSJEkN2ImSJElqwE6UJElSAxttdl6f9ClTZRHNa+68OvqetVW3fl3OnVdX3fK7zPRZxKy9RcicnYe+1H0eWYJtbbOtrL2+xGIUR6IkSZIasBMlSZLUgJ0oSZKkBuxESZIkNWAnSpIkqYFeZ+e1MT9X10/1t5XVtKFoY06keWWA1FWn7ouYtQXt1HteWXht6Ht8NL2+zIXXtTb2p61r6sbQfhyJkiRJasBOlCRJUgN2oiRJkhqwEyVJktSAnShJkqQGep2dVyfLYF4ZFoswf9Es9WlOpHll7XW5zTPWt1Gb5dejjWycvs2pV6eMujaGLKW+6/N1c1F0fU1dxM88R6IkSZIasBMlSZLUgJ0oSZKkBuxESZIkNWAnSpIkqYFeZ+dt7NrKbJilRchwW4Q69iGW48wji6ZuZpBz6k1nkbNVNwYb0zFZxH11JEqSJKkBO1GSJEkN2ImSJElqwE6UJElSA3aiJEmSGjA7bwNSldnQ1XxrdbSRjdO3zI2+1Wc52so2a2Neuj7NqbchZeF1qe5x2pDazsbErMpbcyRKkiSpATtRkiRJDdiJkiRJasBOlCRJUgO9frC8jYfY5vUgXJfb7cPDfXXrsMhTSHT5cHHd49VVkkCXD3P36UHxca/P47rSh6SPNtrJxvxg8cZkEeI8689HR6IkSZIasBMlSZLUgJ0oSZKkBuxESZIkNWAnSpIkqYFeZ+e1YV7ZBF1utw8ZEl1mvtXNtppXFl6XmZazVvfY1ql3W8d1Htl888g27Ys6x0Oz10abNUt9+RyJkiRJasBOlCRJUgN2oiRJkhqwEyVJktSAnShJkqQGep2dt8iZIH3JHOhKl1lli5yF13UGWd/nzhtVTluZf/NoO11mLfZFn463pten9jOPbba1/8tts45ESZIkNWAnSpIkqQE7UZIkSQ3YiZIkSWrATpQkSVIDvc7OWwQba2bLPDI92lK37nVivKHFvY2Mlq6ziOqeL4uYQdelRT5nN4brb919nMe+9+l4163LcjOhHYmSJElqwE6UJElSA3aiJEmSGrATJUmS1ICdKEmSpAYipTTvOkiSJC0cR6IkSZIasBMlSZLUgJ0oSZKkBnrRiYqIiyPixohYGxFrImJVRKwcs/4TIuKLEXFDRKwesXyTiHhZRFwWEddHxDcjYruy7K1lO0s/v4iI68dsK0XEurLupRHx2ojYpGLdl0bEdyPi5og4bsTyv4mIH0XEdRHxtYj4/YFlfx8RF5Vll0XEv0XEyP9RPiL2KPUa3I8XVe3DLM04lk+MiPMj4tqI+GlEnBQR24zZ1qxiGRHxqoi4svy8KiKiYjsRES+MiP8tZZ0ybh9mre14Dqx3ZInHMQOvbVHa5xURcVVEfDwidh1TRpvx3Cki3lvOpasj4uSh5YdGxDfK9i6JiCdUbOeQiFg/1DaPqtqHPpll2x2x7qqI+GXZ9lURcUZE7FOx7kMi4nMlVhePWD421iPWv09EfKFs+4qIePak9/RBB/F6W+Tr6fqIOHpoWZRYXlqO++qI2G/Kul0xrm4R8azI19BfRMSqoWX3L+fCVRHxs4g4NSLuOFSvqa61Q+W+o1w/7jpp3Ul60YkqHpVSWgkcANwbeP6Yda8CXgf8a8Xy44EHAg8AtgGeAtwEkFL6q5TSyqUf4H3AqRPqtn9Z92HAk4CnV6z3P8A/Af89vCAi7lfq+3hgW+DtwIcHLvofA+6TUtoGuCewP/C3E+q13cC+vHTCurM0k1gCZwMPSiltC+xJnsboZRPqNotYPgN4DDmG9wIeBfxlxXaOLPv0IGAX4DbAGybsw6y1GU8iYnvgBcC5Q4ueTY7zvcjH4momH4tlx7P4ELAGuDNwe+DEgfruC7wXeCE53vsDXx9Tp8sGrzEppZMm7EOfzKrtjnJC2fZuwE+BVRXrrQPeATy3YvmkWP9GRNwO+CTwH8COwF2BT016X4+0Ga9vA88EvjFi2RHA04CDgB2ALwHvnrJu9wHuC/xLxXqXka/b7xixbHvgbcAewO7A9cA7B5bXudYCEPkL714T6j61PnWiAEgprQFOJ58UVet8OqX0AfLBv4Vygf474OkppR+n7HsppVs13ojYCngcMNVFLqV0HnAmuZMzavlJKaXTyIEetgdwbkrp6ymnRL4LuB35gk1K6YcppWuWqgasJzfohdV1LFNKP0kp/XzgLb9mymPWZSyBo4DXpJQuSSldCrwGOLqiKo8C3l72ZS3wKuBPI+K20+zHLC03ngNeCbwe+PnQ63cBTk8pXVFi/H6g8tvu0HYbxzMiHg7cCXhuSunalNKvUkrfHFjlX4D/SCmdllK6OaV0ZUrph9PUa1HN8jo8otwbyJ3Wqlh+NaX0buCiiuXj2u6w55DPuZNTSr9IKV2fUvrBFO/rlTbaZkrpTSmlzzC6o3sX4KyU0kUppV8D7wH2nbJulwKnUR3PD6WUPgJcOWLZaSmlU1NK15Xz4o3kL5xL6lxriXx35w3A30xT92n0rhMVEbsBh5O/TTTxO8DNwOPLEOcFEfF/KtZ9HPAz4AtT1m1fck/8m5PWHeE0YJOIuF8ZsXga8C3yt9+l8p8UEdeRP1z2J387GufH5dbCO8s3ql6ZRSwj4vcj4lryBfNx5G9a09Sty1juR/5Wt+TbjO8MxNDvWwB7N6hXp1qIJxFxIPlb6VtHLH478KCI2KV0Ip9MPtbTlLuceN4fOB84qdwSOCciHjy0nHKL6PKIeE9E7DCmvNuXWxg/inxbfqsGdZqrGV+Hh7e9khz7JrGs6/7AVeU2108j30K+8wy226o22uYEpwB7RcTdImIzcuflk1PW7U7AH9BOPA/mliPYda+1fw98IaX0nRbqAuTbH33xkYhIwErgs8CxDcvZjTzkfjdy73lv4DMRcUFK6YyhdY8C3pUm/2dZ34iIX5OHQ/+TWw4nTut64IPAWeQPymuAwwe3nVJ6L/DeiNibfJvnioqyfg78HvmDe0fgTcDJwCMa1KsLM4tlSuksYNvIz848Hbh4QpmziOVK4NqB9a8FVkZEjDjXPgn8U0R8gHz76p/L630aiWolnqXD+WbgWSml9SMeXbgQ+AlwKXlU8bvAsyYU20Y8dwMeDhwDPJXcGf9oRNy1jHTuRr4V9XDyt/iTyN9mnzyirPPIowHnkW8/nAS8lgm3GHpkHtfhJf8YEc8ij4R8lTEjCi3ajXy76TDy+XYC+RGPB417U4+0Fa9JLidf784nt82fAA+dom43k69//w28YjkViIh7AS8G/njg5amvtaUz95fA7y6nHsP6NBL1mJTS1sAhwD7k2yNN3Fj+fUlK6cbS4zyF3BP+jfJt4xDyrZhJ7pNS2j6ltFdK6V9SSusb1OsvyBfo/YDNgT8HPhERuwyvmFK6kNzbfvOoglJKa1NKXyu3Fq4gf9A8PCK2blCvLsw0lvCbIeNPluXjzCKWa8nPgCzZBlhb0Vl/B/mivZoc88+V1y9pUK+utBXPZwLfSSl9uWL5m8ijcDsCW5GfU5o0EtVGPG8ELk4pvb3cyjuF/CHxoIHl70wpXVBuub6CEecg5NsqKaXvp5TWp5R+RH4253EN6jQvM2+7A05MKW2XUto5peYjphwAAB2VSURBVPToGd0yvRH4cErpnHKr8XjggRGx7Qy23Ya24jXJi8lf3O8EbEk+Tp+d8NjBY0o8d08pPTOldOOYdccqD4CfBjw7pXTmwKI619rXkc/Ha0csa6xPnSgAUkqfJz9QeOKEVassDdMNHsRRB/QpwNkppZH31TtwAPCJciFen1L6JLl3/8CK9Tdl+offlvavV/GcYSyX1DlmyzEplueSb8cu2Z9bP0QNQHn/sSmlPVJKu5X1Li0/vdJCPB8GPLbc3llDPl6viYg3luUHAKtSSlellH5BHu05cAa3qr/Drc+rNGZ5nWkeEj1rl9OYQ9udl+XEtjdaiNckBwDvL88e3ZxSWkV+6Huq56KWIyJ2Bz4NvLQ8Czdo6mst+frz6oHrD8CXIuJJy6lfXxv364DDImL/UQsjp85uSf7QXBERW5b7tJRvL2cCL4ycMn0P4InAJ4aKOZLq7I9GImKzUq8VwKalXksZW+cAfxgRe0Z2GHmo+3vlvcdExO3L7/uSsyw+U7Gd+0XE3SNiRUTsSH5Id3XbPeyWdBbLiHjy0vMLpaG9nIpjVtdyYkke3XxOROxaRqf+gYpzLSJ2iIi9Sjn7km/9vKThiMosNI4n+fbMPcgX5AOAr5G/0b6wLD8HODIiti3veSY50234AfTaJsTzw8D2EXFUqf/jybd5zi7L3wk8tcT7tsDzuPX1ZGk7D4mI3Us870TOhProcus/J7O4DtdWrntbApvlP2PLiNh8YPm4WA97J7ljf0Cp+4vID1D38Vo6yXLaJhGxeVkewGZl+VIf4RzgiIi4Qzn+TyEf/2U/gxURm5btbkJ+1nTLKP+9T+THND4LvDGlNOo5yqmvteRr9P789voDObHnw8vagZTS3H/Iz7EcOvTaW4APVqx/NPkbw+DPqoHlu5Jv7awlZ3D85dD7H0BOk916irol4K5T7seqEfU6uiwL4CXA/5KfqfkB8JSB976T/AzUunI8Xg1sObD8XODJ5fc/A35U1r2cfCLtPO84zjqW5E7TJeU4XEJOhd2xB7EM8rMVV5WfEyjzVJbla4GDyu93Iz9ncAPwY+A5845hl/EcWnc1cMzA3zuSn+37Kfk5s7OAA7uOZ1l+EPmZmLXkzt1BQ+8/npyE8jNyavf2FfF8DnkU8QbyLcHXM8V1pg8/s2y7FfF52ZT1PGTEdldPE+sS57VD5f11idnVwMeBO807FnOK1+oRyw8py7Yk326/HLiO/N8gPLJO3case9yI7R5Xlh1b/l47+DPw3qmvtSO2O/X1Y9yPExBLkiQ10NfbeZIkSb1mJ0qSJKkBO1GSJEkN2ImSJElqwE6UJElSAzOd9mX9mr1bSQV8xC63nmPx9Mu+NfW649avs8221K1Llao6nrH+1FvNr7FcVbHs03Hqsi511T0/q3QRS4DDVhxRq222sT9tnfdV6rb9Lq8rs2ybdWOpdvS9bY7S1nk8j8/fvnxuOhIlSZLUgJ0oSZKkBuxESZIkNWAnSpIkqYGZPlje5YO+bT3wVqXrh9jaKKPrB3Wn0eUDg22dP10+BNmnh9m71OU5OK/ze1T5bdWlD21Ti6nu9WoeyR1dP3De5TV4ucfAkShJkqQG7ERJkiQ1YCdKkiSpATtRkiRJDdiJkiRJamCm2XldZgJ0/d/UzyMbqa1yzljfSvHLqkOVOhlRdc1jWpG2ttmXbK55ZAbNawqnUeV0nSk6y7Y5D33LtNUtdZklN678ttavo/6UTNOV60iUJElSA3aiJEmSGrATJUmS1ICdKEmSpAbsREmSJDWwkHPnzSOjq09ZBlVmmdHVddZjnbKrzGMOtj7Pa9hEl3NSdp0Z1Ma52FYG4caq6+OxMRzvRdjHecxd25fPZEeiJEmSGrATJUmS1ICdKEmSpAbsREmSJDUw0wfL62rjYdyu/5v6utttY8qaPpjHg9JdT49TV5cJDrM2j3Ow66ma2noQvcttav66Pq+Wq8vPsK7b/SIkIC2XI1GSJEkN2ImSJElqwE6UJElSA3aiJEmSGrATJUmS1MBMs/MWYdqOKn367+v7oMuMqK4zJKt0mRnSVpbKGeunrkotXWbEzev87nJaiL5ndGl6bZ0ns26bddU5B/uWtddl2cuNpyNRkiRJDdiJkiRJasBOlCRJUgN2oiRJkhqwEyVJktTATLPz+jb32ShdZ9HUmTuvThmLqss5keaV5VenjL7HsssMt64z2brMLOx7RldftBXLNtrJorbBLj+T6rbBeV2Du/ycWO7xdSRKkiSpATtRkiRJDdiJkiRJasBOlCRJUgN2oiRJkhroxdx585hHp8oiZHD0eR6uLo9TW7FsS51MS+dU606XGWBdzpm5MZjXdbNPczguV1vXjjYyZ6t0fX53mTlrdp4kSdIc2ImSJElqwE6UJElSA3aiJEmSGrATJUmS1EAv5s5rIwOm7lw/dZ/s7zLrahEzt+ZxPBbBItd9lHnEueuM2nmci4s4d94iZ7gtSj2XY2PYxyVdzjm73LbpSJQkSVIDdqIkSZIasBMlSZLUgJ0oSZKkBuxESZIkNdCLufPqrt9GVkJbmW9tZAgs4vxcXWaGtHU85pFp2eV8VjD7bK55ZAD1af7KPmfIdm1jyv7SLS3CeV/3et3VdcWRKEmSpAbsREmSJDVgJ0qSJKkBO1GSJEkN2ImSJElqYKbZeXXNY065Luf3qyqnrf2c5fxcfYpB3XK61PW8b7PWxtyTi5DpU6WtOMzyGPTpnGorE7Yv7WERtHEM27oGz+Nzc9ZZ7Y5ESZIkNWAnSpIkqQE7UZIkSQ3YiZIkSWrATpQkSVIDM83OayvDok45i5zt0ee58xZB13PwdbnNjTmW85ojsU4Zdc0yc3YRrm1VFrnuXWkjQ7aqnC6vhX1T9zhO2zYdiZIkSWrATpQkSVIDdqIkSZIasBMlSZLUQC+mfVmE6TyqzOMB4A39oeN5PZzdZRJCn6fwaVKPKm1Ma9R1Aso8psXY0NtslT5dqxfVPBKyurbICV/DHImSJElqwE6UJElSA3aiJEmSGrATJUmS1ICdKEmSpAZ6kZ3XRqbLvJ7q7zJzq43/1r8rfajDJG1lZ3WZSdL3bJQuM2fbyrZs61ycR2bhrLMttfFq43NzXtfOOm151p+bjkRJkiQ1YCdKkiSpATtRkiRJDdiJkiRJasBOlCRJUgMzzc5r60n9UevPay6eLrOX+jzfWpdZGm3Nede1NjJG+pTNWMciZ6W20Qa7nsdRWjKPz8265jUPZp261C172s9NR6IkSZIasBMlSZLUgJ0oSZKkBuxESZIkNWAnSpIkqYFezJ1XpY1snLae1G8ry6DL+Yv6MHdel2W3Fct5lNPnTEuYT0Zk3+YN3JDiqQ3HIl9r29LG56Zz50mSJPWInShJkqQG7ERJkiQ1YCdKkiSpATtRkiRJDURKad51kCRJWjiOREmSJDVgJ0qSJKkBO1GSJEkNLEQnKiIujogbI2JtRKyJiFURsXLM+qsi4pdl/aWfTUas9+KISBFx6JTbvmLctiNidUTcNLDN84eW7xQR742IayPi6og4ecrtro2IT1Wtu0gaxPKEiPhJRFwXET+OiBcMLX9oRHyjLL8oIp4xpqzjIuJXZdvXRMQXI+IBFes+MSLOL7H6aUScFBHblGVbRMTbS32uj4hvRcThY7ZbWdYiaxDLHSLi/RFxZUT8PCJOHjwOEbFHRHwuIm6IiPMmtMvBNn5VRJwREftUrLtFRLy1tN+rIuL/t3fvwZYU9QHHv73sCirPxQcB5eEKGLECPooYCZHSoEZDogJqJAomvmJZWlrlI8ZU1lJLY9RoIooa4lK+EBVfSRBRg3G1UGM0mjWK0ZAIuKggj13wAfeXP7qXHA5nzj3TO3PPnLvfT9Up7p6Z29NnerrP7/bMj/5ESumgke1T++1YWSml9JflM1xdfk7Ln635q2ivJ5Q+cmNK6eIp+z21jKNPH3lv5vOUUjohpbRU6nVD6StPa9j3DimlD5XPEimlE8a2j/bxHa97zVLnCfusTyl9JKW0vfT1JzftOw9dtmdK6YiU0sdSSj8ufeTClNKRI9tbjWHl3G4vdbsipfTGNOE7uOz7ypTSN1NKN6eUNo5te0xKaXPK4/XWlNLfpZT2mlDG+lL3zc1nDFJKLyjlXJ9S+vuU0u7T9p/FQgRRxUkRsSdwDHB/4E+X2f91EbHnyOuW0Y0ppQ3AqcAPWxz7AcCDgJdP2fe5I8c8cmzb+cBW4GDgbsDrZzlueT1ihnouijZteTZwn4jYG3gIcFpK6fEAKaV1wEeAtwP7AE8E3phSOnpKeR8ox74rsBk4v2Fw/wJwXETsA9yLvETSq8q2tcAPgIeW474cOC+ldGjDMaeVtejatOWrgP2Aw4ANwN2BjSPb3w98Ddgf+DPgQymlu04p73Xl2PcAfgRsatjv+cBvAL8GHAj8FPjbsX2m9dtRzwQeCxxdyjsJeNaU/YemTXtdA7wJeG3TDiml/YCXAVvGNrU9T1eWeu0NvAR4Z0rpvg37bgb+kDyWTvKBsbH/+zPWedyZwC/I1+lpwNtSSkct8zsrrav23Bf4OHAk+fN+GfjYyPaaMezoUreHA08GntGw338BLwb+ccK2fcpxDgR+FTgI+KsJ+/0l8J/TKpNSeiTw0lKfQ8rneMUyn2FZixREARARW4ELyRfNzjiT3Fl/0eLYVwAXAPdre7CU0iOAewIviojrIuKXEfG1tuWsJrO0ZUR8JyK2j7y1BNy7/LyePOi+O7KvkDtS0+A7Wu4vgXOAA8hf2uPbfxARPxl565Ydx42I7RGxMSIui4iliPgH4L+BBzYcq7Gs1WLGfnkY8NGIuD4iriMHwEdB/kuY/EfKX0TETRHxYeCbwMkzHPtG4H0098vDgAsj4qqI+BnwgR3HrXA68IaIuLyMB28Azqgsa25m7HufjojzgCunFPUa4G+An4y9X3WeSj/+KDnQvV0/johfRMSbImIzuR/VaKrzrVJKdyZfe38eEdvK8T4OPKXymL3a2faMiC9HxNkRcU0ZG/8aODKltH/ZXj2GRcS3gc/T0D8j4pyIuAC4YcK290XEJyPixoj4KfBO4LjRfVJKDyllv2uZqpwOnB0RW0pZr6SDvrtwQVRK6R7A75Cj12meU6Ylv5pSus1AnFI6Ffh5RPxTy2PfE3g0+a/lJq9J+VbFF8ammh8MfAc4p0xvfyWl9NBlDvneMkX5qWVmVxbSrG2ZUnppSmkbcDlwZ/IXJhFxFXn24mkppd1SvjV3CPkv1eWOvTu5A40PDqP7/GZK6Tpy5z6Z/FfcpP3uDhzBlL9sZy1rUc3YlmcCv5tS2q/MBpxM/qMEclDz/YgYHUj/nRmCnXIL4zSa++XZwHEppQNTSncq+14wtk9Tvx13VKlXqzoOTYtxdFoZx5Jn5s+asLnqPKWU1qSUHkeeGflmZdVOKmP/lpTSn7So86gjgJsj4tKR9wbb1l2055jfArZGxNUjx6gaw8qM4vFM/95sU69bx9lyi/AtwHOB5f5/TZOuybvvCBSrRcTgX8BlwDZy4wXwGWDfKfs/gDy7sJYc9NxAnooE2Av4LnDoSNm/PcOxrwX+B3grcMeGfX+9lL87Oeq9AdhQtr2j1P2PgXXAk0qZd2ko6zjgjsCdyFO0W6d95kV5tW3Lkd9L5OnqVwB7jbx/EnAVcHN5PWNKGRvJM4/Xkm//fBZ44AzHPqj87hETtq0DPg28fcbP31jWor0q+uWB5VwtlddFwB3KtqcAl4zt/2pgU0NZm4CflbbcSp4l2NCw7z7AuaWON5MH8/Uj2xv77YSybiHfXt7x78NLuWne7dF1e4383tOBi8fe2w34V+DB5d8XA0+vOU/ACeV6uJZ8y+nrwJNmqNflwAlj7923XGe7kW///xD4g1nqPFbO8eQgYvS9Z4yfh9XSnmPb7wFcseO8Tdi+7BhW6nM9eUbxe+RbcmuWqdd7gI1Ttp9Yyjti5L0XAG8rP58BbJ7y+98DHjXy73WlnofuTDss0kzUYyNiL3KHuw9wl6YdI+LfIuLqiLg58mzTe4HHl80bybd/Lmt57H0j4pCIeE5E3NRw3C9FxA0R8fOIOId8H/nRZfNNwGWRp0x/GRHnkp+rOa6hrC9Evq1xY0S8hjzAHN+izkM2c1vuENnXyOfxFQApP0h8LvBU4A7kvzRenFJ6zJSizittebeIeFhEfHWGY18BfLIc61YppTXAu8mB2XOXK2daWQusTVueB1xKDlj2Jg9q7ynbtpX3Ru3NhCn+Ea8vbXlARPxeRHyvYb8zyQHS/uSZzPMZmYlapt+OG6/n3sC2KKPyAmjd9xo8B/hGRFzSsL3tebqytOX6iDimjI+tRcS3IuLKiLglIr4IvBk4ZcY6T6v/js8w7Xqch67aE8jJT8CngLdGxPsn7dNiDHtAROwXERsi4uURsbQT9Xow+Q7EKVFmB1NKBwLPIz8/OYtJ1yTsZJsuUhAFQER8jvxX6HIPZd/m18gzGZAfKnteeUJ/K/k5pfNSSi/ptKK3P+43uP10Y5uBd7SsVaGyLdeSH0qGfB/80oi4MPKzSd8hP5zYmCm3E0aPS3kY/WzyQ5gnR36OoKqs1WDGtjyGPGO3PSK2kW+p7AhWtgD3Gsu8OZrlH/6dxTHkGa1rIuLn5IfKj00pNX3hTOtrW0q9uq7jiqrse6MeDjxuZBx9CPCGlNJbyvahnKfxsX9anUddCqxNKR0+8t5g27qD9tzxwP2ngI9HxKuX2X3FxrCU0v3JM81/FBGfGdl0LPArwLdKe76Z3K+3NmQCTromr4qRW5ZVdmYaa6VejN1yI2dWbSc//T9p/1OAPclB4iPIkeYJZdv+5IeJd7x+QM7S23OWY0+p477AI4E9yBfYaaWOR5Tt68lTkaeTp5VPIU9d3+52Hjl77zjy7MoewIuAHwP7z7stVrItS/s9i5zRlcid5ofA88r2DeS/Lh5Wtm8gPxPwzIZjbwTeM2M9TwMOLj8fAnwOOH9k+1nAJU3XTZuyFvVV0S//mRzA3LG83gp8cWT7JeQvgT2Ax5FnX+/aUNYm4FUz1vNdwIfJt/XWkTOzrijbpvbbCWU9m5y8cBD5ttEW4Nnzboue2mu3cl6eDfxL+XndyHkbHUe/CLwQ2KfteSLPolze4nPsXupyOXl834P/X8Ls98fGiyuA02ep84TjnEt+5vLO5PH4OuCoebdjT+25Nzkj7y0Nv9tqDCMHr/ee8XOsK3V5H/m23x7AbmXb/ciPazyx4ToYbc/nA18CDmg4zqPIt/7vW66FzwKv3el2mPeFUHOxlPfeBny4Yf/Plwv+evLDY4331yeV3Wb72AX8FXLAdi35C+HEsX2OJz8suY18b/74kW1nAWeVn48iz1xtB64m3+t+0LzbYaXbkhxEfZIcbG4j/3X4MkaeqwCeAPxHOe+Xk1NdJ957p10Q9epS3vby33dQgtgyiAT5mZxtI6/TyvaDy78PXq6sRX5V9MvDgE+Ua/qa0raHj2w/lPycyk3kJIxp/XITswdR+5Nv6f+o9M3NwLFl29R+W/rstpF/J+B1pf7XlJ8H/zxUZXudUa7z0demhn0v5rbPRM18nmgfRF02oV6Hlm3vL9fXNuDblD+4Zqzzy4ALRv69Hvho6bf/Czx53m3YV3uS/7iP8llHx7SqMYx2QdSmCfU6o2x7F/l5udE6bZny+TaP/Ps243B574XkoOz6UvbuO9sOLkAsSZJUYeGeiZIkSRoCgyhJkqQKBlGSJEkVDKIkSZIqGERJkiRVWLuSBztxzammAs7BRUsf7Px/0rkIbXnhlV+f+P4jD9zZtauby++q7CZ9tCU0t2ef57Bt2X3v34W2x+yjPZe2Ht6qb7Y5f0M61231XcfV1DebNB2zrbbXUZ92tm86EyVJklTBIEqSJKmCQZQkSVIFgyhJkqQKBlGSJEkVVjQ7b0jaZgEMKctktes7Q6OrrJZd4ZroIoumqYy+z3efde9q/5XU52eZ1+fuoi8vQmbhULQ9J31+z84jk28SZ6IkSZIqGERJkiRVMIiSJEmqYBAlSZJUwSBKkiSpwkJm580jM6htXeaRHTKUbIWdtchZMYua6dO23vP4PH2f26G30awWoW3msQ7irjqeTtNVO/R93DZW+vp3JkqSJKmCQZQkSVIFgyhJkqQKBlGSJEkVDKIkSZIqDCI7bx6ZQUPKouoqa6SpnIuWWldpVVtNmSFdWYSMrr77ya6qzyy0eWThNZXT9zqIQxlnu8he77vvtL3m2rTnSvd7Z6IkSZIqGERJkiRVMIiSJEmqYBAlSZJUYRAPls/jAbEhLRWxCEtu7KwhLY+ziOevb332tb6XimhiO9/WPB60bzrmIi/hM/TlYBbhuu9zzF7p5X2ciZIkSapgECVJklTBIEqSJKmCQZQkSVIFgyhJkqQKKSJW7GAnrjl15Q6mW1209MHUdZlNbTmkLLy2hrRMSFNd1hzw3c7bEmBp6+Gt+uYitOc8tM306aM9246zbdpnaH2zSRd1H0JbQr/t2VZXGbJ9Zjh2dS3O+r3pTJQkSVIFgyhJkqQKBlGSJEkVDKIkSZIqGERJkiRVGER2XhdZE109kd939kmfdW+yktl5fdqVsrya9NGWMKzM2a6yqLrIDOp7Ha4+MrqaMi27+CzzyLaadtw2uqpjU1366ptdtWcbfWcyNunzO7/tZzI7T5IkqUcGUZIkSRUMoiRJkioYREmSJFUwiJIkSaqwdt4VqNFnVkLfWX5t9u0qG6kPXdWhz0wpDcPQ1lsb0vhx0VJPFZlgHuvPdVWXRcjgHro256Ttueoqa6/P782+OBMlSZJUwSBKkiSpgkGUJElSBYMoSZKkCgZRkiRJFQaRnbcIGV1tMwH6XOtpCFlqfa9btNrs6p+/jb7XyJtHWww5o6uLDLe+107ropxF7YOLPNbOo0+t9Lp/zkRJkiRVMIiSJEmqYBAlSZJUwSBKkiSpgkGUJElShRQRK3awE9ecOvFgQ8ommIe+16Nac8B3U+tKLaOpLRfZkLK2mo550dIHO29LgKWth09sz9XYB/ts5yG0Z9u+2cX5WOQxvKtsrj7GWehurJ3HeoJ9lt/3tTVr33QmSpIkqYJBlCRJUgWDKEmSpAoGUZIkSRUMoiRJkios5Np5feo7U66LstuWc9FSJ8WvekO6Dlda3+vVtSmjSVd9s8+14vpeW24WfY5hfbdZ2/M0j+twKONsn+u5zmOt2LaG0gediZIkSapgECVJklTBIEqSJKmCQZQkSVIFgyhJkqQKK7p2Xtv1udo8fT+vtZv6XHeqyRDWdFqNa+ctgl1h7by+M2RX+1qIXa2d14V5ZbzO4zP11TfnMdZ2lfnW1f59lTGtnFm/N52JkiRJqmAQJUmSVMEgSpIkqYJBlCRJUoVBP1jehUV+SLUrQ3h4tUmfS22sRiv98OqQEidWoz7as6txdh7L4Azpu6DtddtHAg+075tNukjI6rsvz+OBcx8slyRJmgODKEmSpAoGUZIkSRUMoiRJkioYREmSJFVY0ey8eWR0dVH2tPIXIXtpyNl5bSxCdl5Xy03sCktLNNmVMmqH3DfbXMuLsLxWV2Wv5PJa0O8yPou8LE/fdZ+1bzoTJUmSVMEgSpIkqYJBlCRJUgWDKEmSpAoGUZIkSRUWMjtvHhYh02cls0YWuS0XwUpnAPW5ruW81uca0pp9Q+ibQ8okntcabF3YlTNnmyxCX2vLtfMkSZJ6ZBAlSZJUwSBKkiSpgkGUJElSBYMoSZKkCmtX8mCLkOHWZB7ZBG2P2Zw10rpKnVuEta+GdB0OuS3b6uo67vu4bdbk7Cobacjt2cUabPPK5uvimE36rEub481jvOo707btcdvUpa1Z+6YzUZIkSRUMoiRJkioYREmSJFUwiJIkSapgECVJklRhRdfOkyRJWi2ciZIkSapgECVJklTBIEqSJKmCQZQkSVIFgyhJkqQKBlGSJEkVDKIkSZIqGERJkiRVMIiSJEmqYBAlSZJUwSBKkiSpgkGUJElSBYMoSZKkCgZRkiRJFQyiJEmSKhhESZIkVTCIkiRJqmAQJUmSVMEgSpIkqYJBlCRJUgWDKEmSpAoGUZIkSRUMoiRJkir8Hwj9YtSJBBFuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 다층퍼셉트론 신경망 모델\n",
    "\n",
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "x_train_1d = x_train.reshape(x_train.shape[0], width*height)\n",
    "x_val_1d = x_val.reshape(x_val.shape[0], width*height)\n",
    "x_test_1d = x_test.reshape(x_test.shape[0], width*height)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim = width*height))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train_1d, y_train, batch_size=32, epochs=1000, validation_data=(x_val_1d, y_val))\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 300.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test_1d, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test_1d, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다층퍼셉트론 모델의 입력층인 Dense 레이어는 일차원 벡터로 데이터를 입력 받기 때문에, 이차원인 영상을 일차원 벡터로 변환하는 과정이 필요하다.<br>\n",
    "\n",
    "    x_train_1d = x_train.reshape(x_train.shape[0], width*height)\n",
    "    x_val_1d = x_val.reshape(x_val.shape[0], width*height)\n",
    "    x_test_1d = x_test.reshape(x_test.shape[0], width*height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 12222.2133 - val_loss: 1884.5809\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 1507.7118 - val_loss: 1236.7421\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 1076.2798 - val_loss: 944.1272\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 835.1447 - val_loss: 768.8631\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 670.7571 - val_loss: 593.3357\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 521.5853 - val_loss: 445.2146\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 409.9650 - val_loss: 393.9939\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 329.6340 - val_loss: 281.0722\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 299.4243 - val_loss: 271.3052\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 286.1930 - val_loss: 254.2499\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 269.0778 - val_loss: 228.4655\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 261.0245 - val_loss: 217.2174\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 253.8411 - val_loss: 205.0997\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 242.9360 - val_loss: 204.8711\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 237.9776 - val_loss: 178.4353\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 224.2309 - val_loss: 176.4904\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 217.8832 - val_loss: 201.2341\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 211.1895 - val_loss: 171.2986\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 202.1109 - val_loss: 159.0878\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 198.8695 - val_loss: 155.4002\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 206.4012 - val_loss: 175.5293\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 193.2076 - val_loss: 152.9373\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 192.6556 - val_loss: 158.3037\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 184.6112 - val_loss: 166.1375\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 180.5337 - val_loss: 149.2900\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 180.6645 - val_loss: 152.5731\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 186.8215 - val_loss: 152.9170\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 180.2578 - val_loss: 158.8835\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 171.2504 - val_loss: 148.3548\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 170.4513 - val_loss: 163.3741\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 179.2467 - val_loss: 157.0267\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 178.3535 - val_loss: 144.0349\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 168.9847 - val_loss: 159.1903\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 162.7204 - val_loss: 146.9550\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 162.2654 - val_loss: 147.8124\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 159.3667 - val_loss: 141.1121\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 166.7388 - val_loss: 143.2247\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 162.0491 - val_loss: 145.9235\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 156.3616 - val_loss: 142.8516\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 151.6138 - val_loss: 210.3361\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 166.1453 - val_loss: 151.2297\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 158.2450 - val_loss: 146.2001\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 155.9841 - val_loss: 142.0315\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 156.2954 - val_loss: 140.1650\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 153.6643 - val_loss: 138.2351\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 169.0174 - val_loss: 141.1719\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 174.7565 - val_loss: 152.7087\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 161.1858 - val_loss: 146.7303\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 143.6363 - val_loss: 167.5834\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 149.7436 - val_loss: 138.0633\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 149.2912 - val_loss: 144.6179\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 149.0584 - val_loss: 144.9344\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 144.6593 - val_loss: 135.8065\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 136.8954 - val_loss: 162.7269\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 134.6301 - val_loss: 146.0511\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 147.9935 - val_loss: 139.7074\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 128.4010 - val_loss: 133.9775\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 134.3170 - val_loss: 135.5094\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 124.0230 - val_loss: 151.7836\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 126.6385 - val_loss: 137.4393\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 117.4468 - val_loss: 142.3932\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 124.1732 - val_loss: 134.6718\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 121.6988 - val_loss: 132.4994\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 116.6159 - val_loss: 133.6909\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 121.4782 - val_loss: 135.8715\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 116.9096 - val_loss: 133.4272\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 112.8011 - val_loss: 142.1391\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 116.1898 - val_loss: 133.5985\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 113.3899 - val_loss: 132.3162\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 107.2369 - val_loss: 132.6026\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 108.5749 - val_loss: 140.9366\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 105.5529 - val_loss: 133.1038\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 107.0454 - val_loss: 137.0475\n",
      "Epoch 74/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 105.3028 - val_loss: 133.3090\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 109.9435 - val_loss: 141.9384\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 101.7891 - val_loss: 131.5233\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 107.7516 - val_loss: 166.9537\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 100.8312 - val_loss: 137.7261\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 96.2455 - val_loss: 133.7664\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 96.1805 - val_loss: 132.6748\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 93.5083 - val_loss: 153.6950\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 94.3386 - val_loss: 132.6453\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 104.5541 - val_loss: 133.6712\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 90.7724 - val_loss: 154.3334\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 91.6317 - val_loss: 183.5261\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 93.7199 - val_loss: 134.7480\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 91.0534 - val_loss: 138.5751\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 89.5063 - val_loss: 134.9249\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 86.0528 - val_loss: 134.6514\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 88.9626 - val_loss: 134.9846\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 88.7055 - val_loss: 134.3147\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 86.4773 - val_loss: 145.8479\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 83.5817 - val_loss: 134.2842\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 95.9879 - val_loss: 134.9194\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 89.4937 - val_loss: 133.3581\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 86.7151 - val_loss: 155.9695\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 84.9656 - val_loss: 134.2794\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 77.2680 - val_loss: 138.6112\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 77.7982 - val_loss: 136.7586\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 76.4054 - val_loss: 135.7737\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 81.2152 - val_loss: 146.9829\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 73.5605 - val_loss: 143.8660\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 71.5007 - val_loss: 138.3838\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 75.2491 - val_loss: 142.5541\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 76.3742 - val_loss: 135.1820\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 78.4718 - val_loss: 148.8591\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 66.3597 - val_loss: 145.2055\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 67.5195 - val_loss: 142.0704\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 70.9860 - val_loss: 136.5886\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 67.0493 - val_loss: 138.9128\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 62.9032 - val_loss: 145.3109\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 62.1289 - val_loss: 136.6080\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 64.6543 - val_loss: 145.1754\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 62.5543 - val_loss: 138.9178\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 61.4830 - val_loss: 137.1328\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 64.8348 - val_loss: 137.8931\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 60.4866 - val_loss: 140.0162\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 64.9067 - val_loss: 139.4457\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 61.2399 - val_loss: 139.1804\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 61.9414 - val_loss: 144.2417\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 62.2806 - val_loss: 158.0198\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 58.4897 - val_loss: 139.3797\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 54.9802 - val_loss: 140.3554\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 54.8712 - val_loss: 151.1131\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 55.4434 - val_loss: 153.9873\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 54.5860 - val_loss: 146.8075\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 58.5321 - val_loss: 143.8636\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 53.3259 - val_loss: 139.1950\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 65.8604 - val_loss: 204.7593\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 57.4758 - val_loss: 145.4952\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 52.0574 - val_loss: 149.0914\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 52.7077 - val_loss: 164.7506\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 48.2719 - val_loss: 149.9907\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 45.9027 - val_loss: 139.4018\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 66.5887 - val_loss: 170.8928\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 54.7793 - val_loss: 160.4344\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 44.3507 - val_loss: 146.9747\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 50.8957 - val_loss: 151.2944\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 42.3731 - val_loss: 159.6075\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 49.9933 - val_loss: 161.0740\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 43.5130 - val_loss: 151.8840\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 39.9824 - val_loss: 144.1278\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 42.7168 - val_loss: 140.8702\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 52.1718 - val_loss: 151.3615\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 42.6380 - val_loss: 152.0771\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 136us/step - loss: 39.9636 - val_loss: 145.9347\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 39.4822 - val_loss: 153.6866\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 40.2980 - val_loss: 154.1042\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 36.0588 - val_loss: 156.6832\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 38.0312 - val_loss: 143.9801\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 33.3622 - val_loss: 153.8092\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 34.7287 - val_loss: 151.2723\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 33.3120 - val_loss: 147.3814\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 32.2677 - val_loss: 159.2563\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 32.3957 - val_loss: 150.6488\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 29.8039 - val_loss: 147.8831\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 29.5032 - val_loss: 163.0180\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 28.7207 - val_loss: 148.6657\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 28.1609 - val_loss: 150.7253\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 28.0323 - val_loss: 150.6464\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 32.4768 - val_loss: 148.9230\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 26.8933 - val_loss: 155.0635\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 25.2909 - val_loss: 151.0104\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 29.2664 - val_loss: 157.5115\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 24.0930 - val_loss: 155.6162\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 24.4568 - val_loss: 152.7005\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 23.9266 - val_loss: 164.9624\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 25.0566 - val_loss: 173.0440\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 36.9474 - val_loss: 159.0412\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 21.6768 - val_loss: 152.4391\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 22.6210 - val_loss: 151.7609\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 21.7488 - val_loss: 158.1756\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 18.9548 - val_loss: 154.0423\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 18.4069 - val_loss: 158.1648\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 17.8811 - val_loss: 156.7483\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 18.9417 - val_loss: 158.0112\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 20.6889 - val_loss: 153.3567\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 16.4550 - val_loss: 157.4194\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 16.0972 - val_loss: 157.6508\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 21.2990 - val_loss: 154.5574\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 22.2256 - val_loss: 156.1712\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 18.0376 - val_loss: 153.8341\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 16.0015 - val_loss: 158.9431\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 13.3753 - val_loss: 159.0318\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 13.9591 - val_loss: 160.8539\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 14.2262 - val_loss: 159.7531\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 13.9787 - val_loss: 163.2336\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 12.5541 - val_loss: 171.8884\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 14.4338 - val_loss: 161.9346\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 12.2287 - val_loss: 160.3233\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 13.1625 - val_loss: 160.1248\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 13.8920 - val_loss: 161.4779\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 11.4061 - val_loss: 163.0801\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 11.0506 - val_loss: 161.9208\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 10.2108 - val_loss: 161.9784\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 9.3839 - val_loss: 162.1684\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 8.6943 - val_loss: 163.1968\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 9.5575 - val_loss: 161.6911\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 9.0846 - val_loss: 163.9280\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 8.3302 - val_loss: 163.1743\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 7.7660 - val_loss: 166.5201\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 9.5253 - val_loss: 163.3943\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 7.1943 - val_loss: 166.7146\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 7.9912 - val_loss: 171.9813\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 6.9895 - val_loss: 166.2537\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 6.5083 - val_loss: 166.0907\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 6.0638 - val_loss: 166.0976\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 5.5932 - val_loss: 162.7711\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 7.7298 - val_loss: 169.3708\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 8.5770 - val_loss: 164.4173\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 6.9642 - val_loss: 168.7238\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 5.9377 - val_loss: 169.7895\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 6.0297 - val_loss: 167.0726\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 5.1975 - val_loss: 166.6294\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 4.4287 - val_loss: 167.0254\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 4.5933 - val_loss: 169.6262\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 5.5701 - val_loss: 172.6644\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 7.4792 - val_loss: 166.4565\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 3.9205 - val_loss: 167.7230\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 3.3935 - val_loss: 169.2022\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 4.0711 - val_loss: 167.4592\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 4.9431 - val_loss: 169.4586\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 4.3400 - val_loss: 180.4919\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 7.4020 - val_loss: 165.5931\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 3.7451 - val_loss: 171.2380\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 2.6912 - val_loss: 171.1418\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 2.4885 - val_loss: 171.7737\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 2.3804 - val_loss: 171.1190\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 2.5188 - val_loss: 171.6747\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 2.4889 - val_loss: 169.9588\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 2.7162 - val_loss: 174.6901\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 3.3668 - val_loss: 170.7698\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 4.9567 - val_loss: 175.7288\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 2.7508 - val_loss: 172.7404\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 1.8700 - val_loss: 173.0587\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 1.5649 - val_loss: 172.6519\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 3.0878 - val_loss: 172.3568\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.6748 - val_loss: 172.7719\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 1.7719 - val_loss: 173.8126\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 1.5199 - val_loss: 174.5181\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 1.6655 - val_loss: 174.1384\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 1.6747 - val_loss: 174.5424\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.3736 - val_loss: 179.3888\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 1.7976 - val_loss: 178.0025\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 1.3643 - val_loss: 173.4952\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 1.1385 - val_loss: 174.8430\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 1.1114 - val_loss: 174.9843\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 1.3997 - val_loss: 177.2945\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 1.0900 - val_loss: 176.4957\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.9215 - val_loss: 176.1692\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.7657 - val_loss: 175.6301\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.8040 - val_loss: 176.1039\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.9802 - val_loss: 175.4125\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.0028 - val_loss: 175.5707\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 1.9562 - val_loss: 176.4216\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 1.5414 - val_loss: 173.9395\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 1.1763 - val_loss: 177.6945\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 1.7703 - val_loss: 175.7076\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.9411 - val_loss: 177.1727\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.6877 - val_loss: 175.1717\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.9569 - val_loss: 178.7157\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 1.5138 - val_loss: 173.0148\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 3.0898 - val_loss: 176.3984\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.8408 - val_loss: 174.8187\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.8565 - val_loss: 175.5690\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 2.0577 - val_loss: 176.5784\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.9321 - val_loss: 176.8623\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.7688 - val_loss: 176.5059\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.5325 - val_loss: 179.6919\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 1.0023 - val_loss: 176.5361\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 2.5443 - val_loss: 179.6423\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.8765 - val_loss: 178.6524\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 2.9729 - val_loss: 178.1958\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.8365 - val_loss: 177.0898\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.7497 - val_loss: 176.0828\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 1.0058 - val_loss: 175.5097\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.6929 - val_loss: 177.3299\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.9693 - val_loss: 176.0466\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.8083 - val_loss: 176.1760\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.0724 - val_loss: 177.2316\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.5365 - val_loss: 176.6982\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.7104 - val_loss: 177.6079\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.7976 - val_loss: 180.4861\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.5691 - val_loss: 177.8332\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.3324 - val_loss: 176.7926\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.2608 - val_loss: 177.0885\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.2642 - val_loss: 178.6641\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.3927 - val_loss: 177.8467\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.6549 - val_loss: 177.4991\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 2.7765 - val_loss: 175.9692\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 1.5927 - val_loss: 177.9663\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.4196 - val_loss: 177.0863\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 2.3871 - val_loss: 174.2967\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 138us/step - loss: 4.2278 - val_loss: 177.9028\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.2139 - val_loss: 178.1817\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.7347 - val_loss: 176.8055\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.6983 - val_loss: 177.7742\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 2.6155 - val_loss: 174.4046\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 1.8087 - val_loss: 178.5001\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.5822 - val_loss: 177.0027\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.6530 - val_loss: 176.5303\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.3850 - val_loss: 176.1635\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 1.0247 - val_loss: 176.4599\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.6216 - val_loss: 178.0049\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.3591 - val_loss: 176.6961\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.9511 - val_loss: 178.3445\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 4.7879 - val_loss: 173.5956\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.1990 - val_loss: 175.5083\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.7628 - val_loss: 174.9998\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.9911 - val_loss: 176.5851\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.5089 - val_loss: 176.1708\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.3156 - val_loss: 176.9994\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.3461 - val_loss: 177.1818\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.5324 - val_loss: 176.6926\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.6782 - val_loss: 176.2367\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.3221 - val_loss: 176.6419\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.4362 - val_loss: 176.5310\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.4594 - val_loss: 177.7219\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.7886 - val_loss: 175.9768\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.0145 - val_loss: 175.9685\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.6986 - val_loss: 176.7580\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.7889 - val_loss: 175.7211\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.9283 - val_loss: 175.9237\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.0351 - val_loss: 176.1778\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 1.0214 - val_loss: 176.3202\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6939 - val_loss: 176.4074\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.9589 - val_loss: 175.9977\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.5897 - val_loss: 175.8061\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.5463 - val_loss: 175.8307\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.7939 - val_loss: 176.2961\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.3294 - val_loss: 176.8892\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 1.3754 - val_loss: 174.5955\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 4.9747 - val_loss: 172.6536\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 2.3284 - val_loss: 175.0269\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.6719 - val_loss: 177.0534\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.8271 - val_loss: 175.2563\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.4374 - val_loss: 175.1505\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.2442 - val_loss: 175.8088\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.2283 - val_loss: 176.0336\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.1622 - val_loss: 176.1191\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.4321 - val_loss: 176.1641\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.7920 - val_loss: 174.7284\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.5596 - val_loss: 178.2831\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.1079 - val_loss: 174.0172\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.9767 - val_loss: 176.6841\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.2064 - val_loss: 176.3868\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 2.1020 - val_loss: 185.2563\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 14.8385 - val_loss: 181.8873\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 3.1391 - val_loss: 173.7483\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 2.2921 - val_loss: 174.4335\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.0278 - val_loss: 172.5989\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.5266 - val_loss: 174.2732\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.5394 - val_loss: 174.8355\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.3177 - val_loss: 174.2325\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.1760 - val_loss: 173.9427\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.1770 - val_loss: 174.5196\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.2723 - val_loss: 174.7665\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.1963 - val_loss: 175.3144\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.1305 - val_loss: 174.5298\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.1668 - val_loss: 175.3062\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.2402 - val_loss: 174.9760\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.2238 - val_loss: 176.0912\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.1481 - val_loss: 174.7075\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.1392 - val_loss: 174.7151\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.2154 - val_loss: 174.9968\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.0046 - val_loss: 174.5289\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.6616 - val_loss: 175.2550\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 1.3648 - val_loss: 175.4858\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.7033 - val_loss: 174.6629\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.6011 - val_loss: 175.1268\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.5150 - val_loss: 173.8966\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.9967 - val_loss: 175.5996\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.7500 - val_loss: 176.2295\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.5849 - val_loss: 177.6628\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.3005 - val_loss: 177.4381\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.5298 - val_loss: 173.8461\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.5105 - val_loss: 174.3889\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.5353 - val_loss: 173.6206\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.2984 - val_loss: 174.5540\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.9755 - val_loss: 174.3471\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.2658 - val_loss: 176.2050\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 2.2499 - val_loss: 170.0571\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 3.1337 - val_loss: 176.2318\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.0613 - val_loss: 174.9785\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.7526 - val_loss: 175.0873\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.8653 - val_loss: 174.0073\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.0853 - val_loss: 179.7395\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.9451 - val_loss: 173.3352\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.5115 - val_loss: 176.1224\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.7937 - val_loss: 174.7774\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.4116 - val_loss: 174.3540\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.5392 - val_loss: 175.1363\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.5052 - val_loss: 174.4235\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.5036 - val_loss: 174.5513\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.6609 - val_loss: 173.4863\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.8193 - val_loss: 173.6133\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.6724 - val_loss: 176.3773\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 1.1842 - val_loss: 176.9172\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.2460 - val_loss: 173.8970\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.8178 - val_loss: 175.1631\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.3681 - val_loss: 174.0668\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.3005 - val_loss: 173.7014\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.2851 - val_loss: 174.2543\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.3039 - val_loss: 173.7827\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.3617 - val_loss: 173.5512\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.0820 - val_loss: 172.7295\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 4.0703 - val_loss: 178.8665\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.8902 - val_loss: 173.8702\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6002 - val_loss: 172.8125\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.2775 - val_loss: 174.1742\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.2817 - val_loss: 173.1706\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.2924 - val_loss: 174.0844\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.3906 - val_loss: 174.5006\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.4770 - val_loss: 179.7266\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 4.5094 - val_loss: 175.0681\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.9287 - val_loss: 175.2222\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.0896 - val_loss: 174.9326\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.3509 - val_loss: 173.9766\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.3568 - val_loss: 174.6563\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.3274 - val_loss: 174.8006\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.4726 - val_loss: 175.7154\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.7907 - val_loss: 174.2189\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.7602 - val_loss: 173.2786\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.3625 - val_loss: 175.0313\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.5145 - val_loss: 173.4510\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.4358 - val_loss: 174.2660\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.8226 - val_loss: 175.4601\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.6453 - val_loss: 173.8571\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.3293 - val_loss: 175.3110\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.5902 - val_loss: 174.0837\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.3838 - val_loss: 174.3006\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.1920 - val_loss: 173.1556\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.1852 - val_loss: 174.8978\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.2098 - val_loss: 174.8398\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.2608 - val_loss: 173.5776\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.2199 - val_loss: 174.3377\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.3220 - val_loss: 173.5454\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 1.2629 - val_loss: 176.4342\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 2.0620 - val_loss: 174.7291\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 2.1997 - val_loss: 170.1581\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.7541 - val_loss: 176.0303\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 134us/step - loss: 1.9893 - val_loss: 172.8248\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 2.9630 - val_loss: 173.2534\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 2.6021 - val_loss: 176.1154\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 1.8364 - val_loss: 173.2341\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.0252 - val_loss: 172.6318\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.0401 - val_loss: 173.6619\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.6985 - val_loss: 172.6968\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6466 - val_loss: 173.6653\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.8966 - val_loss: 174.4870\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.6101 - val_loss: 175.4464\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.3897 - val_loss: 173.6368\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.5475 - val_loss: 173.4897\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6302 - val_loss: 173.6687\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.3003 - val_loss: 172.8368\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.0992 - val_loss: 170.2972\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.8545 - val_loss: 172.5042\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.3206 - val_loss: 172.5390\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.1667 - val_loss: 173.2464\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.1546 - val_loss: 173.6032\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.9472 - val_loss: 173.3926\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.8558 - val_loss: 172.8620\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.7563 - val_loss: 171.9220\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 2.7934 - val_loss: 172.9165\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 2.6300 - val_loss: 175.0140\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 2.2877 - val_loss: 176.4337\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.2854 - val_loss: 174.3779\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.6266 - val_loss: 172.8641\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.5421 - val_loss: 173.3857\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.4689 - val_loss: 172.2739\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.7501 - val_loss: 172.9016\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.2872 - val_loss: 174.5141\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.8355 - val_loss: 174.6916\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.4387 - val_loss: 173.3172\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.8103 - val_loss: 173.9544\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.3975 - val_loss: 174.5081\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6278 - val_loss: 174.0768\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.3860 - val_loss: 172.6845\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.2967 - val_loss: 173.0791\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.4549 - val_loss: 172.7346\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.2338 - val_loss: 173.2319\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.4293 - val_loss: 172.5197\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.1941 - val_loss: 173.4772\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.2296 - val_loss: 173.0176\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 1.4435 - val_loss: 173.5908\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.4718 - val_loss: 178.4160\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 1.2668 - val_loss: 173.3282\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.5260 - val_loss: 173.0889\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.2814 - val_loss: 172.2313\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.3629 - val_loss: 172.4475\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.2134 - val_loss: 173.2677\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.1398 - val_loss: 172.4734\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.3598 - val_loss: 172.8720\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.4774 - val_loss: 171.3669\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.6297 - val_loss: 173.3190\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.5688 - val_loss: 172.0563\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.3928 - val_loss: 173.8536\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 2.1076 - val_loss: 174.0627\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.4202 - val_loss: 168.7345\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.8431 - val_loss: 171.8892\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.8186 - val_loss: 170.9136\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 2.5729 - val_loss: 172.7108\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 4.2354 - val_loss: 173.6248\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 2.2487 - val_loss: 172.3775\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 1.0263 - val_loss: 173.1676\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.6911 - val_loss: 172.3602\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.3574 - val_loss: 172.8493\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.5153 - val_loss: 173.4048\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.2676 - val_loss: 173.0938\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.1715 - val_loss: 172.4297\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.1536 - val_loss: 172.6208\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.5132 - val_loss: 173.4919\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.2901 - val_loss: 172.8799\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.3534 - val_loss: 174.4071\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.3681 - val_loss: 172.7462\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 1.1958 - val_loss: 172.4593\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 1.1051 - val_loss: 172.3680\n",
      "Epoch 518/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 2.1026 - val_loss: 175.4519\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 1.0277 - val_loss: 173.5811\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6464 - val_loss: 171.6499\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.4391 - val_loss: 172.2645\n",
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.2470 - val_loss: 171.8634\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.3654 - val_loss: 173.1196\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.3423 - val_loss: 172.3201\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.2677 - val_loss: 173.1832\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.2517 - val_loss: 172.6872\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.4408 - val_loss: 174.1145\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.1888 - val_loss: 172.4920\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.3375 - val_loss: 172.8951\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.5713 - val_loss: 171.1464\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.7759 - val_loss: 169.8175\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.5256 - val_loss: 172.0704\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.5911 - val_loss: 171.3219\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.3078 - val_loss: 172.1797\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.5465 - val_loss: 173.6277\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 3.8897 - val_loss: 221.6972\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 11.6380 - val_loss: 178.8323\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 5.8858 - val_loss: 173.7217\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 1.4616 - val_loss: 174.0313\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 1.0960 - val_loss: 171.3752\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.4312 - val_loss: 172.1342\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.3096 - val_loss: 170.9042\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.7730 - val_loss: 170.8385\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6551 - val_loss: 172.4225\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.3963 - val_loss: 171.0830\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.3381 - val_loss: 172.3208\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.5204 - val_loss: 171.3644\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.3013 - val_loss: 171.7314\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.2648 - val_loss: 171.2480\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.1319 - val_loss: 171.4581\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.0939 - val_loss: 171.2980\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.0780 - val_loss: 171.4559\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.0725 - val_loss: 171.4292\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.0563 - val_loss: 171.6757\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.1134 - val_loss: 171.2218\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.0888 - val_loss: 171.5057\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.0636 - val_loss: 171.1759\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.0865 - val_loss: 171.5898\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.1008 - val_loss: 171.3837\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.1038 - val_loss: 171.1898\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.0631 - val_loss: 171.3156\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.0899 - val_loss: 171.6437\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.2255 - val_loss: 171.9298\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.5145 - val_loss: 171.9918\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.8299 - val_loss: 172.8622\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.5657 - val_loss: 171.9066\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 1.3958 - val_loss: 171.0211\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 1.1285 - val_loss: 170.7385\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 1.5898 - val_loss: 170.6340\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 1.4908 - val_loss: 177.1093\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 31.7711 - val_loss: 161.7622\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 7.0648 - val_loss: 167.3684\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 2.6460 - val_loss: 169.7909\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 1.6809 - val_loss: 168.0891\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.7626 - val_loss: 168.9810\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.5544 - val_loss: 170.1517\n",
      "Epoch 577/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.4092 - val_loss: 170.5062\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.2176 - val_loss: 170.1143\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.1825 - val_loss: 169.6401\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.1356 - val_loss: 170.6711\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.1983 - val_loss: 170.9810\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2085 - val_loss: 170.0309\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1082 - val_loss: 170.3725\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.1920 - val_loss: 170.4579\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.1203 - val_loss: 169.9028\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0901 - val_loss: 170.5015\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1172 - val_loss: 170.5058\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 0.0801 - val_loss: 170.1405\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 0s 169us/step - loss: 0.0652 - val_loss: 170.6296\n",
      "Epoch 590/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.0652 - val_loss: 170.6062\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0510 - val_loss: 170.1068\n",
      "Epoch 592/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.0596 - val_loss: 170.7671\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.0655 - val_loss: 170.7613\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0522 - val_loss: 170.7939\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.0500 - val_loss: 170.7238\n",
      "Epoch 596/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0591 - val_loss: 170.7550\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0890 - val_loss: 170.6081\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0721 - val_loss: 170.7910\n",
      "Epoch 599/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0649 - val_loss: 170.6670\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0425 - val_loss: 170.6850\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0358 - val_loss: 170.5192\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.0315 - val_loss: 170.8627\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.0390 - val_loss: 170.6749\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0636 - val_loss: 170.7828\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1013 - val_loss: 170.6106\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1404 - val_loss: 170.8278\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3929 - val_loss: 173.2520\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.3345 - val_loss: 170.9988\n",
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1937 - val_loss: 169.7259\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.9183 - val_loss: 171.5629\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 5.0278 - val_loss: 195.4362\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 7.6454 - val_loss: 172.6610\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 2.9025 - val_loss: 175.7597\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.4760 - val_loss: 170.9349\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 1.4538 - val_loss: 169.3476\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.7275 - val_loss: 169.5793\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.5464 - val_loss: 168.6535\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.2641 - val_loss: 170.0828\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1696 - val_loss: 170.1963\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1553 - val_loss: 170.1731\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0971 - val_loss: 170.0799\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1201 - val_loss: 170.4169\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.0724 - val_loss: 170.0116\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1020 - val_loss: 170.3901\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0766 - val_loss: 170.2953\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1021 - val_loss: 170.0505\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0660 - val_loss: 170.3129\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0468 - val_loss: 170.4108\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1210 - val_loss: 172.0079\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.1209 - val_loss: 171.4359\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6443 - val_loss: 171.0390\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.5111 - val_loss: 170.7400\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.3157 - val_loss: 170.8801\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.4829 - val_loss: 170.5948\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 6.1066 - val_loss: 202.6823\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 10.6394 - val_loss: 169.4999\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 3.6578 - val_loss: 169.0073\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.9149 - val_loss: 170.7504\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.6596 - val_loss: 171.1936\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.4506 - val_loss: 169.9345\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.3079 - val_loss: 170.4295\n",
      "Epoch 642/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.4740 - val_loss: 169.8270\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.2392 - val_loss: 170.3905\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6082 - val_loss: 171.5099\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.4317 - val_loss: 169.9923\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.2274 - val_loss: 170.1046\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.1826 - val_loss: 169.4617\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0892 - val_loss: 170.0617\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1075 - val_loss: 170.1408\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1675 - val_loss: 169.8624\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.8332 - val_loss: 171.4635\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.3461 - val_loss: 169.7735\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2143 - val_loss: 170.0999\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1295 - val_loss: 170.0844\n",
      "Epoch 655/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.0630 - val_loss: 170.2072\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.0701 - val_loss: 169.9171\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0710 - val_loss: 170.3165\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1006 - val_loss: 171.0048\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0928 - val_loss: 170.5592\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1376 - val_loss: 170.4917\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4640 - val_loss: 169.3088\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.2248 - val_loss: 169.9288\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1391 - val_loss: 170.4805\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1078 - val_loss: 169.8421\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1120 - val_loss: 170.7939\n",
      "Epoch 666/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.5253 - val_loss: 167.9167\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 6.0821 - val_loss: 165.5398\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 5.7165 - val_loss: 169.3776\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.6117 - val_loss: 170.3210\n",
      "Epoch 670/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.9989 - val_loss: 169.8044\n",
      "Epoch 671/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.2782 - val_loss: 170.5424\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.6768 - val_loss: 170.8456\n",
      "Epoch 673/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.6669 - val_loss: 170.5245\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.7343 - val_loss: 168.4862\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4900 - val_loss: 169.5431\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2463 - val_loss: 169.1863\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1691 - val_loss: 170.0029\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1829 - val_loss: 169.8050\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0866 - val_loss: 169.2345\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0735 - val_loss: 169.4278\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.0969 - val_loss: 169.2890\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.6737 - val_loss: 171.2912\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.4330 - val_loss: 169.1463\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1795 - val_loss: 170.5399\n",
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1707 - val_loss: 169.9075\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.2554 - val_loss: 172.6286\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.1506 - val_loss: 170.6007\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.1919 - val_loss: 171.3030\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.0847 - val_loss: 168.5681\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 1.2318 - val_loss: 170.8992\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.8117 - val_loss: 171.1751\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 1.0010 - val_loss: 171.8340\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.7432 - val_loss: 169.0549\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.8388 - val_loss: 170.4721\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.3905 - val_loss: 169.3964\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.2380 - val_loss: 169.3780\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.5484 - val_loss: 169.1080\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.4270 - val_loss: 171.1350\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2931 - val_loss: 169.5777\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2783 - val_loss: 170.4606\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 1.9444 - val_loss: 171.1982\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 1.4623 - val_loss: 169.2067\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 1.5099 - val_loss: 168.0245\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 2.7377 - val_loss: 169.8134\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 3.9515 - val_loss: 168.5525\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 1.4814 - val_loss: 170.7457\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 3.0801 - val_loss: 168.8914\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.2035 - val_loss: 170.7753\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.4362 - val_loss: 171.2494\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.6120 - val_loss: 171.5617\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.3858 - val_loss: 169.1333\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1855 - val_loss: 169.2854\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2328 - val_loss: 170.5163\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2292 - val_loss: 171.3361\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4533 - val_loss: 171.0326\n",
      "Epoch 716/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.1427 - val_loss: 172.5914\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.8863 - val_loss: 170.9296\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.6909 - val_loss: 171.0880\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.3568 - val_loss: 169.3496\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.4046 - val_loss: 168.9094\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3809 - val_loss: 169.3155\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.2935 - val_loss: 169.5673\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1393 - val_loss: 170.2929\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0843 - val_loss: 169.5854\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1349 - val_loss: 169.5114\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1448 - val_loss: 170.6805\n",
      "Epoch 727/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4018 - val_loss: 171.7532\n",
      "Epoch 728/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 5.8161 - val_loss: 172.7754\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 2.9748 - val_loss: 169.5491\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.1300 - val_loss: 168.5252\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 1.0695 - val_loss: 168.7607\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.7067 - val_loss: 170.3247\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 1.0185 - val_loss: 171.4449\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.9247 - val_loss: 170.5098\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.4145 - val_loss: 170.7854\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.2026 - val_loss: 169.4491\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1287 - val_loss: 169.6675\n",
      "Epoch 738/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1543 - val_loss: 169.1547\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1048 - val_loss: 169.6728\n",
      "Epoch 740/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.0692 - val_loss: 169.9824\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.3123 - val_loss: 169.9123\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2591 - val_loss: 170.0490\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2308 - val_loss: 169.6737\n",
      "Epoch 744/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1896 - val_loss: 169.9928\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2169 - val_loss: 169.9715\n",
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.3120 - val_loss: 171.0163\n",
      "Epoch 747/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 2.2813 - val_loss: 169.5339\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 1.4164 - val_loss: 171.3628\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 1.0309 - val_loss: 171.1914\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.7330 - val_loss: 170.4944\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.4912 - val_loss: 169.9759\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4510 - val_loss: 170.6418\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.4398 - val_loss: 169.8319\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2599 - val_loss: 170.4014\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2497 - val_loss: 170.5076\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1575 - val_loss: 169.6253\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.1516 - val_loss: 169.4970\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2702 - val_loss: 170.3595\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1794 - val_loss: 170.1231\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 3.0729 - val_loss: 167.6743\n",
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 5.7304 - val_loss: 173.6794\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 4.2073 - val_loss: 174.7222\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 2.8175 - val_loss: 170.6834\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.2042 - val_loss: 170.4464\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.4659 - val_loss: 170.3171\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2720 - val_loss: 170.2584\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.3330 - val_loss: 169.9985\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1784 - val_loss: 169.5086\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2547 - val_loss: 170.2189\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1748 - val_loss: 169.3513\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1091 - val_loss: 169.6559\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2747 - val_loss: 169.6044\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3217 - val_loss: 169.4783\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2293 - val_loss: 169.7243\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.2384 - val_loss: 169.8218\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 2.3650 - val_loss: 169.6311\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.9479 - val_loss: 170.0746\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 10.9792 - val_loss: 167.2105\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 2.4587 - val_loss: 171.0171\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.9188 - val_loss: 170.1757\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4997 - val_loss: 169.4821\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.3940 - val_loss: 170.4426\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.5827 - val_loss: 169.9121\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.5214 - val_loss: 171.5885\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.4839 - val_loss: 169.2215\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4616 - val_loss: 169.3622\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3796 - val_loss: 170.2337\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.3088 - val_loss: 169.5000\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.0957 - val_loss: 169.4972\n",
      "Epoch 790/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1429 - val_loss: 169.6964\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2166 - val_loss: 169.9246\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2888 - val_loss: 169.7904\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.1222 - val_loss: 169.3958\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0937 - val_loss: 169.6868\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2447 - val_loss: 169.0903\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4190 - val_loss: 169.7061\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.4412 - val_loss: 169.9348\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.7026 - val_loss: 170.6973\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.9601 - val_loss: 169.1075\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.5547 - val_loss: 170.1027\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.3928 - val_loss: 168.9154\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.4004 - val_loss: 169.5938\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 1.2321 - val_loss: 168.7586\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 1.0670 - val_loss: 170.7928\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.8653 - val_loss: 169.3878\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.3109 - val_loss: 169.4394\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2150 - val_loss: 168.7873\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1535 - val_loss: 169.1257\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1525 - val_loss: 169.2414\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1599 - val_loss: 169.5156\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1300 - val_loss: 170.0098\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1235 - val_loss: 168.7612\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2773 - val_loss: 170.2592\n",
      "Epoch 814/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6647 - val_loss: 169.3757\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.8879 - val_loss: 170.3859\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 3.5603 - val_loss: 171.0451\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 3.6552 - val_loss: 169.7927\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 5.5157 - val_loss: 170.2849\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 1.6315 - val_loss: 170.7618\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 2.1591 - val_loss: 171.7296\n",
      "Epoch 821/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 1.2921 - val_loss: 168.9662\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.7776 - val_loss: 170.4414\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.3380 - val_loss: 170.1731\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1895 - val_loss: 169.6797\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1704 - val_loss: 169.9353\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1582 - val_loss: 169.3628\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1206 - val_loss: 168.8635\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0989 - val_loss: 169.9200\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2085 - val_loss: 169.1252\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1706 - val_loss: 169.0339\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1127 - val_loss: 169.1124\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.0964 - val_loss: 169.2834\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1011 - val_loss: 169.7208\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1547 - val_loss: 169.2071\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.8577 - val_loss: 168.0895\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.4043 - val_loss: 169.2459\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 1.2246 - val_loss: 168.6271\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6675 - val_loss: 170.7438\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.5759 - val_loss: 169.6831\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.2750 - val_loss: 170.1449\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6095 - val_loss: 169.8472\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.7321 - val_loss: 168.2797\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.3411 - val_loss: 169.6839\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.3341 - val_loss: 169.0373\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.4178 - val_loss: 169.4228\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 5.1901 - val_loss: 175.6101\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 7.2543 - val_loss: 181.6105\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 4.9622 - val_loss: 168.9675\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 2.2511 - val_loss: 170.0886\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 1.2732 - val_loss: 169.6565\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.5425 - val_loss: 168.4308\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.4466 - val_loss: 169.7297\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2179 - val_loss: 168.9435\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.2469 - val_loss: 168.3913\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1738 - val_loss: 168.8545\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1843 - val_loss: 168.0983\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1122 - val_loss: 168.5662\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0948 - val_loss: 169.0296\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0952 - val_loss: 169.3185\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0883 - val_loss: 169.3219\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0425 - val_loss: 168.6600\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.0395 - val_loss: 169.2121\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0747 - val_loss: 168.8564\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.4058 - val_loss: 167.9330\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1972 - val_loss: 168.6796\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2723 - val_loss: 169.7194\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 0.1941 - val_loss: 168.4653\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.1176 - val_loss: 168.7279\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.2757 - val_loss: 168.9138\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3665 - val_loss: 168.1634\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.8198 - val_loss: 168.7716\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 0.4998 - val_loss: 169.2014\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.8809 - val_loss: 169.7633\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.3467 - val_loss: 168.5323\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.4141 - val_loss: 169.1409\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.4298 - val_loss: 171.7476\n",
      "Epoch 877/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.4032 - val_loss: 169.0616\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 8.6523 - val_loss: 201.9775\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 6.9400 - val_loss: 165.7243\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 2.4243 - val_loss: 168.5590\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 1.5026 - val_loss: 168.5794\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.6693 - val_loss: 168.1097\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.4352 - val_loss: 168.7755\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.3971 - val_loss: 169.0353\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.2141 - val_loss: 169.0632\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.1424 - val_loss: 169.1992\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.1494 - val_loss: 169.1954\n",
      "Epoch 888/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.0823 - val_loss: 168.8925\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.0974 - val_loss: 168.9969\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.0757 - val_loss: 168.9228\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.0415 - val_loss: 169.1212\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.0633 - val_loss: 169.0672\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.0379 - val_loss: 169.1809\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.0361 - val_loss: 169.3060\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.0774 - val_loss: 169.4964\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.0738 - val_loss: 168.9834\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.2521 - val_loss: 169.0428\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.2278 - val_loss: 168.6317\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.5843 - val_loss: 170.7967\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.8144 - val_loss: 171.6522\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 1.1846 - val_loss: 169.8600\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.9184 - val_loss: 170.5119\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.5788 - val_loss: 169.4825\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.2657 - val_loss: 168.9184\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 2.0527 - val_loss: 169.1529\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 3.4237 - val_loss: 168.5777\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 2.7571 - val_loss: 168.0269\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.7050 - val_loss: 171.3918\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.7905 - val_loss: 171.0380\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.5954 - val_loss: 170.0599\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.3244 - val_loss: 168.9868\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.1929 - val_loss: 169.1981\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.4551 - val_loss: 169.3729\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.2168 - val_loss: 169.3462\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.2678 - val_loss: 169.5478\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.1832 - val_loss: 169.0031\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.0849 - val_loss: 168.9733\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.0396 - val_loss: 168.9207\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.0490 - val_loss: 168.9764\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.0420 - val_loss: 169.0658\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.0898 - val_loss: 168.5385\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.0868 - val_loss: 169.1368\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.2291 - val_loss: 169.1546\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 3.5123 - val_loss: 173.5863\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 2.0244 - val_loss: 169.4455\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.8633 - val_loss: 170.1681\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.6029 - val_loss: 169.5069\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.6445 - val_loss: 171.3588\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.7016 - val_loss: 169.3593\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.3853 - val_loss: 169.3050\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.2028 - val_loss: 169.3092\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.2569 - val_loss: 169.3649\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.2157 - val_loss: 168.4033\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.1463 - val_loss: 169.1641\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.1414 - val_loss: 168.9471\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.0814 - val_loss: 169.3579\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.0536 - val_loss: 168.6548\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.0389 - val_loss: 169.1420\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.0284 - val_loss: 168.9283\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.0951 - val_loss: 168.9223\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.0587 - val_loss: 169.7618\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.1639 - val_loss: 169.2954\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 3.1981 - val_loss: 169.3542\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 1.5248 - val_loss: 171.7789\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 1.0909 - val_loss: 167.7516\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.7018 - val_loss: 168.4954\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 1.5271 - val_loss: 169.6365\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.9992 - val_loss: 168.2819\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.5570 - val_loss: 168.0076\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.3948 - val_loss: 167.6181\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.3574 - val_loss: 169.9378\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.9186 - val_loss: 168.4136\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.7402 - val_loss: 168.6839\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 1.0195 - val_loss: 167.0602\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 1.4321 - val_loss: 169.4481\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 1.0749 - val_loss: 167.7977\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.7758 - val_loss: 167.3323\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.8948 - val_loss: 168.2338\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.4034 - val_loss: 167.7954\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.9838 - val_loss: 168.7085\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 2.5855 - val_loss: 171.6155\n",
      "Epoch 962/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 2.0328 - val_loss: 164.4636\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 1.1731 - val_loss: 167.4007\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.5381 - val_loss: 166.3441\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.3779 - val_loss: 166.9746\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.3539 - val_loss: 167.9990\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.1594 - val_loss: 168.2652\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.3274 - val_loss: 168.4837\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.1431 - val_loss: 168.7692\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.2945 - val_loss: 168.7562\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.5942 - val_loss: 167.7987\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.1938 - val_loss: 167.9887\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.2102 - val_loss: 168.6037\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.1113 - val_loss: 168.5516\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.0884 - val_loss: 168.0483\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.2352 - val_loss: 168.9424\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 1.2486 - val_loss: 168.6428\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 2.2190 - val_loss: 166.0625\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 3.3658 - val_loss: 170.2080\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 3.0445 - val_loss: 169.0268\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 2.5968 - val_loss: 168.0203\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 2.2894 - val_loss: 167.4686\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.6310 - val_loss: 168.1458\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.5283 - val_loss: 167.8847\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.3413 - val_loss: 168.9862\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.3871 - val_loss: 168.5324\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.2266 - val_loss: 169.2117\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.1280 - val_loss: 168.8103\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.1418 - val_loss: 168.2512\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.0588 - val_loss: 168.4133\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.0795 - val_loss: 168.3321\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.0709 - val_loss: 168.9520\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.1515 - val_loss: 168.3202\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.1554 - val_loss: 168.0753\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.2181 - val_loss: 168.6157\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.1077 - val_loss: 168.5897\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.2380 - val_loss: 168.3302\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.2431 - val_loss: 168.8135\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.5768 - val_loss: 168.1162\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 1.5084 - val_loss: 169.4655\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 89us/step\n",
      "207.56140014648437\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 컨볼루션 신경망 모델\n",
    "\n",
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=1000, validation_data=(x_val, y_val))\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 300.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 학습결과 비교\n",
    "다층퍼셉트론 신경망 모델과 컨볼루션 신경망 모델을 비교했을 때<br>\n",
    "현재 파라미터로는 다층퍼셉트론 신경망 모델의 정확도가 더 높았다.<br>\n",
    "라벨값이 모양 및 색상 등 이미지의 특성보다 단순히 1인 픽셀 개수와 관련이 있기 때문에 컨볼루션 신경망 모델이 크게 성능을 발휘 못했다.<br>\n",
    "<br>\n",
    "즉 영상 입력이라고 해서 컨볼루션 신경망 모델이 항상 좋은 성능이 나오는 것이 아니다.<br>\n",
    "어떤 모델이 성능이 좋게 나올지는 테스트를 해봐야겠지만, 워낙 모델을 다양하게 구성할 수 있고 여러 파라미터를 설정할 수 있으므로 모델을 개발하기 전에 데이터 특징을 분석하고 적절한 후보 모델들을 선정하는 것을 권장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
