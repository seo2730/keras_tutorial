{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영상입력 수치 예측 모델 레시피\n",
    "영상을 입력해서 수치를 예측하는 모델들에 대하여 알아보겠다.<br>\n",
    "수치 예측을 위한 영상 데이터셋을 생성해보고, 다층퍼셉트론 및 컨볼루션 신경망 모델을 구성 및 학습시켜보겠다.<br>\n",
    "이 모델은 고정된 지역에서 촬영된 영상으로부터 복잡도, 밀도 등을 수치화하는 문제를 풀 수 있다.<br>\n",
    "- CCTV 등 촬영 영상으로부터 미세먼지 지수 예측\n",
    "- 위성영상으로부터 녹조, 적조 등의 지수 예측\n",
    "- 태양광 패널의 먼지가 쌓여있는 정도 예측\n",
    "<br>\n",
    "\n",
    "### 1. 데이터셋 준비\n",
    "너비가 16, 높이가 16이고, 픽셀값으로 0과 1을 가지는 영상을 만들어보겠다.<br>\n",
    "임의의 값이 주어지면, 그 값만큼 반복하여 영상 내에 픽셀값이 1인 픽셀을 찍었다.<br>\n",
    "여기서 임의의 값을 라벨값으로 지정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "width = 16\n",
    "height =16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "    \n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "        \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples,1)\n",
    "\n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "        \n",
    "    return img.reshape(width,height,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋 생성( 훈련셋 : 1500개, 검증셋 : 300개, 시험셋 : 100개)\n",
    "\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#데이터셋 일부 가시화\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_train[i].reshape(width,height))\n",
    "    sub_plt.set_title('R ' + str(y_train[i][0]))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R(Real)은 픽셀값이 1인 픽셀 수를 의미한다. 한 번 표시한 픽셀에 다시 표시가 될 수 있기 때문에 실제 픽셀 수와 조금 차이가 있을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 레이어 준비\n",
    "- 2D Input data\n",
    "\n",
    "2차원의 입력 데이터이다.<br>\n",
    "주로 영상 데이터를 의미하며 너비 높이 채널 수로 구성되어있다.<br>\n",
    "\n",
    "- Conv2D\n",
    "\n",
    "필터를 이용하여 영상 특징을 추출하는 컨볼루션 레이어이다.<br>\n",
    "\n",
    "- MaxPooling2D\n",
    "\n",
    "영상에서 사소한 변화가 특징 추출에 크게 영향을 미치지 않도록 해주는 맥스풀링 레이어이다.<br>\n",
    "\n",
    "- Flatten\n",
    "\n",
    "2차원의 특징 맵을 전결합층으로 전달하기 위해 1차원 형식으로 바꿔준다.<br>\n",
    "\n",
    "- relu\n",
    "\n",
    "활성화 함수로 주로 Conv2D 은닉층에 사용된다.<br>\n",
    "\n",
    "### 3. 모델 준비\n",
    "영상입력 수치 예측을 하기 위해 다층퍼셉트론 신경망 모델, 컨볼루션 신경망 모델을 준비하였다.\n",
    "<br>\n",
    "- 다층퍼셉트론 신경망 모델\n",
    "\n",
    "      model = Sequential()\n",
    "      model.add(Dense(256, input_dim = width * height, activation = 'relu'))\n",
    "      model.add(Dense(256, activation = 'relu'))\n",
    "      model.add(Dense(256))\n",
    "      model.add(Dense(1))\n",
    "<br>\n",
    "\n",
    "- 컨볼루션 신경망 모델\n",
    "\n",
    "      model = Sequential()\n",
    "      model.add(Conv2D(32, (3,3),input_dim = (width, height, 1), activation = 'relu'))\n",
    "      model.add(MaxPooling2D(pool_size(2,2)))\n",
    "      model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "      model.add(MaxPooling2D(pool_size(2,2)))\n",
    "      model.add(Flatten())\n",
    "      model.add(Dense(256), activation = 'relu'))\n",
    "      model.add(Dense(1))    \n",
    "    \n",
    "### 4. 전체 소스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/duckbe/virtual/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 4531.4984 - val_loss: 502.6979\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 0s 67us/step - loss: 301.5262 - val_loss: 245.2407\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 208.6551 - val_loss: 190.3442\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 150.2709 - val_loss: 158.5467\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 101.3946 - val_loss: 133.8490\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 72.9046 - val_loss: 149.1762\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 0s 66us/step - loss: 56.4535 - val_loss: 118.9446\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 0s 67us/step - loss: 41.1626 - val_loss: 118.0269\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 43.1212 - val_loss: 126.9391\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 26.4327 - val_loss: 115.9829\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 19.3374 - val_loss: 111.6813\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 17.4631 - val_loss: 112.0572\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 12.2372 - val_loss: 109.7101\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 7.9206 - val_loss: 108.9737\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 6.6459 - val_loss: 107.8906\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 4.7479 - val_loss: 112.3543\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.7841 - val_loss: 108.2227\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.7277 - val_loss: 107.1198\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 1.9619 - val_loss: 109.1087\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 0s 67us/step - loss: 1.6051 - val_loss: 106.6026\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.3137 - val_loss: 107.3934\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.3666 - val_loss: 110.4204\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.8368 - val_loss: 110.3231\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.6027 - val_loss: 108.5532\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4649 - val_loss: 108.5192\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.3996 - val_loss: 108.4438\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2515 - val_loss: 108.7372\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1685 - val_loss: 108.0199\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2289 - val_loss: 108.9150\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2446 - val_loss: 109.2962\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.1547 - val_loss: 109.5453\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 0s 67us/step - loss: 0.1566 - val_loss: 108.9453\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.1461 - val_loss: 108.1594\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1250 - val_loss: 109.1298\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.1537 - val_loss: 107.8772\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 0s 67us/step - loss: 0.1920 - val_loss: 109.8837\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.5611 - val_loss: 110.4038\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 0.9717 - val_loss: 108.3983\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 1.4221 - val_loss: 111.5858\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 3.1397 - val_loss: 110.1263\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.3643 - val_loss: 112.1654\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 6.7844 - val_loss: 107.4906\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 0s 69us/step - loss: 5.9017 - val_loss: 111.8375\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 0s 69us/step - loss: 12.3758 - val_loss: 123.3974\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 17.2261 - val_loss: 115.3446\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 9.0656 - val_loss: 106.9219\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 3.5201 - val_loss: 119.6392\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 2.8697 - val_loss: 109.5694\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 4.5929 - val_loss: 108.8702\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 3.7967 - val_loss: 111.7220\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.5075 - val_loss: 109.0797\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.5230 - val_loss: 108.1780\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 3.7792 - val_loss: 112.7824\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 2.9467 - val_loss: 109.8645\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.2878 - val_loss: 105.6517\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 1.6693 - val_loss: 104.9812\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.2877 - val_loss: 107.3922\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.8079 - val_loss: 104.2653\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.7694 - val_loss: 105.8663\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5026 - val_loss: 104.9129\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.5483 - val_loss: 108.9723\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.2026 - val_loss: 104.5173\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 2.3231 - val_loss: 107.7557\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.2238 - val_loss: 106.6630\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 2.8606 - val_loss: 107.7541\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 3.9367 - val_loss: 120.4350\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 6.9652 - val_loss: 106.6175\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 4.9153 - val_loss: 105.0285\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 9.7290 - val_loss: 110.7910\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 24.4921 - val_loss: 118.7375\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 49.7722 - val_loss: 133.0728\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 26.6677 - val_loss: 108.8451\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 6.5602 - val_loss: 109.6564\n",
      "Epoch 74/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 3.3546 - val_loss: 105.8755\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 2.2045 - val_loss: 104.6588\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 2.1737 - val_loss: 101.7104\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.2641 - val_loss: 107.7161\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.6211 - val_loss: 104.9963\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.7470 - val_loss: 102.8214\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.5651 - val_loss: 103.1711\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.7122 - val_loss: 102.7800\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.6542 - val_loss: 102.5197\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3141 - val_loss: 102.0699\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3837 - val_loss: 101.6039\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.2317 - val_loss: 101.7394\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2978 - val_loss: 101.5316\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4463 - val_loss: 103.0293\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.3372 - val_loss: 101.6892\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1848 - val_loss: 102.9287\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.1214 - val_loss: 101.5925\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1350 - val_loss: 102.0098\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1953 - val_loss: 102.6253\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1398 - val_loss: 101.9413\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1118 - val_loss: 102.5193\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2776 - val_loss: 101.1921\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3065 - val_loss: 102.8258\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.8311 - val_loss: 102.7941\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.9261 - val_loss: 103.7849\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.1980 - val_loss: 104.1348\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 4.4276 - val_loss: 106.3394\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 17.9649 - val_loss: 105.5555\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 13.0971 - val_loss: 104.8056\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 15.4007 - val_loss: 132.9812\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 60.6035 - val_loss: 131.8950\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 48.2404 - val_loss: 105.9579\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 13.6141 - val_loss: 112.6182\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 3.8038 - val_loss: 108.8201\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.0473 - val_loss: 98.3194\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.4492 - val_loss: 100.7282\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.9286 - val_loss: 104.0669\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.7482 - val_loss: 101.7282\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.4543 - val_loss: 102.8352\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3429 - val_loss: 102.1779\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3433 - val_loss: 101.7671\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3038 - val_loss: 99.8818\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3514 - val_loss: 100.2544\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1702 - val_loss: 101.0634\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.0873 - val_loss: 100.6214\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.0573 - val_loss: 101.4606\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0339 - val_loss: 100.8488\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0882 - val_loss: 100.3924\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.0912 - val_loss: 101.7923\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.1257 - val_loss: 101.1309\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4006 - val_loss: 100.3814\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.2595 - val_loss: 101.4506\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5290 - val_loss: 101.8779\n",
      "Epoch 127/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2638 - val_loss: 101.7600\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2871 - val_loss: 100.9388\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.1309 - val_loss: 100.0497\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1367 - val_loss: 100.3058\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.0887 - val_loss: 100.7167\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1164 - val_loss: 100.3490\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.2226 - val_loss: 99.0192\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.7485 - val_loss: 106.3578\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 5.7015 - val_loss: 110.8631\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 7.4519 - val_loss: 112.2802\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 6.6698 - val_loss: 102.0259\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.8340 - val_loss: 100.3803\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 14.4871 - val_loss: 117.7097\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 6.6228 - val_loss: 104.1264\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.8678 - val_loss: 103.3577\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 4.3518 - val_loss: 99.9773\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 4.0060 - val_loss: 100.2339\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.9672 - val_loss: 99.0920\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.0247 - val_loss: 102.7425\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.5540 - val_loss: 99.6965\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.9272 - val_loss: 107.1956\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.2197 - val_loss: 99.2301\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.0533 - val_loss: 102.6850\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.9572 - val_loss: 99.1614\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.0855 - val_loss: 99.3468\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.9266 - val_loss: 99.7208\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8099 - val_loss: 101.6838\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.4444 - val_loss: 100.1913\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.0910 - val_loss: 100.7675\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.2634 - val_loss: 103.2548\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.7851 - val_loss: 101.7819\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.9146 - val_loss: 97.8670\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.8109 - val_loss: 107.4112\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 2.6782 - val_loss: 102.1361\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 5.3679 - val_loss: 102.1053\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 3.4864 - val_loss: 98.2906\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.8776 - val_loss: 102.0035\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 2.9192 - val_loss: 113.3909\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 4.0224 - val_loss: 100.8775\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 2.3509 - val_loss: 112.6593\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 3.7464 - val_loss: 102.8076\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 4.5717 - val_loss: 100.5437\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 6.1853 - val_loss: 104.2142\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.3506 - val_loss: 100.8948\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 4.0453 - val_loss: 102.4297\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 6.9844 - val_loss: 104.2204\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 10.2619 - val_loss: 103.7063\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 13.0666 - val_loss: 106.1690\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 5.3123 - val_loss: 103.2574\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.5631 - val_loss: 101.7552\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.6630 - val_loss: 100.0418\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.0376 - val_loss: 100.4378\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.8591 - val_loss: 106.2256\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.9224 - val_loss: 102.7717\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6170 - val_loss: 99.6897\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.9395 - val_loss: 99.0935\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.3656 - val_loss: 100.4311\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3333 - val_loss: 100.1646\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4261 - val_loss: 101.5151\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.3328 - val_loss: 99.9298\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1584 - val_loss: 100.6475\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1051 - val_loss: 99.9743\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.1019 - val_loss: 100.9131\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1243 - val_loss: 100.3840\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1364 - val_loss: 101.7704\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3232 - val_loss: 100.6766\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.4409 - val_loss: 99.3839\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.6761 - val_loss: 103.2317\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.5793 - val_loss: 100.4932\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3676 - val_loss: 100.9563\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.4721 - val_loss: 100.2392\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.8789 - val_loss: 101.8443\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5506 - val_loss: 105.0191\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.6378 - val_loss: 99.5441\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 5.6795 - val_loss: 103.2861\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 11.9261 - val_loss: 104.2489\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 20.5755 - val_loss: 133.8909\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 7.9379 - val_loss: 103.9484\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 3.8177 - val_loss: 106.0917\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 1.7889 - val_loss: 101.9046\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.5738 - val_loss: 103.7474\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.0800 - val_loss: 100.2062\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.6206 - val_loss: 102.0759\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.7052 - val_loss: 100.9065\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.7123 - val_loss: 100.5720\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7054 - val_loss: 99.8414\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.4307 - val_loss: 102.6726\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2546 - val_loss: 100.6275\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.4824 - val_loss: 99.6035\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.5084 - val_loss: 105.3587\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 1.3031 - val_loss: 101.4733\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.0868 - val_loss: 100.2617\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.1018 - val_loss: 101.9078\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.1199 - val_loss: 101.5087\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.7571 - val_loss: 100.4823\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 3.6588 - val_loss: 105.3452\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 3.6862 - val_loss: 99.2091\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.3452 - val_loss: 99.2953\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 5.6691 - val_loss: 105.1305\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 7.3851 - val_loss: 98.4251\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 5.5554 - val_loss: 99.5701\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.7196 - val_loss: 101.7478\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.5723 - val_loss: 101.3366\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.7125 - val_loss: 102.9813\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.7347 - val_loss: 101.3356\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.0267 - val_loss: 101.6596\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 2.8661 - val_loss: 101.4533\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.5242 - val_loss: 103.9445\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.7080 - val_loss: 101.7919\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.9277 - val_loss: 101.1218\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.5284 - val_loss: 100.9485\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.3780 - val_loss: 101.0257\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2249 - val_loss: 100.8231\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4023 - val_loss: 101.7163\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.9831 - val_loss: 102.9854\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.6282 - val_loss: 100.9929\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 3.0360 - val_loss: 100.9325\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.7136 - val_loss: 102.6539\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.0508 - val_loss: 105.6242\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.2867 - val_loss: 102.0913\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 4.1903 - val_loss: 103.7963\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 7.2574 - val_loss: 118.3260\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 23.3116 - val_loss: 137.4746\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 11.6942 - val_loss: 105.8515\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 5.5255 - val_loss: 101.4327\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.9227 - val_loss: 101.6333\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.7054 - val_loss: 99.8846\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.7257 - val_loss: 102.0667\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.8057 - val_loss: 100.8161\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.3780 - val_loss: 103.4242\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.5130 - val_loss: 100.9342\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.8978 - val_loss: 103.6304\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.8578 - val_loss: 101.1429\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.0334 - val_loss: 102.7683\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4482 - val_loss: 103.2108\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.2358 - val_loss: 101.9836\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1337 - val_loss: 101.8143\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.1128 - val_loss: 101.3530\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1395 - val_loss: 103.7358\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.1436 - val_loss: 101.1315\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0884 - val_loss: 102.9633\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.0695 - val_loss: 101.2238\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1474 - val_loss: 102.0286\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0715 - val_loss: 101.1141\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0719 - val_loss: 102.5294\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1258 - val_loss: 101.7466\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0760 - val_loss: 102.1036\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0589 - val_loss: 101.9007\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1032 - val_loss: 100.6034\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.3473 - val_loss: 104.5498\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6845 - val_loss: 101.2171\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.6384 - val_loss: 115.3764\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 8.8377 - val_loss: 100.9573\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 9.3085 - val_loss: 107.6798\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 7.9658 - val_loss: 100.6279\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.9825 - val_loss: 101.5484\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.6153 - val_loss: 98.6031\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.7857 - val_loss: 98.9509\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.7446 - val_loss: 100.4783\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.6759 - val_loss: 102.2579\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.5321 - val_loss: 100.3736\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.0339 - val_loss: 100.3494\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.9808 - val_loss: 101.1253\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.4943 - val_loss: 102.8917\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 2.5784 - val_loss: 103.0870\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.1742 - val_loss: 99.6411\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.9589 - val_loss: 100.1362\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.8259 - val_loss: 101.1599\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.0899 - val_loss: 101.2122\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.0887 - val_loss: 101.4096\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.0581 - val_loss: 105.1156\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.4208 - val_loss: 98.6637\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.2571 - val_loss: 100.2933\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.3604 - val_loss: 98.7251\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 1.9381 - val_loss: 106.1790\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 3.0586 - val_loss: 100.5417\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 2.5432 - val_loss: 98.3968\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 2.9613 - val_loss: 112.7562\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 3.1616 - val_loss: 97.4599\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.7890 - val_loss: 100.6945\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 3.6274 - val_loss: 100.0633\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.3021 - val_loss: 103.0317\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 11.9072 - val_loss: 103.1687\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 3.6976 - val_loss: 99.4575\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.8586 - val_loss: 103.7208\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.0509 - val_loss: 101.1568\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.8803 - val_loss: 101.1052\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.6123 - val_loss: 101.6453\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.2927 - val_loss: 101.0596\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.2041 - val_loss: 100.8757\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1551 - val_loss: 99.8845\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.2990 - val_loss: 99.3250\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1788 - val_loss: 100.0687\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1441 - val_loss: 100.5216\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1653 - val_loss: 100.2351\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3132 - val_loss: 103.2804\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.1798 - val_loss: 97.7651\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.7843 - val_loss: 103.0040\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.8428 - val_loss: 100.5906\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 7.5778 - val_loss: 102.1406\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 3.8667 - val_loss: 101.7141\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 3.2177 - val_loss: 101.7619\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.9755 - val_loss: 101.7266\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.9519 - val_loss: 98.4244\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.8551 - val_loss: 99.8817\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.7329 - val_loss: 106.4493\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.5331 - val_loss: 100.0653\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.3208 - val_loss: 100.1272\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.8416 - val_loss: 101.0197\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.0112 - val_loss: 101.1882\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.8812 - val_loss: 101.6801\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.7260 - val_loss: 99.1596\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.4763 - val_loss: 101.0223\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.2565 - val_loss: 102.1823\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2436 - val_loss: 100.2782\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.1253 - val_loss: 100.1037\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1278 - val_loss: 101.2991\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1651 - val_loss: 101.9510\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.2443 - val_loss: 102.6991\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1929 - val_loss: 101.3565\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.1705 - val_loss: 101.1787\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.0903 - val_loss: 100.2306\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3637 - val_loss: 99.7304\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.6712 - val_loss: 99.6154\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 4.5853 - val_loss: 103.5511\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 12.0659 - val_loss: 96.3310\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 6.3591 - val_loss: 101.7923\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.7787 - val_loss: 99.5573\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 3.5729 - val_loss: 100.6906\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 3.5238 - val_loss: 107.1532\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.9643 - val_loss: 104.6122\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.5210 - val_loss: 101.0434\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.3880 - val_loss: 98.7957\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.0834 - val_loss: 100.1284\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.3494 - val_loss: 99.5690\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.4178 - val_loss: 99.7305\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2124 - val_loss: 101.8982\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.5043 - val_loss: 99.2682\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4510 - val_loss: 99.9468\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.2037 - val_loss: 99.9987\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1672 - val_loss: 99.9866\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.0679 - val_loss: 100.5635\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.1555 - val_loss: 99.4618\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.1926 - val_loss: 100.4730\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2024 - val_loss: 101.7598\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3567 - val_loss: 103.5632\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.6253 - val_loss: 99.5315\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.5619 - val_loss: 97.6177\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 1.0986 - val_loss: 99.0075\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.9763 - val_loss: 98.7441\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 3.3297 - val_loss: 114.7577\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 6.0406 - val_loss: 102.5043\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 4.8781 - val_loss: 118.4403\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 6.3357 - val_loss: 100.3228\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 4.3785 - val_loss: 104.1043\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.6724 - val_loss: 96.6328\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.2297 - val_loss: 98.0422\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.2576 - val_loss: 99.3398\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0868 - val_loss: 100.3905\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.8754 - val_loss: 104.2581\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.5552 - val_loss: 100.0064\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.6416 - val_loss: 98.9210\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.4725 - val_loss: 106.0047\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 1.0987 - val_loss: 104.4891\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.8436 - val_loss: 101.7371\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.3961 - val_loss: 99.3037\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2622 - val_loss: 100.9288\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1268 - val_loss: 99.0290\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.2764 - val_loss: 100.7487\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2541 - val_loss: 98.7595\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1953 - val_loss: 98.7129\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2105 - val_loss: 100.3591\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.3767 - val_loss: 101.5236\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.5798 - val_loss: 101.0117\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.5315 - val_loss: 99.5881\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 1.1251 - val_loss: 99.0721\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 1.0232 - val_loss: 99.3559\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 2.4633 - val_loss: 101.7186\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 3.9594 - val_loss: 98.4034\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 6.6806 - val_loss: 104.2682\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 11.9793 - val_loss: 99.7609\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 5.0450 - val_loss: 97.3864\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.0446 - val_loss: 100.8780\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.9976 - val_loss: 100.0193\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6518 - val_loss: 99.1669\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3000 - val_loss: 99.8361\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3127 - val_loss: 103.7363\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3697 - val_loss: 100.3110\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.5186 - val_loss: 98.4461\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.9315 - val_loss: 99.0702\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2644 - val_loss: 99.4165\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1862 - val_loss: 99.4976\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3913 - val_loss: 99.9035\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.7762 - val_loss: 98.7197\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4885 - val_loss: 99.1167\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6434 - val_loss: 100.2639\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.4769 - val_loss: 102.4514\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.7872 - val_loss: 97.6441\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 3.1942 - val_loss: 106.9823\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.2234 - val_loss: 100.1059\n",
      "Epoch 427/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.9871 - val_loss: 103.2631\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4647 - val_loss: 100.0171\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.0699 - val_loss: 101.9253\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 11.0275 - val_loss: 107.2971\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 6.4902 - val_loss: 101.3774\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 2.7471 - val_loss: 98.9821\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.0373 - val_loss: 99.5419\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.2767 - val_loss: 100.1921\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.9121 - val_loss: 100.7959\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.5028 - val_loss: 100.8164\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.2925 - val_loss: 100.1928\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.2669 - val_loss: 99.7516\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1449 - val_loss: 100.9869\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0788 - val_loss: 99.5534\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.0639 - val_loss: 99.6073\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0471 - val_loss: 99.9630\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.0323 - val_loss: 99.8294\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 0s 69us/step - loss: 0.0345 - val_loss: 100.7137\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0252 - val_loss: 100.2429\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0301 - val_loss: 100.2402\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0473 - val_loss: 98.7016\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1038 - val_loss: 99.6596\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1457 - val_loss: 99.5722\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1886 - val_loss: 99.5859\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1641 - val_loss: 99.9694\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.5910 - val_loss: 101.2944\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 2.8175 - val_loss: 100.1430\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 4.3634 - val_loss: 106.2938\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 5.2991 - val_loss: 107.4821\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.0309 - val_loss: 108.6595\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.0250 - val_loss: 101.9688\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.1816 - val_loss: 99.9427\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.5698 - val_loss: 99.6618\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.8151 - val_loss: 98.3975\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5979 - val_loss: 98.6007\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3361 - val_loss: 102.1446\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3820 - val_loss: 99.1774\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4309 - val_loss: 99.5366\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.4115 - val_loss: 99.9477\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.4036 - val_loss: 98.4508\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.7193 - val_loss: 97.3314\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.9571 - val_loss: 99.4756\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 3.1867 - val_loss: 101.2626\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 7.1190 - val_loss: 101.3796\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 3.3825 - val_loss: 99.8231\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 3.3852 - val_loss: 102.3417\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.6947 - val_loss: 99.1375\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.8645 - val_loss: 103.7570\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0901 - val_loss: 103.4377\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.4827 - val_loss: 101.4391\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.6764 - val_loss: 98.7019\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.4923 - val_loss: 99.8684\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.8103 - val_loss: 103.3932\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.4499 - val_loss: 99.7303\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.2102 - val_loss: 100.1118\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1511 - val_loss: 100.3922\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.1591 - val_loss: 100.5188\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0830 - val_loss: 99.6961\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.0951 - val_loss: 100.5147\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.2226 - val_loss: 101.6154\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1935 - val_loss: 100.7951\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.4421 - val_loss: 97.3862\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.6375 - val_loss: 98.6054\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.1848 - val_loss: 103.1236\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 3.9012 - val_loss: 103.8091\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 4.5884 - val_loss: 99.2087\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 1.4187 - val_loss: 98.5212\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 1.4603 - val_loss: 103.9060\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.8682 - val_loss: 101.4496\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.6625 - val_loss: 98.4137\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.8414 - val_loss: 98.5578\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.5923 - val_loss: 98.1812\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4131 - val_loss: 99.3760\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.4835 - val_loss: 98.1375\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.4950 - val_loss: 100.4137\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.3589 - val_loss: 99.8280\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2977 - val_loss: 98.6397\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.4954 - val_loss: 101.0178\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.3538 - val_loss: 99.0098\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 1.2491 - val_loss: 102.6413\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.8368 - val_loss: 100.2452\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.7289 - val_loss: 99.3139\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.7666 - val_loss: 102.6757\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.7039 - val_loss: 102.1363\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.9072 - val_loss: 99.1860\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4115 - val_loss: 104.0140\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.6565 - val_loss: 98.8657\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.6854 - val_loss: 104.6287\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 3.1926 - val_loss: 102.4717\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 2.9272 - val_loss: 118.9883\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 6.5055 - val_loss: 102.1212\n",
      "Epoch 518/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 3.4636 - val_loss: 100.1225\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 2.3374 - val_loss: 100.2993\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.1194 - val_loss: 101.7273\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.4688 - val_loss: 100.1792\n",
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.4684 - val_loss: 98.2153\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 1.2989 - val_loss: 101.7913\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.1808 - val_loss: 105.8259\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.7049 - val_loss: 101.0294\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.3588 - val_loss: 100.9649\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.1769 - val_loss: 100.4602\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.1874 - val_loss: 99.3287\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.1597 - val_loss: 100.3292\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.0861 - val_loss: 99.9711\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.0479 - val_loss: 100.9270\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.1985 - val_loss: 102.2338\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.4428 - val_loss: 105.1405\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.7153 - val_loss: 102.9374\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 3.1164 - val_loss: 126.8798\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 4.7091 - val_loss: 100.5528\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 2.8290 - val_loss: 96.8165\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 2.4936 - val_loss: 99.4516\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 1.2235 - val_loss: 98.1558\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.0473 - val_loss: 102.9384\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 1.3290 - val_loss: 99.8786\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.4694 - val_loss: 100.4355\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.4456 - val_loss: 102.7133\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.7354 - val_loss: 104.6542\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.3851 - val_loss: 100.1289\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.2002 - val_loss: 101.2856\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1104 - val_loss: 101.7894\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.1221 - val_loss: 100.8510\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1517 - val_loss: 100.3298\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 1.0603 - val_loss: 97.9682\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 2.8605 - val_loss: 103.3792\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.2647 - val_loss: 97.6617\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 1.3155 - val_loss: 98.2829\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.0132 - val_loss: 99.2229\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.9511 - val_loss: 99.9500\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 1.0170 - val_loss: 99.0527\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.7532 - val_loss: 101.5018\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 1.3616 - val_loss: 101.5002\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.8920 - val_loss: 105.1424\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.5054 - val_loss: 100.0469\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.4496 - val_loss: 98.2441\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.4944 - val_loss: 99.5090\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.4968 - val_loss: 100.4431\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.3188 - val_loss: 99.0573\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.5778 - val_loss: 101.9768\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.4013 - val_loss: 102.7901\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.6775 - val_loss: 102.2470\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.7774 - val_loss: 99.7321\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 2.1844 - val_loss: 103.7094\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.2807 - val_loss: 102.0199\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.7540 - val_loss: 100.4195\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.8431 - val_loss: 99.3748\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 1.0470 - val_loss: 100.1012\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.7029 - val_loss: 100.1119\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 2.1125 - val_loss: 104.8663\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 5.1204 - val_loss: 98.6408\n",
      "Epoch 577/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 91us/step - loss: 5.7027 - val_loss: 121.2083\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 4.6930 - val_loss: 103.9313\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 1.8946 - val_loss: 109.2161\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 1.4299 - val_loss: 99.1113\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 1.8147 - val_loss: 98.5960\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.3696 - val_loss: 103.0613\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.7857 - val_loss: 99.6340\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.9756 - val_loss: 103.1294\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.4876 - val_loss: 100.4689\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.2428 - val_loss: 102.0354\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.2483 - val_loss: 101.5222\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.1495 - val_loss: 100.8467\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1161 - val_loss: 101.6428\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.2092 - val_loss: 100.6996\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1640 - val_loss: 102.3319\n",
      "Epoch 592/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.1588 - val_loss: 99.8025\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0873 - val_loss: 101.0290\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0690 - val_loss: 100.4439\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.0539 - val_loss: 101.0889\n",
      "Epoch 596/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1070 - val_loss: 100.3224\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0836 - val_loss: 100.5063\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1295 - val_loss: 100.1801\n",
      "Epoch 599/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1541 - val_loss: 100.9034\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.1733 - val_loss: 100.4439\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.4258 - val_loss: 104.5669\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.5464 - val_loss: 99.8903\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.0415 - val_loss: 100.3703\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.5322 - val_loss: 99.6836\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 2.0183 - val_loss: 98.2682\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 4.3565 - val_loss: 105.7741\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 3.0362 - val_loss: 112.7417\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 3.4688 - val_loss: 101.8175\n",
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.2906 - val_loss: 100.2054\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.8489 - val_loss: 101.5323\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.6786 - val_loss: 100.7567\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.9873 - val_loss: 98.4735\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.0624 - val_loss: 101.5807\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.4784 - val_loss: 102.6307\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.0086 - val_loss: 109.6332\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 1.6982 - val_loss: 99.9177\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.8829 - val_loss: 102.8927\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 1.0077 - val_loss: 99.5263\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.4133 - val_loss: 100.3163\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.2770 - val_loss: 99.1113\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.3794 - val_loss: 100.8487\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.2911 - val_loss: 98.9798\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.2630 - val_loss: 101.6679\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.1901 - val_loss: 99.5550\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0918 - val_loss: 99.8246\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.0806 - val_loss: 99.7753\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0507 - val_loss: 99.7476\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0657 - val_loss: 99.5136\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0476 - val_loss: 101.1473\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.0738 - val_loss: 99.5043\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.1423 - val_loss: 100.2353\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1284 - val_loss: 99.8416\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.3665 - val_loss: 99.5807\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.9271 - val_loss: 101.9374\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.8645 - val_loss: 98.7045\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.8752 - val_loss: 97.8617\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.0207 - val_loss: 101.5894\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.9082 - val_loss: 98.7199\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 3.4484 - val_loss: 96.8958\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 9.2025 - val_loss: 97.7910\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 2.4293 - val_loss: 101.6953\n",
      "Epoch 642/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 1.0649 - val_loss: 100.6028\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.6192 - val_loss: 101.0629\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.5520 - val_loss: 103.3925\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.5529 - val_loss: 101.9451\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.2587 - val_loss: 102.1187\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.2677 - val_loss: 100.2259\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.4229 - val_loss: 101.0538\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.3886 - val_loss: 99.8918\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.3426 - val_loss: 99.1457\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.8238 - val_loss: 100.4035\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.1981 - val_loss: 99.4146\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.8848 - val_loss: 99.2083\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.9350 - val_loss: 99.4140\n",
      "Epoch 655/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.4221 - val_loss: 99.8242\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.5516 - val_loss: 97.6187\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.5986 - val_loss: 101.1969\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 1.2473 - val_loss: 96.0016\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.9021 - val_loss: 101.3329\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.5029 - val_loss: 100.5348\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.3957 - val_loss: 100.1357\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.2428 - val_loss: 99.7462\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2078 - val_loss: 100.2069\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.1307 - val_loss: 100.4209\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.3377 - val_loss: 99.6473\n",
      "Epoch 666/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.6130 - val_loss: 107.2957\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.8887 - val_loss: 102.5157\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 1.2153 - val_loss: 99.8238\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 3.8639 - val_loss: 100.5657\n",
      "Epoch 670/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 9.4292 - val_loss: 105.3722\n",
      "Epoch 671/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 3.1998 - val_loss: 101.6452\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 2.4170 - val_loss: 100.5935\n",
      "Epoch 673/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.9827 - val_loss: 101.0245\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.6031 - val_loss: 104.6057\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.3915 - val_loss: 101.6927\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2230 - val_loss: 101.1623\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1275 - val_loss: 101.4925\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1201 - val_loss: 99.7590\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1103 - val_loss: 101.5660\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0472 - val_loss: 100.7651\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0413 - val_loss: 100.9796\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0266 - val_loss: 100.2795\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0265 - val_loss: 101.1543\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0221 - val_loss: 100.8036\n",
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.0182 - val_loss: 101.2300\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.0168 - val_loss: 101.0041\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0144 - val_loss: 101.1429\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0401 - val_loss: 101.5190\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.0674 - val_loss: 101.0549\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.0615 - val_loss: 101.2907\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0640 - val_loss: 101.5594\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.0975 - val_loss: 101.5549\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2457 - val_loss: 99.3648\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.3039 - val_loss: 100.2875\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.5237 - val_loss: 102.1908\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.0190 - val_loss: 105.1286\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.9951 - val_loss: 100.9322\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.9023 - val_loss: 101.2143\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 2.6022 - val_loss: 105.3315\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 3.2083 - val_loss: 102.9630\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 2.5590 - val_loss: 99.2151\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 1.2023 - val_loss: 104.9998\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.7555 - val_loss: 102.2635\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.4830 - val_loss: 100.9167\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 0s 66us/step - loss: 0.6555 - val_loss: 103.3313\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 0s 68us/step - loss: 1.0729 - val_loss: 102.1959\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.9864 - val_loss: 104.9592\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.9628 - val_loss: 102.9805\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.8801 - val_loss: 98.0971\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6219 - val_loss: 101.1599\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.2731 - val_loss: 101.4617\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3101 - val_loss: 101.7032\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5461 - val_loss: 98.6677\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4163 - val_loss: 100.7670\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3778 - val_loss: 99.2044\n",
      "Epoch 716/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.3250 - val_loss: 99.4423\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2660 - val_loss: 100.7556\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2310 - val_loss: 101.5534\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.4187 - val_loss: 101.6065\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.8409 - val_loss: 98.3045\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.7285 - val_loss: 101.6630\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.7897 - val_loss: 101.6819\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.5433 - val_loss: 99.7637\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3618 - val_loss: 101.2667\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2167 - val_loss: 100.9405\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3466 - val_loss: 102.3662\n",
      "Epoch 727/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2953 - val_loss: 100.0013\n",
      "Epoch 728/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4656 - val_loss: 101.8264\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.4046 - val_loss: 99.5940\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.9816 - val_loss: 100.2123\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.8022 - val_loss: 98.5173\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.6486 - val_loss: 99.3709\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.3209 - val_loss: 108.4650\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 6.9638 - val_loss: 104.4423\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 3.2237 - val_loss: 100.8282\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.0345 - val_loss: 106.6416\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.2959 - val_loss: 104.8082\n",
      "Epoch 738/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.7247 - val_loss: 102.6787\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4226 - val_loss: 103.3418\n",
      "Epoch 740/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2854 - val_loss: 101.5093\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4394 - val_loss: 101.8138\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2824 - val_loss: 101.2508\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1860 - val_loss: 100.9843\n",
      "Epoch 744/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0851 - val_loss: 100.9783\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0528 - val_loss: 101.4708\n",
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0414 - val_loss: 100.7363\n",
      "Epoch 747/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0299 - val_loss: 101.4654\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0173 - val_loss: 101.7073\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0180 - val_loss: 100.8634\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0111 - val_loss: 100.9718\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0240 - val_loss: 101.3515\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.1083 - val_loss: 102.1150\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1046 - val_loss: 101.9476\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1224 - val_loss: 99.8077\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3323 - val_loss: 103.2154\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2505 - val_loss: 101.5530\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2545 - val_loss: 100.1974\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0356 - val_loss: 104.7962\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.1906 - val_loss: 101.6665\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.9483 - val_loss: 104.6146\n",
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.1825 - val_loss: 103.0280\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.8107 - val_loss: 105.7229\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.8244 - val_loss: 103.0910\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.4902 - val_loss: 102.1836\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5784 - val_loss: 100.2095\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.7557 - val_loss: 99.7066\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.6022 - val_loss: 101.3807\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.0559 - val_loss: 106.6350\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0662 - val_loss: 100.1449\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.1777 - val_loss: 113.2496\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 2.0671 - val_loss: 101.0325\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.8749 - val_loss: 101.2732\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.7565 - val_loss: 98.5755\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0484 - val_loss: 99.8425\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.8446 - val_loss: 101.2558\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.7050 - val_loss: 103.7878\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.0250 - val_loss: 99.0412\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.1026 - val_loss: 100.2332\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.5554 - val_loss: 100.8318\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4217 - val_loss: 101.7509\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3159 - val_loss: 100.0537\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3218 - val_loss: 101.7416\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1833 - val_loss: 99.7430\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1507 - val_loss: 102.9361\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.9073 - val_loss: 97.5569\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.8739 - val_loss: 98.4527\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.3001 - val_loss: 102.6252\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.7040 - val_loss: 100.9913\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.5050 - val_loss: 99.7396\n",
      "Epoch 790/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4486 - val_loss: 101.6709\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3355 - val_loss: 100.3066\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3461 - val_loss: 102.8818\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.7196 - val_loss: 100.2913\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.4972 - val_loss: 101.1244\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.5131 - val_loss: 99.4297\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.8022 - val_loss: 101.3005\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 4.1753 - val_loss: 102.6485\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 2.5273 - val_loss: 99.3040\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.2561 - val_loss: 100.6316\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.0076 - val_loss: 98.9836\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4924 - val_loss: 101.5874\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4940 - val_loss: 101.2800\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2768 - val_loss: 100.5196\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4564 - val_loss: 103.8965\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2597 - val_loss: 100.5391\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2516 - val_loss: 102.6229\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1997 - val_loss: 100.5589\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0949 - val_loss: 101.4437\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0592 - val_loss: 101.5642\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1584 - val_loss: 100.7321\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1449 - val_loss: 101.3004\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0756 - val_loss: 100.6670\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.1167 - val_loss: 101.3331\n",
      "Epoch 814/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3049 - val_loss: 100.8842\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2600 - val_loss: 103.5973\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2894 - val_loss: 100.1489\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.2207 - val_loss: 102.6310\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3134 - val_loss: 101.1103\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.6063 - val_loss: 104.3243\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4443 - val_loss: 100.4169\n",
      "Epoch 821/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.4756 - val_loss: 100.3140\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.9760 - val_loss: 104.9380\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.9929 - val_loss: 97.0776\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.1543 - val_loss: 101.1288\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.9034 - val_loss: 103.9669\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.5945 - val_loss: 100.6737\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.9205 - val_loss: 100.8514\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.3381 - val_loss: 101.5512\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.9293 - val_loss: 109.0095\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 4.9833 - val_loss: 110.6864\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 3.4666 - val_loss: 102.0927\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.6376 - val_loss: 105.6002\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.8326 - val_loss: 102.6092\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.3986 - val_loss: 103.8258\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 0.6355 - val_loss: 100.0352\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.4091 - val_loss: 100.8412\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.3312 - val_loss: 101.7490\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.2282 - val_loss: 103.0748\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1584 - val_loss: 101.8284\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0562 - val_loss: 102.2884\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0552 - val_loss: 102.4355\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0511 - val_loss: 101.9584\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0534 - val_loss: 102.1670\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0308 - val_loss: 102.1754\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0879 - val_loss: 101.6667\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0667 - val_loss: 102.7033\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1148 - val_loss: 102.4900\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0528 - val_loss: 101.6110\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0586 - val_loss: 101.4984\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.0575 - val_loss: 101.8787\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.0475 - val_loss: 102.6797\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0550 - val_loss: 102.2854\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0633 - val_loss: 101.4273\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0388 - val_loss: 103.5015\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0730 - val_loss: 102.7485\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0852 - val_loss: 100.5758\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.2992 - val_loss: 102.3386\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.6954 - val_loss: 98.9198\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.8012 - val_loss: 100.9093\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 1.5105 - val_loss: 102.4356\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 1.2703 - val_loss: 100.8388\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 3.8816 - val_loss: 105.3672\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 7.9475 - val_loss: 106.7434\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 2.9023 - val_loss: 100.8363\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 1.6934 - val_loss: 104.4112\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.8750 - val_loss: 104.4241\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.4071 - val_loss: 103.0321\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.3338 - val_loss: 100.9905\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 0s 73us/step - loss: 0.1777 - val_loss: 100.7503\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1479 - val_loss: 100.3090\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 0s 70us/step - loss: 0.1171 - val_loss: 102.9417\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 0s 72us/step - loss: 0.0814 - val_loss: 101.1183\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0538 - val_loss: 101.2094\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0542 - val_loss: 102.3798\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0374 - val_loss: 102.3656\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0431 - val_loss: 101.7215\n",
      "Epoch 877/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0326 - val_loss: 102.2792\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0333 - val_loss: 100.6219\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.0513 - val_loss: 102.0211\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0253 - val_loss: 101.8886\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0133 - val_loss: 101.7873\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0156 - val_loss: 101.8185\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0176 - val_loss: 101.8146\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.0173 - val_loss: 101.9152\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0282 - val_loss: 101.0126\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0537 - val_loss: 102.0993\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0750 - val_loss: 101.4841\n",
      "Epoch 888/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2550 - val_loss: 102.2847\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.4836 - val_loss: 100.0828\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.0767 - val_loss: 112.2167\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 6.6398 - val_loss: 110.1734\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 2.1752 - val_loss: 97.2579\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.8841 - val_loss: 103.2156\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6372 - val_loss: 102.0469\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4644 - val_loss: 101.3388\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2871 - val_loss: 103.4024\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.2006 - val_loss: 100.8715\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1529 - val_loss: 102.8781\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1029 - val_loss: 103.0913\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2516 - val_loss: 104.4271\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2841 - val_loss: 100.1010\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2045 - val_loss: 103.5218\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1715 - val_loss: 102.2111\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3189 - val_loss: 103.8045\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.2169 - val_loss: 105.3029\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2698 - val_loss: 102.3540\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3197 - val_loss: 101.3490\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3975 - val_loss: 107.8677\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5711 - val_loss: 102.4667\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.1942 - val_loss: 97.3232\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.8960 - val_loss: 100.9515\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.6152 - val_loss: 105.6594\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.6401 - val_loss: 104.1214\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.6339 - val_loss: 105.9429\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5845 - val_loss: 102.1223\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.3622 - val_loss: 101.2927\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3350 - val_loss: 103.6759\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3714 - val_loss: 106.6580\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.1558 - val_loss: 100.5563\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 4.7264 - val_loss: 99.6196\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.8895 - val_loss: 107.8652\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.5866 - val_loss: 99.0388\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.1296 - val_loss: 103.0413\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.5713 - val_loss: 101.8507\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3866 - val_loss: 103.9272\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1715 - val_loss: 101.8216\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1772 - val_loss: 101.4284\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2479 - val_loss: 103.0784\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1157 - val_loss: 103.0982\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.0927 - val_loss: 101.6464\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.1905 - val_loss: 101.6476\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1734 - val_loss: 103.5792\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2709 - val_loss: 105.6504\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3530 - val_loss: 103.3155\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.2304 - val_loss: 101.2747\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2936 - val_loss: 101.6916\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.5599 - val_loss: 103.2734\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.6309 - val_loss: 101.0444\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.5212 - val_loss: 100.4232\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.4179 - val_loss: 101.7993\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.8727 - val_loss: 99.6709\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.7217 - val_loss: 104.2263\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.3204 - val_loss: 101.3820\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.0384 - val_loss: 100.9415\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.6355 - val_loss: 99.9387\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.8620 - val_loss: 99.8543\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.8147 - val_loss: 104.6317\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.4978 - val_loss: 104.1106\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3961 - val_loss: 102.5444\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2519 - val_loss: 102.1304\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3091 - val_loss: 103.3718\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2985 - val_loss: 102.7022\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 0s 71us/step - loss: 0.1691 - val_loss: 101.3636\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1433 - val_loss: 103.3026\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1370 - val_loss: 101.9499\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1802 - val_loss: 101.5098\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1754 - val_loss: 102.4281\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1271 - val_loss: 103.0590\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1709 - val_loss: 100.9363\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.1900 - val_loss: 100.5801\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2807 - val_loss: 100.4223\n",
      "Epoch 962/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4443 - val_loss: 100.9904\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.6607 - val_loss: 105.1696\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.7956 - val_loss: 103.9370\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.2319 - val_loss: 101.7589\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 1.2695 - val_loss: 100.7323\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.8906 - val_loss: 106.5263\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.8567 - val_loss: 101.0240\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.2468 - val_loss: 106.4377\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.5526 - val_loss: 102.3687\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 3.8166 - val_loss: 103.4976\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 1.5960 - val_loss: 103.3325\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.3828 - val_loss: 99.3674\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.7042 - val_loss: 106.7188\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.5895 - val_loss: 102.5513\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.2192 - val_loss: 102.1207\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1333 - val_loss: 100.8670\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.1245 - val_loss: 101.4367\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.0631 - val_loss: 101.2432\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0359 - val_loss: 101.5189\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0277 - val_loss: 101.0820\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.0233 - val_loss: 101.0318\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0383 - val_loss: 101.5859\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.0821 - val_loss: 103.1853\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.2403 - val_loss: 101.1984\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2042 - val_loss: 100.7634\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.2741 - val_loss: 102.6982\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.2065 - val_loss: 101.1055\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.1725 - val_loss: 100.0152\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.3296 - val_loss: 100.2060\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 2.7654 - val_loss: 103.0380\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 1.4797 - val_loss: 101.2763\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.8129 - val_loss: 103.1613\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.5635 - val_loss: 100.8306\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.3562 - val_loss: 105.1963\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.4871 - val_loss: 101.4138\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2657 - val_loss: 100.5675\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.2091 - val_loss: 102.8198\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.3637 - val_loss: 106.3643\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.3860 - val_loss: 101.7741\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 53us/step\n",
      "120.52575592041016\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 다층퍼셉트론 신경망 모델\n",
    "\n",
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "x_train_1d = x_train.reshape(x_train.shape[0], width*height)\n",
    "x_val_1d = x_val.reshape(x_val.shape[0], width*height)\n",
    "x_test_1d = x_test.reshape(x_test.shape[0], width*height)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim = width*height))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train_1d, y_train, batch_size=32, epochs=1000, validation_data=(x_val_1d, y_val))\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 300.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test_1d, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test_1d, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다층퍼셉트론 모델의 입력층인 Dense 레이어는 일차원 벡터로 데이터를 입력 받기 때문에, 이차원인 영상을 일차원 벡터로 변환하는 과정이 필요하다.<br>\n",
    "\n",
    "    x_train_1d = x_train.reshape(x_train.shape[0], width*height)\n",
    "    x_val_1d = x_val.reshape(x_val.shape[0], width*height)\n",
    "    x_test_1d = x_test.reshape(x_test.shape[0], width*height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/seo2730/ai1/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "1500/1500 [==============================] - 1s 603us/step - loss: 12046.0122 - val_loss: 2183.6551\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 1555.9196 - val_loss: 1340.3026\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 1108.2014 - val_loss: 1020.7094\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 847.9946 - val_loss: 807.4052\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 660.3542 - val_loss: 625.9101\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 490.5324 - val_loss: 438.0189\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 366.7961 - val_loss: 366.6168\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 290.0616 - val_loss: 283.5194\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 260.9788 - val_loss: 261.1523\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 247.2818 - val_loss: 247.9929\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 243.3378 - val_loss: 259.7580\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 219.7002 - val_loss: 217.3715\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 202.6861 - val_loss: 241.2791\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 216.3567 - val_loss: 206.7004\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 192.1712 - val_loss: 209.6511\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 189.4769 - val_loss: 229.6552\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 184.5796 - val_loss: 200.1631\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 176.3762 - val_loss: 201.9024\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 166.9379 - val_loss: 193.8340\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 164.1734 - val_loss: 195.8716\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 161.0111 - val_loss: 191.3315\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 0s 252us/step - loss: 169.0307 - val_loss: 218.3367\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 0s 239us/step - loss: 160.1918 - val_loss: 186.8400\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 150.7556 - val_loss: 183.0910\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 154.4405 - val_loss: 193.4547\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 151.2678 - val_loss: 186.1937\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 154.2027 - val_loss: 178.5850\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 141.4166 - val_loss: 178.2078\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 138.8834 - val_loss: 176.1002\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 0s 228us/step - loss: 136.4003 - val_loss: 173.5515\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 0s 225us/step - loss: 140.2749 - val_loss: 178.6774\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 148.7959 - val_loss: 175.3742\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 136.6162 - val_loss: 210.8492\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 142.7982 - val_loss: 211.1005\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 130.8044 - val_loss: 170.0302\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 128.3527 - val_loss: 171.3954\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 123.4792 - val_loss: 178.0363\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 126.4691 - val_loss: 171.8927\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 123.3952 - val_loss: 171.7638\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 125.3364 - val_loss: 166.8117\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 0s 232us/step - loss: 119.5258 - val_loss: 168.5484\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 117.2564 - val_loss: 167.1893\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 0s 232us/step - loss: 130.7364 - val_loss: 183.8030\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 114.1636 - val_loss: 163.6223\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 112.1279 - val_loss: 186.5705\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 117.0635 - val_loss: 176.0637\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 106.6744 - val_loss: 162.0009\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 0s 237us/step - loss: 104.3624 - val_loss: 162.8365\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 110.4128 - val_loss: 164.7968\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 213us/step - loss: 105.4532 - val_loss: 163.6127\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 102.2926 - val_loss: 165.3503\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 100.1268 - val_loss: 160.2174\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 0s 225us/step - loss: 100.6804 - val_loss: 187.3510\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 103.8748 - val_loss: 169.0792\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 0s 237us/step - loss: 96.7846 - val_loss: 161.5710\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 94.5676 - val_loss: 165.9777\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 92.6374 - val_loss: 166.4138\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 99.8554 - val_loss: 157.6010\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 99.5567 - val_loss: 159.1976\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 91.9386 - val_loss: 169.9054\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 94.2560 - val_loss: 160.5471\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 0s 225us/step - loss: 91.0197 - val_loss: 178.1662\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 126.8449 - val_loss: 182.8776\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 92.9921 - val_loss: 174.9559\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 88.5502 - val_loss: 160.0122\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 94.3103 - val_loss: 214.2970\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 90.2060 - val_loss: 194.9028\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 91.0406 - val_loss: 168.4792\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 81.4710 - val_loss: 160.4230\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 80.7070 - val_loss: 160.2618\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 0s 189us/step - loss: 76.6558 - val_loss: 181.3227\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 0s 189us/step - loss: 91.2428 - val_loss: 157.8810\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 83.0173 - val_loss: 168.9443\n",
      "Epoch 74/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 79.0415 - val_loss: 158.8857\n",
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 0s 237us/step - loss: 75.1564 - val_loss: 160.3358\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 71.6983 - val_loss: 172.2367\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 78.2762 - val_loss: 168.0396\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 74.6953 - val_loss: 163.7626\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 70.3487 - val_loss: 160.6141\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 69.9730 - val_loss: 168.9583\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 83.0444 - val_loss: 163.3063\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 67.2459 - val_loss: 161.8346\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 63.3341 - val_loss: 169.7525\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 74.9165 - val_loss: 228.5857\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 74.8105 - val_loss: 171.8674\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 62.1866 - val_loss: 163.8243\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 62.0729 - val_loss: 164.8754\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 62.6659 - val_loss: 170.6697\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 67.4416 - val_loss: 178.6098\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 62.2951 - val_loss: 164.0410\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 56.8894 - val_loss: 165.7656\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 61.2951 - val_loss: 179.2189\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 56.2068 - val_loss: 169.0537\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 53.1544 - val_loss: 171.5224\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 56.3997 - val_loss: 177.9478\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 55.6243 - val_loss: 166.6959\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 55.5392 - val_loss: 174.0922\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 60.5791 - val_loss: 183.5081\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 58.7428 - val_loss: 173.8343\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 50.7912 - val_loss: 188.8947\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 62.6868 - val_loss: 168.5700\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 55.8470 - val_loss: 171.7091\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 47.4767 - val_loss: 170.2992\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 47.0342 - val_loss: 171.1538\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 47.0204 - val_loss: 174.5505\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 45.8546 - val_loss: 180.4873\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 45.1265 - val_loss: 178.0121\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 50.4422 - val_loss: 176.8901\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 41.3142 - val_loss: 180.1580\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 41.8330 - val_loss: 181.7997\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 39.7483 - val_loss: 176.4208\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 39.5751 - val_loss: 176.3297\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 43.9622 - val_loss: 187.4884\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 42.9996 - val_loss: 184.2678\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 42.4873 - val_loss: 180.1712\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 44.4335 - val_loss: 178.0794\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 40.9189 - val_loss: 183.4523\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 42.7295 - val_loss: 179.7399\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 0s 228us/step - loss: 36.3142 - val_loss: 180.1088\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 35.3493 - val_loss: 181.7242\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 33.9441 - val_loss: 180.3808\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 36.0436 - val_loss: 188.4317\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 34.6439 - val_loss: 180.5888\n",
      "Epoch 124/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 223us/step - loss: 34.5991 - val_loss: 185.5093\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 33.8870 - val_loss: 183.3542\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 30.2469 - val_loss: 181.4804\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 30.2895 - val_loss: 182.8303\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 34.7101 - val_loss: 188.5089\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 33.0684 - val_loss: 194.5759\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 35.3169 - val_loss: 201.1589\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 33.3280 - val_loss: 203.6484\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 32.7534 - val_loss: 184.8166\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 27.6588 - val_loss: 195.4794\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 36.0490 - val_loss: 195.2662\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 26.0598 - val_loss: 187.4185\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 25.9032 - val_loss: 195.2135\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 27.9439 - val_loss: 186.1234\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 26.0265 - val_loss: 191.3484\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 22.3111 - val_loss: 194.8926\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 0s 228us/step - loss: 23.0764 - val_loss: 191.7096\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 21.9139 - val_loss: 195.3509\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 24.6724 - val_loss: 188.9793\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 0s 171us/step - loss: 22.5922 - val_loss: 198.5321\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 22.7703 - val_loss: 201.6517\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 0s 168us/step - loss: 22.7361 - val_loss: 189.5846\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 28.7931 - val_loss: 193.4112\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 24.5295 - val_loss: 192.5832\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 20.3476 - val_loss: 217.0763\n",
      "Epoch 149/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 23.3319 - val_loss: 211.2918\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 20.3240 - val_loss: 196.3351\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 19.0705 - val_loss: 215.2080\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 21.7943 - val_loss: 198.0918\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 19.9967 - val_loss: 197.9930\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 20.8415 - val_loss: 227.5895\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 20.9276 - val_loss: 202.9860\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 16.8004 - val_loss: 201.3788\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 15.1692 - val_loss: 200.6554\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 18.2282 - val_loss: 211.4664\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 17.1057 - val_loss: 198.2493\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 17.2711 - val_loss: 217.2552\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 16.0527 - val_loss: 205.9098\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 15.1234 - val_loss: 201.7131\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 14.2713 - val_loss: 207.6102\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 12.98 - 0s 208us/step - loss: 13.1082 - val_loss: 207.6992\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 13.5459 - val_loss: 209.7445\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 12.7978 - val_loss: 205.3676\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 12.8370 - val_loss: 210.3252\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 12.6034 - val_loss: 209.1944\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 13.3809 - val_loss: 222.2703\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 13.5974 - val_loss: 204.0119\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 12.1684 - val_loss: 213.8133\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 13.4805 - val_loss: 204.4707\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 12.2800 - val_loss: 209.4953\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 10.9410 - val_loss: 233.3401\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 13.0759 - val_loss: 219.6198\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 9.3520 - val_loss: 209.3143\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 9.3746 - val_loss: 208.0970\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 9.6951 - val_loss: 207.1958\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 9.7405 - val_loss: 208.9768\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 10.8867 - val_loss: 209.8895\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 11.3222 - val_loss: 207.8523\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 11.2002 - val_loss: 209.6304\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 9.1364 - val_loss: 214.8510\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 9.4229 - val_loss: 208.9919\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 9.8527 - val_loss: 215.8001\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 7.4188 - val_loss: 212.9750\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 8.4099 - val_loss: 233.9826\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 9.0441 - val_loss: 211.8470\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 6.9167 - val_loss: 212.3010\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 6.8223 - val_loss: 216.4953\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 7.8105 - val_loss: 221.6371\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 6.9036 - val_loss: 210.2349\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 6.1204 - val_loss: 214.8086\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 6.5912 - val_loss: 213.1190\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 6.2397 - val_loss: 214.1983\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 7.5782 - val_loss: 219.3091\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 5.5074 - val_loss: 224.1383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 0s 228us/step - loss: 6.6309 - val_loss: 213.2739\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 5.8501 - val_loss: 211.9755\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 5.7687 - val_loss: 219.4083\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 5.3593 - val_loss: 218.7111\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 6.2553 - val_loss: 216.0414\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 0s 225us/step - loss: 4.6467 - val_loss: 228.2292\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 8.8844 - val_loss: 214.7023\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 5.7416 - val_loss: 214.1046\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 5.5333 - val_loss: 214.0397\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 4.4420 - val_loss: 215.2748\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 0s 225us/step - loss: 4.7341 - val_loss: 221.7320\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 4.4963 - val_loss: 219.3014\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 5.4704 - val_loss: 220.7165\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 4.4406 - val_loss: 216.5156\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 3.9010 - val_loss: 217.8503\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 6.6423 - val_loss: 229.9224\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 6.7370 - val_loss: 217.1908\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 4.7997 - val_loss: 221.1811\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 0s 188us/step - loss: 2.8195 - val_loss: 220.7479\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 2.7468 - val_loss: 220.4726\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 5.0731 - val_loss: 218.0324\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 3.0887 - val_loss: 220.3844\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 2.4982 - val_loss: 220.8687\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 2.4241 - val_loss: 223.6241\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 2.5368 - val_loss: 219.3658\n",
      "Epoch 223/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 2.6465 - val_loss: 221.9971\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 2.3415 - val_loss: 219.8503\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 2.5688 - val_loss: 220.8171\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 3.3753 - val_loss: 225.3199\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 2.0554 - val_loss: 221.6644\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 2.3764 - val_loss: 220.0860\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 2.3522 - val_loss: 223.9514\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 2.7914 - val_loss: 230.7595\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 2.1845 - val_loss: 223.8427\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 2.3211 - val_loss: 228.6365\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 2.3520 - val_loss: 219.3155\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 2.5392 - val_loss: 226.8568\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 2.1311 - val_loss: 221.2086\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 1.9398 - val_loss: 222.0057\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.5450 - val_loss: 225.4640\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 2.2736 - val_loss: 221.1280\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 2.6638 - val_loss: 228.2712\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 1.7821 - val_loss: 227.9964\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 2.3513 - val_loss: 223.7021\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 1.5703 - val_loss: 222.5209\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 1.4081 - val_loss: 221.1872\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 2.3238 - val_loss: 221.1369\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 2.4857 - val_loss: 221.9417\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 1.9604 - val_loss: 233.6688\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 1.4899 - val_loss: 222.9737\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 1.2938 - val_loss: 221.7935\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 1.2429 - val_loss: 223.4779\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 1.1479 - val_loss: 223.6381\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 2.4000 - val_loss: 226.0661\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 3.1853 - val_loss: 222.8057\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 3.9143 - val_loss: 221.3560\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 4.0106 - val_loss: 222.1447\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 1.6370 - val_loss: 225.2197\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 1.4039 - val_loss: 225.1367\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.2016 - val_loss: 224.0164\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 1.5815 - val_loss: 223.4806\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 0s 232us/step - loss: 1.2509 - val_loss: 222.8009\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 0.8844 - val_loss: 224.4740\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 1.8504 - val_loss: 223.7680\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 0s 237us/step - loss: 1.8246 - val_loss: 225.0968\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 1.4220 - val_loss: 219.4233\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 1.3892 - val_loss: 225.9231\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.6565 - val_loss: 228.8058\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.8625 - val_loss: 226.8790\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 1.7622 - val_loss: 223.4333\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 1.0159 - val_loss: 222.6005\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 1.4370 - val_loss: 228.6900\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.9274 - val_loss: 228.5822\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 1.4961 - val_loss: 223.2797\n",
      "Epoch 272/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 226us/step - loss: 1.8437 - val_loss: 224.0254\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.8029 - val_loss: 229.4965\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 2.1508 - val_loss: 222.2752\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 1.4110 - val_loss: 224.7429\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 0.7071 - val_loss: 227.6359\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.6288 - val_loss: 224.2856\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 0.4562 - val_loss: 227.0909\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 0.3987 - val_loss: 225.8408\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 0.4545 - val_loss: 225.5726\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.6174 - val_loss: 225.0765\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 1.8805 - val_loss: 226.7795\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 1.1426 - val_loss: 224.8374\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 0.6621 - val_loss: 224.7661\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 0s 191us/step - loss: 0.8336 - val_loss: 224.9726\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 2.5027 - val_loss: 227.9455\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 1.8374 - val_loss: 228.3040\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 3.4549 - val_loss: 225.2738\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 2.2004 - val_loss: 225.0665\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 3.8041 - val_loss: 229.5115\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.5035 - val_loss: 230.2320\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 0s 188us/step - loss: 0.8357 - val_loss: 225.8393\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 0.9063 - val_loss: 229.8825\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 0.7084 - val_loss: 224.0987\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 0s 238us/step - loss: 0.5971 - val_loss: 225.9509\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.3850 - val_loss: 225.8990\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 0.4492 - val_loss: 226.0759\n",
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.3524 - val_loss: 226.2629\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 0.5510 - val_loss: 224.5611\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 0s 225us/step - loss: 0.3051 - val_loss: 228.5502\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.4960 - val_loss: 227.9245\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 0.6359 - val_loss: 228.2915\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 1.4862 - val_loss: 226.5341\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 1.0890 - val_loss: 226.1490\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 1.0821 - val_loss: 225.8842\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.8239 - val_loss: 225.8396\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.8464 - val_loss: 226.0383\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 1.3591 - val_loss: 225.0462\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 1.3254 - val_loss: 228.0134\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.8846 - val_loss: 221.8680\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.9545 - val_loss: 223.3266\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 1.0132 - val_loss: 225.4090\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.6032 - val_loss: 227.5086\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 0.7145 - val_loss: 225.4032\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.6963 - val_loss: 226.9299\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.5373 - val_loss: 224.7988\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 0.7147 - val_loss: 226.1357\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 0.8596 - val_loss: 228.1544\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 1.3358 - val_loss: 222.2217\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 1.4172 - val_loss: 226.1857\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 2.3551 - val_loss: 230.6703\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 9.3311 - val_loss: 228.2958\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 2.7966 - val_loss: 222.4509\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 0.9800 - val_loss: 224.2154\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.2126 - val_loss: 226.6949\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.6616 - val_loss: 225.2957\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 0.8489 - val_loss: 226.7760\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.5642 - val_loss: 223.8961\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.2604 - val_loss: 225.8477\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 0.2293 - val_loss: 227.0977\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.3011 - val_loss: 226.4390\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.3595 - val_loss: 227.0204\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.3908 - val_loss: 227.0039\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 0.3435 - val_loss: 226.2423\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 0.1988 - val_loss: 226.0564\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.3929 - val_loss: 223.6914\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 0.7983 - val_loss: 226.2369\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.3973 - val_loss: 227.6838\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.2531 - val_loss: 224.5425\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 0.2296 - val_loss: 224.1545\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.2233 - val_loss: 225.7434\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 0s 237us/step - loss: 0.2490 - val_loss: 223.8965\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 1.4813 - val_loss: 226.8021\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 1.1081 - val_loss: 223.2151\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 0.9974 - val_loss: 224.8954\n",
      "Epoch 346/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 241us/step - loss: 1.0817 - val_loss: 224.6467\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 0s 238us/step - loss: 1.2025 - val_loss: 224.7819\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.4381 - val_loss: 224.3367\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.4150 - val_loss: 226.3992\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.7064 - val_loss: 225.7022\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 0s 238us/step - loss: 1.4350 - val_loss: 226.0465\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 4.0883 - val_loss: 225.2663\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 0s 192us/step - loss: 2.9154 - val_loss: 222.9186\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 4.1680 - val_loss: 235.3790\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 3.0302 - val_loss: 222.5306\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 2.1820 - val_loss: 231.6854\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 4.0932 - val_loss: 228.6163\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 1.3949 - val_loss: 222.8721\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.7279 - val_loss: 228.0642\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 0s 285us/step - loss: 1.2624 - val_loss: 225.2956\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 0.8880 - val_loss: 225.7798\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 1.9035 - val_loss: 227.9078\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 1.0118 - val_loss: 229.3805\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 0s 311us/step - loss: 0.4439 - val_loss: 225.1945\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 0.3650 - val_loss: 225.1409\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 0s 181us/step - loss: 0.2328 - val_loss: 225.9386\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 0s 182us/step - loss: 0.4800 - val_loss: 226.7977\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 0s 184us/step - loss: 0.2279 - val_loss: 224.8668\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 0s 181us/step - loss: 0.1465 - val_loss: 224.6086\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.1123 - val_loss: 224.4995\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 0.2794 - val_loss: 222.7706\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 1.1569 - val_loss: 227.9045\n",
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 3.0675 - val_loss: 230.9154\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 3.1398 - val_loss: 220.9353\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.8183 - val_loss: 223.0090\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.4940 - val_loss: 229.2156\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.3606 - val_loss: 224.7258\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2439 - val_loss: 224.5514\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.3384 - val_loss: 226.6936\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.1956 - val_loss: 224.5582\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 0.1452 - val_loss: 225.0572\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 0.2651 - val_loss: 223.2083\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.6851 - val_loss: 225.1353\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.3662 - val_loss: 226.7428\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 0.4675 - val_loss: 223.1630\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.9222 - val_loss: 226.9684\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.8613 - val_loss: 225.1017\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 0.5711 - val_loss: 224.1262\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.4918 - val_loss: 225.3943\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 0.3302 - val_loss: 223.4611\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 2.2116 - val_loss: 220.9224\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 1.8085 - val_loss: 231.2168\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 2.6670 - val_loss: 224.6389\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 1.3036 - val_loss: 227.3373\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 1.0298 - val_loss: 224.2098\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 0.7081 - val_loss: 224.7228\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 1.2184 - val_loss: 224.2650\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 1.3812 - val_loss: 224.6903\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.7834 - val_loss: 231.5888\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 2.0024 - val_loss: 224.5945\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 1.7584 - val_loss: 222.6957\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.7024 - val_loss: 224.4846\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 1.1359 - val_loss: 223.5072\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 1.6656 - val_loss: 219.8485\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 1.3561 - val_loss: 227.9405\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 0.6224 - val_loss: 222.1877\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 0.8419 - val_loss: 226.9638\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 1.1520 - val_loss: 221.5852\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.9309 - val_loss: 223.9069\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 0.5693 - val_loss: 224.4322\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.5485 - val_loss: 224.7829\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 0.7854 - val_loss: 226.7381\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 1.2354 - val_loss: 220.6797\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 0.8009 - val_loss: 224.7769\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 7.0242 - val_loss: 222.0868\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 2.2727 - val_loss: 224.1188\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 1.0385 - val_loss: 220.4399\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.9071 - val_loss: 221.9996\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 3.8901 - val_loss: 224.3775\n",
      "Epoch 420/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 205us/step - loss: 3.4461 - val_loss: 224.9208\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 1.4555 - val_loss: 225.5629\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 0.6894 - val_loss: 220.8617\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 1.6819 - val_loss: 221.0046\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 1.1785 - val_loss: 223.3101\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.4195 - val_loss: 223.8612\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.3000 - val_loss: 222.7695\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.3245 - val_loss: 225.2279\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.2451 - val_loss: 221.6194\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.3410 - val_loss: 221.6281\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.3876 - val_loss: 221.5159\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.2329 - val_loss: 221.7801\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1529 - val_loss: 223.3117\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 0.1691 - val_loss: 223.9992\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1586 - val_loss: 223.5986\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.2568 - val_loss: 222.4601\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.1789 - val_loss: 225.1962\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 0s 189us/step - loss: 0.1515 - val_loss: 222.2133\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.1158 - val_loss: 222.1349\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 0s 182us/step - loss: 0.3278 - val_loss: 224.3422\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 0.1347 - val_loss: 223.5903\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 0s 176us/step - loss: 0.1136 - val_loss: 223.3539\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.4387 - val_loss: 232.4362\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 1.2784 - val_loss: 227.5920\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 2.4262 - val_loss: 229.5496\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 2.6897 - val_loss: 225.8086\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 1.9215 - val_loss: 226.2221\n",
      "Epoch 447/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 1.1816 - val_loss: 225.0094\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.0456 - val_loss: 225.6234\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 0s 228us/step - loss: 4.2933 - val_loss: 226.5667\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 3.2423 - val_loss: 223.3396\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 1.4572 - val_loss: 221.5081\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 1.3345 - val_loss: 226.7942\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 0.5374 - val_loss: 224.1779\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.4239 - val_loss: 222.6998\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 0.3250 - val_loss: 225.3983\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 0.2572 - val_loss: 224.5982\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.3188 - val_loss: 225.5413\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.3973 - val_loss: 226.6670\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.7529 - val_loss: 222.4463\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 1.0458 - val_loss: 221.7179\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 0s 182us/step - loss: 1.1067 - val_loss: 219.0472\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 0s 189us/step - loss: 1.1959 - val_loss: 224.3127\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.3835 - val_loss: 223.4576\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.4786 - val_loss: 222.2700\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.5015 - val_loss: 221.9072\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.9905 - val_loss: 221.0482\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.4614 - val_loss: 225.0514\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.2513 - val_loss: 222.3844\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 0s 191us/step - loss: 0.2358 - val_loss: 225.1717\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.2731 - val_loss: 223.1664\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 0.1289 - val_loss: 223.7350\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.3017 - val_loss: 226.4109\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2236 - val_loss: 222.4449\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 0.2472 - val_loss: 222.8296\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.2530 - val_loss: 221.9157\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 4.0769 - val_loss: 223.3916\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 4.4930 - val_loss: 228.4921\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 4.2534 - val_loss: 225.4629\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 2.5970 - val_loss: 228.4683\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.8349 - val_loss: 225.0142\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 2.8737 - val_loss: 228.3959\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 2.4695 - val_loss: 222.7954\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 0.9742 - val_loss: 225.1571\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 0.5133 - val_loss: 222.1674\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.3242 - val_loss: 223.4097\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.2429 - val_loss: 224.6737\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 0s 192us/step - loss: 0.2480 - val_loss: 223.6018\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.4531 - val_loss: 225.5281\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.9850 - val_loss: 222.9852\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.6068 - val_loss: 222.1765\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.3552 - val_loss: 224.9771\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 1.0518 - val_loss: 222.6349\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 0.7534 - val_loss: 225.0036\n",
      "Epoch 494/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 214us/step - loss: 0.6981 - val_loss: 224.0319\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.3329 - val_loss: 224.7997\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.3006 - val_loss: 224.0057\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.2752 - val_loss: 222.4489\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 0.4362 - val_loss: 222.0332\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.2974 - val_loss: 223.5201\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.6331 - val_loss: 222.3061\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 0s 188us/step - loss: 0.4214 - val_loss: 220.9669\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 0.3166 - val_loss: 222.5902\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.2435 - val_loss: 224.0149\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.7326 - val_loss: 222.6844\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 1.1778 - val_loss: 220.1168\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 3.8507 - val_loss: 225.4402\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 4.2603 - val_loss: 224.6207\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 2.2197 - val_loss: 217.6776\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 1.5091 - val_loss: 221.7481\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 1.3868 - val_loss: 235.5890\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 4.0648 - val_loss: 220.3404\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 1.9730 - val_loss: 223.9567\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 0s 232us/step - loss: 2.7153 - val_loss: 219.1682\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 0s 176us/step - loss: 0.8420 - val_loss: 228.0630\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.5496 - val_loss: 222.0638\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.4854 - val_loss: 225.3925\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.2883 - val_loss: 222.8880\n",
      "Epoch 518/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.3645 - val_loss: 222.8413\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.4213 - val_loss: 224.6456\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.1935 - val_loss: 222.4249\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.2233 - val_loss: 222.2560\n",
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.1688 - val_loss: 221.1712\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.352 - 0s 207us/step - loss: 0.4070 - val_loss: 220.3719\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.2959 - val_loss: 224.3147\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 0.2490 - val_loss: 223.3850\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.3531 - val_loss: 224.2020\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.2963 - val_loss: 225.7053\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.8031 - val_loss: 229.5365\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 1.3445 - val_loss: 225.6562\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.8830 - val_loss: 221.2612\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 1.0475 - val_loss: 221.1585\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 1.0012 - val_loss: 222.5217\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.6701 - val_loss: 232.6245\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 3.9508 - val_loss: 228.3095\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 0s 194us/step - loss: 1.6362 - val_loss: 227.4972\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 0s 192us/step - loss: 1.1960 - val_loss: 226.8947\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 0s 192us/step - loss: 1.4919 - val_loss: 224.6712\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 1.2123 - val_loss: 221.5883\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.1830 - val_loss: 221.6332\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 0.4287 - val_loss: 220.0135\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.2860 - val_loss: 224.8579\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 0s 192us/step - loss: 1.3041 - val_loss: 222.9560\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 1.2226 - val_loss: 221.2109\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.9461 - val_loss: 228.8454\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.5602 - val_loss: 221.7870\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.4749 - val_loss: 225.9134\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.3231 - val_loss: 221.3415\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2738 - val_loss: 221.3354\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 0.1682 - val_loss: 222.6755\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 0.1621 - val_loss: 221.9009\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 0.2884 - val_loss: 221.6907\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.3704 - val_loss: 223.8352\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 0.2036 - val_loss: 223.9146\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 0.1556 - val_loss: 222.4408\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.2818 - val_loss: 221.9668\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 0.3940 - val_loss: 222.6571\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 1.3774 - val_loss: 228.3279\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 2.7477 - val_loss: 232.1390\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 2.3442 - val_loss: 226.2992\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 3.0848 - val_loss: 222.4649\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 1.7140 - val_loss: 221.9637\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 1.4791 - val_loss: 226.4017\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 1.0306 - val_loss: 221.7214\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 0.4270 - val_loss: 222.4929\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.3409 - val_loss: 222.8357\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.7696 - val_loss: 222.0577\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.6517 - val_loss: 220.5317\n",
      "Epoch 568/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.6905 - val_loss: 224.0219\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.3228 - val_loss: 221.1577\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 0s 190us/step - loss: 1.1700 - val_loss: 221.8938\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 1.1355 - val_loss: 222.7656\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 3.4871 - val_loss: 223.3210\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 2.6745 - val_loss: 224.9980\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 1.4018 - val_loss: 220.4469\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.7717 - val_loss: 221.0992\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.4943 - val_loss: 221.6648\n",
      "Epoch 577/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 0.8034 - val_loss: 222.0853\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.8470 - val_loss: 223.8754\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.5411 - val_loss: 226.4974\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 0s 192us/step - loss: 0.2953 - val_loss: 222.7181\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.1424 - val_loss: 221.9670\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.1921 - val_loss: 222.6609\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 1.2509 - val_loss: 221.4433\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 1.2791 - val_loss: 223.0098\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 0s 179us/step - loss: 0.3768 - val_loss: 223.5419\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 0.1857 - val_loss: 224.1995\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.1417 - val_loss: 222.3642\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 0s 182us/step - loss: 0.0897 - val_loss: 223.3673\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.1370 - val_loss: 222.6634\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 0.2810 - val_loss: 222.5099\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 0.4856 - val_loss: 222.0112\n",
      "Epoch 592/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 0.3902 - val_loss: 224.5404\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 0.3947 - val_loss: 222.1480\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 0s 191us/step - loss: 1.2400 - val_loss: 225.6741\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 2.6174 - val_loss: 226.1407\n",
      "Epoch 596/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 9.0686 - val_loss: 217.7219\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 5.1646 - val_loss: 226.9356\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 3.4725 - val_loss: 222.1447\n",
      "Epoch 599/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 2.5637 - val_loss: 227.4185\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.1973 - val_loss: 218.8648\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.8419 - val_loss: 217.5582\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.6482 - val_loss: 222.9561\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.3933 - val_loss: 220.7351\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 0.2657 - val_loss: 221.0328\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.2572 - val_loss: 221.5277\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.1375 - val_loss: 222.1326\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 0s 228us/step - loss: 0.2353 - val_loss: 222.7636\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 0.1208 - val_loss: 221.7253\n",
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.0849 - val_loss: 222.3818\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 0s 232us/step - loss: 0.1049 - val_loss: 221.9290\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 0.0645 - val_loss: 221.3822\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 0s 191us/step - loss: 0.0938 - val_loss: 222.2820\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 0.0565 - val_loss: 223.5458\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 0.2025 - val_loss: 222.2718\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.3062 - val_loss: 221.2556\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.3361 - val_loss: 223.9627\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 0.1498 - val_loss: 222.2048\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 0s 191us/step - loss: 0.4680 - val_loss: 224.6382\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.5427 - val_loss: 222.4310\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.6233 - val_loss: 223.5261\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 1.1475 - val_loss: 221.8515\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 0s 225us/step - loss: 2.5825 - val_loss: 225.7968\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 3.2912 - val_loss: 221.2480\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 0s 237us/step - loss: 2.7436 - val_loss: 222.0895\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 0s 228us/step - loss: 1.6241 - val_loss: 224.8576\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 1.9022 - val_loss: 220.7994\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 0s 239us/step - loss: 0.7490 - val_loss: 220.4592\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.3524 - val_loss: 224.7637\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.4018 - val_loss: 221.6731\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 0.3729 - val_loss: 221.8532\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 0s 239us/step - loss: 0.2147 - val_loss: 222.7359\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.5275 - val_loss: 225.1006\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.4913 - val_loss: 226.4686\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.7144 - val_loss: 221.1304\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.5303 - val_loss: 222.5656\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 0.3892 - val_loss: 220.6471\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.4032 - val_loss: 221.5555\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 2.2895 - val_loss: 220.1463\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 1.4776 - val_loss: 222.7709\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 0s 189us/step - loss: 0.8750 - val_loss: 223.1059\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.8429 - val_loss: 221.4306\n",
      "Epoch 642/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 194us/step - loss: 0.3384 - val_loss: 222.0032\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.2670 - val_loss: 222.9195\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.4740 - val_loss: 221.4679\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 0s 189us/step - loss: 0.6963 - val_loss: 225.3612\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.9428 - val_loss: 223.1332\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 1.3707 - val_loss: 220.3269\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.7350 - val_loss: 222.4390\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.8791 - val_loss: 224.6088\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 1.0443 - val_loss: 219.5328\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 2.1389 - val_loss: 222.0824\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 1.2953 - val_loss: 225.5754\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 0s 239us/step - loss: 1.8621 - val_loss: 220.3290\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 4.3525 - val_loss: 224.9262\n",
      "Epoch 655/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 1.6979 - val_loss: 222.8639\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 0s 258us/step - loss: 2.0489 - val_loss: 222.6830\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.7068 - val_loss: 220.1776\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 0s 233us/step - loss: 0.4003 - val_loss: 225.1442\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.8942 - val_loss: 227.7404\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 0s 176us/step - loss: 0.8161 - val_loss: 225.5960\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.3560 - val_loss: 222.9937\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.2331 - val_loss: 223.1684\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.3267 - val_loss: 219.7044\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 0s 182us/step - loss: 1.0262 - val_loss: 220.8460\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 0.4489 - val_loss: 224.5917\n",
      "Epoch 666/1000\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.3973 - val_loss: 221.5757\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 0s 182us/step - loss: 0.2209 - val_loss: 222.5076\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.2047 - val_loss: 223.2691\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 0s 188us/step - loss: 0.1145 - val_loss: 221.6310\n",
      "Epoch 670/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.0974 - val_loss: 221.7279\n",
      "Epoch 671/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.1192 - val_loss: 222.9294\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.1173 - val_loss: 221.7147\n",
      "Epoch 673/1000\n",
      "1500/1500 [==============================] - 0s 183us/step - loss: 0.0705 - val_loss: 221.8342\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 0s 194us/step - loss: 0.0565 - val_loss: 222.0817\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2881 - val_loss: 223.1803\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.1742 - val_loss: 222.4692\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.3946 - val_loss: 221.3081\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.6346 - val_loss: 225.3212\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.9426 - val_loss: 221.6325\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 1.1698 - val_loss: 226.2895\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.8929 - val_loss: 221.1367\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 2.3478 - val_loss: 221.2485\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 7.4997 - val_loss: 229.1512\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 8.0861 - val_loss: 220.1554\n",
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 1.3633 - val_loss: 219.7557\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.5631 - val_loss: 219.1836\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.7122 - val_loss: 219.8978\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.4279 - val_loss: 220.9000\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.2832 - val_loss: 219.4614\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 0.3910 - val_loss: 221.9635\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 0.2995 - val_loss: 220.4315\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.1864 - val_loss: 222.2311\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 0.1533 - val_loss: 221.9386\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 0.0644 - val_loss: 222.0357\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 0.0740 - val_loss: 221.6233\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.0717 - val_loss: 221.2631\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.0625 - val_loss: 221.5900\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.0689 - val_loss: 221.8921\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.0420 - val_loss: 221.5704\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 0.0528 - val_loss: 220.6457\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.2233 - val_loss: 222.7316\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.1766 - val_loss: 221.0509\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 0.5202 - val_loss: 221.5387\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 2.1485 - val_loss: 222.5098\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 3.9733 - val_loss: 224.9893\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 3.6464 - val_loss: 218.1091\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 1.7085 - val_loss: 220.2261\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.9944 - val_loss: 225.1263\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 1.0210 - val_loss: 220.8578\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 0.3345 - val_loss: 220.1635\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.2414 - val_loss: 220.9102\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 0.3370 - val_loss: 223.2997\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.3036 - val_loss: 222.1580\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 0.2706 - val_loss: 220.7853\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.3526 - val_loss: 221.9910\n",
      "Epoch 716/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.3211 - val_loss: 222.3087\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 0.2382 - val_loss: 224.9552\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 0.4367 - val_loss: 222.0258\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.3196 - val_loss: 226.3490\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 1.3610 - val_loss: 220.2554\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 0.9736 - val_loss: 221.9908\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 0s 194us/step - loss: 0.4543 - val_loss: 220.6109\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.8180 - val_loss: 229.4900\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 1.0499 - val_loss: 218.1657\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.5537 - val_loss: 222.7652\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.3598 - val_loss: 222.5266\n",
      "Epoch 727/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.8020 - val_loss: 224.8499\n",
      "Epoch 728/1000\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 1.9914 - val_loss: 221.1451\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 4.0385 - val_loss: 222.4040\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 4.2421 - val_loss: 227.4564\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 0s 178us/step - loss: 1.8700 - val_loss: 219.8458\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.8671 - val_loss: 220.4167\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.6920 - val_loss: 222.9696\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.5219 - val_loss: 220.2700\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 0s 171us/step - loss: 0.3353 - val_loss: 221.4881\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.2291 - val_loss: 221.6731\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 0.2123 - val_loss: 221.2101\n",
      "Epoch 738/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.3173 - val_loss: 223.2655\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2021 - val_loss: 222.3500\n",
      "Epoch 740/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 0.2417 - val_loss: 223.6647\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.1822 - val_loss: 221.1610\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 0s 232us/step - loss: 0.1611 - val_loss: 224.1738\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.1570 - val_loss: 222.0929\n",
      "Epoch 744/1000\n",
      "1500/1500 [==============================] - 0s 232us/step - loss: 0.1183 - val_loss: 221.5661\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 0.1111 - val_loss: 222.1105\n",
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 0.1540 - val_loss: 221.6200\n",
      "Epoch 747/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.5695 - val_loss: 220.9138\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 2.5641 - val_loss: 229.3716\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 1.6413 - val_loss: 221.5603\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 1.1551 - val_loss: 220.5644\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 0.8589 - val_loss: 221.7708\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.6577 - val_loss: 225.5764\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.8596 - val_loss: 221.8157\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 0.4480 - val_loss: 222.2255\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 1.1385 - val_loss: 217.7500\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 1.6357 - val_loss: 219.8801\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 0s 232us/step - loss: 1.7867 - val_loss: 224.4884\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 1.2430 - val_loss: 219.2817\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 1.7628 - val_loss: 233.2035\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 1.0909 - val_loss: 222.8419\n",
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 0.5075 - val_loss: 220.6441\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.5890 - val_loss: 220.3944\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 0.9609 - val_loss: 224.3625\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.8755 - val_loss: 225.8145\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 1.2350 - val_loss: 223.8206\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 6.4378 - val_loss: 222.5780\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 3.8796 - val_loss: 227.5565\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 2.1087 - val_loss: 221.4714\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 0.6640 - val_loss: 219.9046\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.3609 - val_loss: 222.3843\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.3420 - val_loss: 220.2036\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.6069 - val_loss: 224.3423\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 0.3430 - val_loss: 222.0511\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 0.3180 - val_loss: 223.4315\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 0.4966 - val_loss: 222.2417\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 0s 201us/step - loss: 0.2825 - val_loss: 221.8594\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 0.2012 - val_loss: 222.8131\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 0.1925 - val_loss: 221.2987\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.1483 - val_loss: 221.5386\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 0.1039 - val_loss: 221.2929\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.1275 - val_loss: 221.5043\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.0984 - val_loss: 219.9686\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.1705 - val_loss: 220.7735\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.2833 - val_loss: 221.0317\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 0.2071 - val_loss: 221.0291\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 0.1316 - val_loss: 221.4304\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.2150 - val_loss: 224.8726\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.5366 - val_loss: 220.5893\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 0.4940 - val_loss: 223.2135\n",
      "Epoch 790/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 212us/step - loss: 0.4300 - val_loss: 220.4106\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.8279 - val_loss: 219.4609\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 1.3973 - val_loss: 216.8181\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 4.0270 - val_loss: 218.9674\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 0s 237us/step - loss: 2.2008 - val_loss: 225.3905\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 0s 232us/step - loss: 1.0765 - val_loss: 220.4938\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.6525 - val_loss: 220.5442\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 0s 208us/step - loss: 0.5086 - val_loss: 221.5984\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 1.1258 - val_loss: 220.6675\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 2.8459 - val_loss: 219.5504\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 1.1719 - val_loss: 219.8649\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 0.5137 - val_loss: 221.5068\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 0.4653 - val_loss: 220.4309\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 1.1714 - val_loss: 221.2181\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.4510 - val_loss: 219.8510\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 0s 168us/step - loss: 0.6022 - val_loss: 220.3235\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 0.6666 - val_loss: 218.9082\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.8019 - val_loss: 220.8903\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.7291 - val_loss: 223.2210\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 0s 186us/step - loss: 1.1209 - val_loss: 220.8942\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 2.5677 - val_loss: 221.9612\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 1.9123 - val_loss: 219.3773\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 0s 194us/step - loss: 0.8041 - val_loss: 220.7066\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.5328 - val_loss: 222.8240\n",
      "Epoch 814/1000\n",
      "1500/1500 [==============================] - 0s 188us/step - loss: 0.4651 - val_loss: 224.4398\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.3805 - val_loss: 224.2425\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 0.3701 - val_loss: 221.9112\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 0.1509 - val_loss: 222.3711\n",
      "Epoch 818/1000\n",
      "1500/1500 [==============================] - 0s 210us/step - loss: 0.1059 - val_loss: 222.3369\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.7518 - val_loss: 223.4379\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 1.0795 - val_loss: 221.9755\n",
      "Epoch 821/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 0.6980 - val_loss: 222.8387\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.4502 - val_loss: 219.5962\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 2.0408 - val_loss: 221.7330\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 0s 203us/step - loss: 1.3737 - val_loss: 221.8910\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.5751 - val_loss: 221.7444\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.3084 - val_loss: 220.6224\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.3143 - val_loss: 222.3294\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.4472 - val_loss: 222.7948\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 1.3020 - val_loss: 222.9888\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 0.6950 - val_loss: 221.7479\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.5171 - val_loss: 223.7390\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 0.8876 - val_loss: 221.0209\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 0.4071 - val_loss: 221.3342\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 0.5583 - val_loss: 220.2892\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 0s 237us/step - loss: 0.3480 - val_loss: 219.9956\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.5105 - val_loss: 225.2649\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 0.4242 - val_loss: 219.0720\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 0s 252us/step - loss: 0.7673 - val_loss: 226.9472\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 1.4967 - val_loss: 217.5396\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 3.3446 - val_loss: 221.0977\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 5.4876 - val_loss: 221.9059\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 3.6591 - val_loss: 222.9778\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 0.9765 - val_loss: 219.2769\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 0s 238us/step - loss: 0.5010 - val_loss: 223.6216\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.8311 - val_loss: 220.5800\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.4580 - val_loss: 224.9404\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.5951 - val_loss: 222.5302\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.3490 - val_loss: 223.1190\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 0.3826 - val_loss: 221.2003\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.9572 - val_loss: 222.3569\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 1.4852 - val_loss: 220.4558\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 0.6605 - val_loss: 222.5557\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 0s 215us/step - loss: 0.9135 - val_loss: 221.1455\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.6891 - val_loss: 222.2875\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 0s 216us/step - loss: 0.3897 - val_loss: 219.9381\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 0.2032 - val_loss: 220.5249\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 0.2475 - val_loss: 221.5130\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 0s 285us/step - loss: 0.3116 - val_loss: 220.6596\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.1622 - val_loss: 220.0046\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 0s 239us/step - loss: 0.0966 - val_loss: 220.5334\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 0s 225us/step - loss: 0.0993 - val_loss: 221.1954\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 0.2121 - val_loss: 219.7353\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 0.5184 - val_loss: 224.3318\n",
      "Epoch 864/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 230us/step - loss: 0.5671 - val_loss: 222.3357\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.3416 - val_loss: 221.7991\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.4806 - val_loss: 221.8555\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 0s 206us/step - loss: 0.5055 - val_loss: 222.3033\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 0.2528 - val_loss: 222.1785\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 0.6868 - val_loss: 220.2593\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 1.3069 - val_loss: 226.9765\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 1.3809 - val_loss: 223.1237\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 1.2483 - val_loss: 221.6105\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 1.6823 - val_loss: 220.1926\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 0s 228us/step - loss: 1.3660 - val_loss: 221.2074\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 1.5815 - val_loss: 219.0924\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 0s 218us/step - loss: 6.2995 - val_loss: 223.3727\n",
      "Epoch 877/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 2.7588 - val_loss: 218.1861\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.7799 - val_loss: 220.7026\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.4311 - val_loss: 218.1093\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.3668 - val_loss: 217.4071\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 0s 168us/step - loss: 0.5374 - val_loss: 220.8460\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.4004 - val_loss: 219.0247\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 0s 171us/step - loss: 0.1844 - val_loss: 221.0273\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.1403 - val_loss: 221.5593\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.1282 - val_loss: 221.0352\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.0823 - val_loss: 222.1398\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 0s 196us/step - loss: 0.1014 - val_loss: 220.0066\n",
      "Epoch 888/1000\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.0613 - val_loss: 220.2320\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 0s 214us/step - loss: 0.0940 - val_loss: 219.9765\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 0s 180us/step - loss: 0.4460 - val_loss: 219.7522\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 2.7598 - val_loss: 223.3091\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 2.3078 - val_loss: 217.2148\n",
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 1.0628 - val_loss: 227.2480\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 1.2684 - val_loss: 222.0106\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 1.1338 - val_loss: 222.0971\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.8038 - val_loss: 220.6643\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.5182 - val_loss: 217.9922\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.7376 - val_loss: 219.4200\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.4256 - val_loss: 221.7908\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.2624 - val_loss: 219.1815\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.3821 - val_loss: 220.5052\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.3950 - val_loss: 222.1100\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.3741 - val_loss: 220.7646\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.1996 - val_loss: 219.6693\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.2485 - val_loss: 222.1401\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 0.1814 - val_loss: 218.8396\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 0.2104 - val_loss: 220.5311\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 0.2004 - val_loss: 219.6089\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 0s 223us/step - loss: 0.1838 - val_loss: 218.9648\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 0s 232us/step - loss: 0.2525 - val_loss: 219.1024\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 0.4683 - val_loss: 219.9457\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.3215 - val_loss: 220.4107\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.4184 - val_loss: 219.0402\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 7.0065 - val_loss: 227.5404\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 3.0266 - val_loss: 219.1129\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 1.5439 - val_loss: 216.7061\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 1.1841 - val_loss: 219.9915\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 2.2792 - val_loss: 218.7027\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 1.5834 - val_loss: 219.3732\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.5690 - val_loss: 221.7293\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 0.3587 - val_loss: 219.8685\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 0.4051 - val_loss: 222.8492\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.2131 - val_loss: 219.9258\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.1498 - val_loss: 221.7242\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 0s 225us/step - loss: 0.1598 - val_loss: 220.6836\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 0.1205 - val_loss: 220.5975\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 0s 232us/step - loss: 0.1246 - val_loss: 219.6362\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 0.1134 - val_loss: 220.1630\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 0.1459 - val_loss: 223.5108\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 1.0200 - val_loss: 220.2287\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 0.5681 - val_loss: 219.9466\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 0.3239 - val_loss: 219.9342\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 0.2021 - val_loss: 220.0626\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 0s 217us/step - loss: 0.2987 - val_loss: 221.8395\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 0s 225us/step - loss: 0.2974 - val_loss: 220.0759\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 0s 228us/step - loss: 0.8978 - val_loss: 218.1291\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 0s 230us/step - loss: 1.6376 - val_loss: 223.4034\n",
      "Epoch 938/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.7828 - val_loss: 224.5621\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 1.3839 - val_loss: 221.0985\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 0s 211us/step - loss: 1.7534 - val_loss: 221.3115\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 3.5792 - val_loss: 220.9477\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 1.5644 - val_loss: 228.8763\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 0s 231us/step - loss: 1.3589 - val_loss: 219.3393\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.5421 - val_loss: 221.1746\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 0s 239us/step - loss: 0.2420 - val_loss: 221.9323\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 0s 219us/step - loss: 0.2398 - val_loss: 221.0532\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.3186 - val_loss: 219.9374\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 0s 238us/step - loss: 0.3078 - val_loss: 221.3645\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.1799 - val_loss: 219.8124\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 0s 235us/step - loss: 0.1533 - val_loss: 219.6369\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 0.1154 - val_loss: 220.3837\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 0s 228us/step - loss: 0.1087 - val_loss: 219.8966\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.0768 - val_loss: 219.5871\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 0s 254us/step - loss: 0.1562 - val_loss: 219.9327\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 0.2099 - val_loss: 221.3888\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.5410 - val_loss: 220.5375\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.9060 - val_loss: 218.6769\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 0s 256us/step - loss: 1.2114 - val_loss: 218.2202\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 0s 278us/step - loss: 1.9647 - val_loss: 229.1597\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 6.4286 - val_loss: 237.0110\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 4.6107 - val_loss: 225.5891\n",
      "Epoch 962/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 1.5865 - val_loss: 220.0105\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 0s 280us/step - loss: 0.6949 - val_loss: 220.2066\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 0s 271us/step - loss: 0.7047 - val_loss: 219.7680\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 0.4960 - val_loss: 221.8864\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 0.3619 - val_loss: 220.3144\n",
      "Epoch 967/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.2947 - val_loss: 218.4680\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 0s 265us/step - loss: 0.1759 - val_loss: 221.2717\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 0s 284us/step - loss: 0.5142 - val_loss: 219.2895\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.2212 - val_loss: 221.7153\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 0s 288us/step - loss: 0.1101 - val_loss: 220.0299\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 0s 299us/step - loss: 0.1213 - val_loss: 221.0660\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.2931 - val_loss: 219.4383\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 0s 288us/step - loss: 0.4629 - val_loss: 218.8179\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 0.3608 - val_loss: 221.5221\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 0s 294us/step - loss: 0.2710 - val_loss: 217.9550\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 0s 293us/step - loss: 0.2418 - val_loss: 222.5376\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 0s 275us/step - loss: 0.1978 - val_loss: 219.5425\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 0s 267us/step - loss: 0.4946 - val_loss: 218.0897\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 0s 255us/step - loss: 0.5410 - val_loss: 218.9718\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 0s 269us/step - loss: 0.1968 - val_loss: 219.6937\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 0.1974 - val_loss: 219.8511\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 0s 263us/step - loss: 0.6158 - val_loss: 220.3419\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 0s 262us/step - loss: 3.4388 - val_loss: 221.5265\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 1.7601 - val_loss: 217.0597\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 1.1620 - val_loss: 226.3146\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 0s 252us/step - loss: 1.9664 - val_loss: 221.8934\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 1.3347 - val_loss: 218.0777\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.5341 - val_loss: 219.0831\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 0s 259us/step - loss: 0.2205 - val_loss: 219.2828\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.2825 - val_loss: 222.0285\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.2079 - val_loss: 219.3580\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 0s 276us/step - loss: 0.2072 - val_loss: 218.3229\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 0s 266us/step - loss: 0.2131 - val_loss: 220.0954\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 0s 264us/step - loss: 0.1534 - val_loss: 220.7718\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 0s 260us/step - loss: 0.3273 - val_loss: 220.0922\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.3615 - val_loss: 222.6286\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 0s 270us/step - loss: 0.6953 - val_loss: 216.9285\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 0s 281us/step - loss: 1.6652 - val_loss: 216.7609\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 0s 272us/step - loss: 4.2028 - val_loss: 223.5212\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 326us/step\n",
      "264.794628200531\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 컨볼루션 신경망 모델\n",
    "\n",
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=1000, validation_data=(x_val, y_val))\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 300.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 학습결과 비교\n",
    "다층퍼셉트론 신경망 모델과 컨볼루션 신경망 모델을 비교했을 때<br>\n",
    "현재 파라미터로는 다층퍼셉트론 신경망 모델의 정확도가 더 높았다.<br>\n",
    "라벨값이 모양 및 색상 등 이미지의 특성보다 단순히 1인 픽셀 개수와 관련이 있기 때문에 컨볼루션 신경망 모델이 크게 성능을 발휘 못했다.<br>\n",
    "<br>\n",
    "즉 영상 입력이라고 해서 컨볼루션 신경망 모델이 항상 좋은 성능이 나오는 것이 아니다.<br>\n",
    "어떤 모델이 성능이 좋게 나올지는 테스트를 해봐야겠지만, 워낙 모델을 다양하게 구성할 수 있고 여러 파라미터를 설정할 수 있으므로 모델을 개발하기 전에 데이터 특징을 분석하고 적절한 후보 모델들을 선정하는 것을 권장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
